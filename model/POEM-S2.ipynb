{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T01:53:37.614558Z",
     "start_time": "2019-12-23T01:53:37.145175Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MhcOrxNibMjb"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T01:53:37.618088Z",
     "start_time": "2019-12-23T01:53:37.615727Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EGxgHeR6bN0K"
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T01:53:37.628879Z",
     "start_time": "2019-12-23T01:53:37.620028Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tBeDjO8dbPzP"
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "plot_num = 50000\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is different form POEM\n",
    "class SessionData(object):\n",
    "    def __init__(self,session_index,session_id,items_indexes):\n",
    "        self.session_index = session_index\n",
    "        self.session_id = session_id\n",
    "        self.item_list = items_indexes\n",
    "    def generate_seq_datas(self,session_length,padding_idx=0,predict_length=1):\n",
    "        sessions = []\n",
    "        if len(self.item_list)<2:\n",
    "            self.item_list.append[self.item_list[0]]\n",
    "        if predict_length==1:\n",
    "#             # when session length>=3\n",
    "#             for i in range(1,len(self.item_list)-1):\n",
    "            # when session length >=2\n",
    "            for i in range(len(self.item_list)-1):\n",
    "                if i <session_length:\n",
    "                    train_data = [0 for _ in range(session_length-i-1)]\n",
    "                    train_data.extend(self.item_list[:i+1])\n",
    "                    train_data.append(self.item_list[i+1])\n",
    "                else:\n",
    "                    train_data = self.item_list[i+1-session_length:i+1]\n",
    "                    train_data.append(self.item_list[i+1])\n",
    "                sessions.append(train_data)\n",
    "        else:\n",
    "            # To be continue if necessary\n",
    "            pass\n",
    "        return self.session_index,sessions\n",
    "    def __str__(self):\n",
    "        info = \" session index = {}\\n session id = {} \\n the length of item list= {} \\n the fisrt item index in item list is {}\".format(self.session_index,self.session_id,len(self.item_list),self.item_list[0])\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-23T02:56:36.525Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hl6NiyNJbTRg"
   },
   "outputs": [],
   "source": [
    "class SessionDataSet(object):\n",
    "    def __init__(self,train_file,test_file,padding_idx=0):\n",
    "        super(SessionDataSet,self).__init__()\n",
    "        self.index_count = 0\n",
    "        self.session_count = 0\n",
    "        self.train_count = 0\n",
    "        self.test_count = 0\n",
    "        self.max_session_length = 0\n",
    "\n",
    "        self.padding_idx = padding_idx\n",
    "        self.item2index = dict()\n",
    "        self.index2item = dict()\n",
    "        self.session2index = dict()\n",
    "        self.index2session = dict()\n",
    "        self.item_total_num = dict()\n",
    "        self.item2index[\"<pad>\"] = padding_idx\n",
    "        self.index2item[padding_idx] = \"<pad>\"\n",
    "        self.train_data = self.load_data(train_file)\n",
    "        print(\"training set is loaded, # index: \",len(self.item2index.keys()))\n",
    "        self.train_count = self.session_count\n",
    "        print(\"train_session_num\",self.train_count)\n",
    "        self.test_data = self.load_data(test_file)\n",
    "        print(\"testing set is loaded, # index: \",len(self.index2item.keys()))\n",
    "        print(\"# item\",self.index_count)\n",
    "        self.test_count = self.session_count-self.train_count\n",
    "        print(\"# test session:\",self.test_count)\n",
    "        self.all_training_data = []\n",
    "        self.all_testing_data = []\n",
    "        self.all_meta_training_data = []\n",
    "        self.all_meta_testing_data = []\n",
    "        self.train_session_length = 0\n",
    "        self.test_session_length = 0\n",
    "    \n",
    "    def load_data(self,file_path):\n",
    "        data =  pickle.load(open(file_path, 'rb'))\n",
    "        session_ids = data[0]\n",
    "        session_data = data[1]\n",
    "        session_label = data[2]\n",
    "\n",
    "        result_data = []\n",
    "        lenth = len(session_ids)\n",
    "        print(\"# session\",lenth)\n",
    "\n",
    "        last_session_id = session_ids[0]\n",
    "        \n",
    "        session_item_indexes = []\n",
    "\n",
    "        for item_id in session_data[0]:\n",
    "            if item_id not in self.item2index.keys():\n",
    "                self.index_count+=1\n",
    "                self.item2index[item_id] = self.index_count\n",
    "                self.index2item[self.index_count] = item_id\n",
    "                self.item_total_num[self.index_count] = 0\n",
    "            session_item_indexes.append(self.item2index[item_id])\n",
    "            self.item_total_num[self.item2index[item_id]] += 1\n",
    "        target_item = session_label[0]\n",
    "        if target_item not in self.item2index.keys():\n",
    "            self.index_count+=1\n",
    "            self.item2index[target_item] = self.index_count\n",
    "            self.index2item[self.index_count] = target_item\n",
    "            self.item_total_num[self.index_count] = 0\n",
    "        session_item_indexes.append(self.item2index[target_item])\n",
    "        self.item_total_num[self.item2index[target_item]] += 1\n",
    "\n",
    "        for session_id,items,target_item in zip(session_ids,session_data,session_label):\n",
    "            if session_id!=last_session_id:\n",
    "\n",
    "                self.session_count+=1\n",
    "                self.session2index[last_session_id] = self.session_count\n",
    "                self.index2session[self.session_count] = last_session_id\n",
    "                if len(session_item_indexes)>self.max_session_length:\n",
    "                    self.max_session_length = len(session_item_indexes)\n",
    "                new_session = SessionData(self.session_count,last_session_id,session_item_indexes)\n",
    "                result_data.append(new_session)\n",
    "                last_session_id = session_id\n",
    "                session_item_indexes = []\n",
    "                for item_id in items:\n",
    "                    if item_id not in self.item2index.keys():\n",
    "                        self.index_count+=1\n",
    "                        self.item2index[item_id] = self.index_count\n",
    "                        self.index2item[self.index_count] = item_id\n",
    "                        self.item_total_num[self.index_count] = 0\n",
    "                    session_item_indexes.append(self.item2index[item_id])\n",
    "                    self.item_total_num[self.item2index[item_id]] += 1\n",
    "                if target_item not in self.item2index.keys():\n",
    "                    self.index_count+=1\n",
    "                    self.item2index[target_item] = self.index_count\n",
    "                    self.index2item[self.index_count] = target_item\n",
    "                    self.item_total_num[self.index_count] = 0\n",
    "                session_item_indexes.append(self.item2index[target_item])\n",
    "                self.item_total_num[self.item2index[target_item]] += 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        self.session_count+=1\n",
    "        self.session2index[last_session_id] = self.session_count\n",
    "        new_session = SessionData(self.session_count,last_session_id,session_item_indexes)\n",
    "        result_data.append(new_session)\n",
    "        print(\"loaded\")\n",
    "        print(new_session)\n",
    "        \n",
    "        return result_data\n",
    "    \n",
    "\n",
    "    def get_batch(self,batch_size,session_length=10,predict_length=1,all_data=None,phase=\"train\",neg_num=1,sampling_mathod=\"random\"):\n",
    "\n",
    "        if phase == \"train\":\n",
    "            if all_data is None:\n",
    "                all_data = self.get_all_training_data(session_length)\n",
    "            indexes = np.random.permutation(all_data.shape[0])\n",
    "            all_data = all_data[indexes]\n",
    "        else:\n",
    "            if all_data is None:\n",
    "                all_data = self.get_all_testing_data(session_length)\n",
    "        \n",
    "        sindex = 0\n",
    "        eindex = batch_size\n",
    "        while eindex < all_data.shape[0]:\n",
    "            batch = all_data[sindex: eindex]\n",
    "\n",
    "            temp = eindex\n",
    "            eindex = eindex + batch_size\n",
    "            sindex = temp\n",
    "            if phase ==\"train\":\n",
    "                batch = self.divid_and_extend_negative_samples(batch,session_length=session_length,predict_length=predict_length,neg_num=neg_num,method=sampling_mathod)\n",
    "            else:\n",
    "                batch = [batch[:,:session_length],batch[:,session_length:]]\n",
    "            yield batch\n",
    "\n",
    "        if eindex >= all_data.shape[0]:\n",
    "            batch = all_data[sindex:]\n",
    "            if phase ==\"train\":\n",
    "                batch = self.divid_and_extend_negative_samples(batch,session_length=session_length,predict_length=predict_length,neg_num=neg_num,method=sampling_mathod)\n",
    "            else:\n",
    "                batch = [batch[:,:session_length],batch[:,session_length:]]\n",
    "            yield batch\n",
    "    \n",
    "    def divid_and_extend_negative_samples(self,batch_data,session_length,predict_length=1,neg_num=1,method=\"random\"):\n",
    "        \"\"\"\n",
    "        divid and extend negative samples\n",
    "        \"\"\"\n",
    "        neg_items = []\n",
    "        if method == \"random\":\n",
    "            for session_and_target in batch_data:\n",
    "                neg_item = []\n",
    "                for i in range(neg_num):\n",
    "                    rand_item = random.randint(1,self.index_count)\n",
    "                    while rand_item in session_and_target or rand_item in neg_item:\n",
    "                        rand_item = random.randint(1,self.index_count)\n",
    "                    neg_item.append(rand_item)\n",
    "                neg_items.append(neg_item)\n",
    "        else:\n",
    "\n",
    "            total_list = set()\n",
    "            for session in batch_data:\n",
    "                for i in session:\n",
    "                    total_list.add(i) \n",
    "            total_list = list(total_list)\n",
    "            total_list =  sorted(total_list, key=lambda item: self.item_total_num[item],reverse=True)\n",
    "            for i,session in enumerate(batch_data):\n",
    "                np.random.choice(total_list)\n",
    "        session_items = batch_data[:,:session_length]\n",
    "        target_item = batch_data[:,session_length:]\n",
    "        neg_items = np.array(neg_items)\n",
    "        return [session_items,target_item,neg_items]\n",
    "    \n",
    "    def get_all_training_data(self,session_length,predict_length=1):\n",
    "        if len(self.all_training_data)!=0 and self.train_session_length==session_length:\n",
    "#             print(\"The build is complete and there is no need to repeat the build\")\n",
    "            return self.all_training_data\n",
    "        print(\"Start building the all training dataset\")\n",
    "        all_sessions = []\n",
    "        for session_data in self.train_data:\n",
    "            # 前session_length为session，后predict_length为target_item\n",
    "            session_index,sessions = session_data.generate_seq_datas(session_length,padding_idx=self.padding_idx)\n",
    "            if sessions is not None:\n",
    "                all_sessions.extend(sessions)\n",
    "        all_sessions = np.array(all_sessions)\n",
    "        self.all_training_data = all_sessions\n",
    "        self.train_session_length=session_length\n",
    "        print(\"The total number of training samples is：\",all_sessions.shape)\n",
    "        return all_sessions\n",
    "    \n",
    "    def get_all_testing_data(self,session_length,predict_length=1):\n",
    "        if len(self.all_testing_data)!=0 and self.test_session_length==session_length:\n",
    "            return self.all_testing_data\n",
    "        all_sessions = []\n",
    "        for session_data in self.test_data:\n",
    "            session_index,sessions = session_data.generate_seq_datas(session_length,padding_idx=self.padding_idx)\n",
    "            if sessions is not None:\n",
    "                all_sessions.extend(sessions)\n",
    "        all_sessions = np.array(all_sessions)\n",
    "        self.all_testing_data = all_sessions\n",
    "        self.test_session_length=session_length\n",
    "        print(\"The total number of testing samples is：\",all_sessions.shape)\n",
    "        return all_sessions\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T01:53:38.510098Z",
     "start_time": "2019-12-23T01:53:37.685667Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "ctSu0HF8bUqh",
    "outputId": "7287ecc0-f73d-4883-c8f6-20c9b8aeddb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# session 369859\n",
      "loaded\n",
      " session index = 116167\n",
      " session id = 11497318 \n",
      " the length of item list= 3 \n",
      " the fisrt item index in item list is 373\n",
      "training set is loaded, # index:  17377\n",
      "train_session_num 116167\n",
      "# session 55898\n",
      "loaded\n",
      " session index = 131491\n",
      " session id = 11560908 \n",
      " the length of item list= 3 \n",
      " the fisrt item index in item list is 4799\n",
      "testing set is loaded, # index:  17746\n",
      "# item 17745\n",
      "# test session: 15324\n"
     ]
    }
   ],
   "source": [
    "# dataset = SessionDataSet(train_file=\"../data/retailrocket/train.txt\",test_file=\"../data/srgnn/retailrocket/test.txt\")\n",
    "# dataset = SessionDataSet(train_file=\"../data/diginetica/train.txt\",test_file=\"../data/srgnn/diginetica/test.txt\")\n",
    "dataset = SessionDataSet(train_file=\"../data/yoochoose1_4/train.txt\",test_file=\"../data/srgnn/yoochoose1_4/test.txt\")\n",
    "# dataset = SessionDataSet(train_file=\"../data/yoochoose1_64/train.txt\",test_file=\"../data/srgnn/yoochoose1_64/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T01:53:38.518875Z",
     "start_time": "2019-12-23T01:53:38.511002Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "cm7qU4B6bq2i"
   },
   "outputs": [],
   "source": [
    "def bpr_loss(r):\n",
    "    return torch.sum(-torch.log(torch.sigmoid(r)))\n",
    "def get_hit_num(pred,y_truth):\n",
    "    \"\"\"\n",
    "        pred: numpy type(batch_size,k) \n",
    "        y_truth: list type (batch_size,groudtruth_num)\n",
    "    \"\"\"\n",
    "\n",
    "    hit_num = 0\n",
    "    for i in range(len(y_truth)):\n",
    "        for value in y_truth[i]:\n",
    "            hit_num += np.sum(pred[i]==value)\n",
    "    return hit_num\n",
    "\n",
    "def get_rr(pred,y_truth):\n",
    "    rr=0.\n",
    "    for i in range(len(y_truth)):\n",
    "        for value in y_truth[i]:\n",
    "            hit_indexes = np.where(pred[i]==value)[0]\n",
    "            for hit_index in hit_indexes:\n",
    "                rr += 1/(hit_index+1)\n",
    "    return rr\n",
    "\n",
    "def get_dcg(pred,y_truth):\n",
    "    y_pred_score = np.zeros_like(pred)\n",
    "\n",
    "    for i in range(len(y_truth)):\n",
    "\n",
    "        for j,y_pred in enumerate(pred[i]):\n",
    "            if y_pred == y_truth[i][0]:\n",
    "                y_pred_score[i][j]=1\n",
    "    gain = 2 ** y_pred_score - 1\n",
    "    discounts = np.tile(np.log2(np.arange(pred.shape[1]) + 2),(len(y_truth),1))\n",
    "    dcg = np.sum(gain / discounts,axis=1)\n",
    "    return dcg\n",
    "\n",
    "def get_ndcg(pred,y_truth):\n",
    "    dcg = get_dcg(pred, y_truth)\n",
    "    idcg = get_dcg(np.concatenate((y_truth,np.zeros_like(pred)[:,:-1]-1),axis=1), y_truth)\n",
    "    ndcg = np.sum(dcg / idcg)\n",
    "\n",
    "    return ndcg\n",
    "\n",
    "def dcg_score(y_pre, y_true, k):\n",
    "    y_pre_score = np.zeros(k)\n",
    "    if len(y_pre) > k:\n",
    "        y_pre = y_pre[:k]\n",
    "    for i in range(len(y_pre)):\n",
    "        pre_tag = y_pre[i]\n",
    "        if pre_tag in y_true:\n",
    "            y_pre_score[i] = 1\n",
    "    gain = 2 ** y_pre_score - 1\n",
    "    discounts = np.log2(np.arange(k) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_pre, y_true, k=5):\n",
    "    dcg = dcg_score(y_pre, y_true, k)\n",
    "    idcg = dcg_score(y_true, y_true, k)\n",
    "    return dcg / idcg\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T01:53:38.532829Z",
     "start_time": "2019-12-23T01:53:38.520350Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "QdNvTTApbr_g"
   },
   "outputs": [],
   "source": [
    "# SelfAttention Layer\n",
    "class SelfAttention(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size,activate=\"selu\",dropout=0):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.config = list()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method not in ['dot', 'general']:\n",
    "            raise ValueError(self.method, \"Attention method do not exists.\")\n",
    "\n",
    "        if self.method == \"dot\":\n",
    "            self.query = torch.nn.Linear(self.hidden_size *2, self.hidden_size*2)\n",
    "            self.key = torch.nn.Linear(self.hidden_size*2, self.hidden_size*2)\n",
    "            torch.nn.init.constant_(self.query.bias,0)\n",
    "            torch.nn.init.constant_(self.key.bias,0)\n",
    "\n",
    "        if self.method == \"general\":\n",
    "            self.attention = torch.nn.Linear(self.hidden_size*2, self.hidden_size*2)\n",
    "            torch.nn.init.constant_(self.attention.bias,0)\n",
    "        \n",
    "        if activate == \"relu\":\n",
    "            self.activate = torch.relu\n",
    "        elif activate == \"tanh\":\n",
    "            self.activate = torch.tanh\n",
    "        elif activate == \"elu\":\n",
    "            self.activate = torch.nn.ELU()\n",
    "        elif activate == \"selu\":\n",
    "            self.activate = torch.selu\n",
    "        else:\n",
    "            self.activate = torch.sigmoid\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        torch.nn.utils.clip_grad_norm_(self.parameters(),max_norm=110)\n",
    "\n",
    "    def dot_score(self, encoder_output,is_train=True,weights=None):\n",
    "\n",
    "        if weights is None:\n",
    "            if is_train:\n",
    "                query = self.dropout(self.activate(self.query(encoder_output)))\n",
    "                key = self.dropout(self.activate(self.key(encoder_output)))\n",
    "            else:\n",
    "                query = self.activate(self.query(encoder_output))\n",
    "                key = self.activate(self.key(encoder_output))\n",
    "        else:\n",
    "            query = self.activate(torch.matmul(encoder_output,weights[0].t())+weights[1])\n",
    "            key = self.activate(torch.matmul(encoder_output,weights[2].t())+weights[3])\n",
    "        dot = query.bmm(key.permute(0, 2, 1))\n",
    "        return dot\n",
    "\n",
    "    def general_score(self, encoder_output,is_train=True,weights=None):\n",
    "        if weights is None:\n",
    "            if is_train:\n",
    "                energy = self.dropout(self.activate(self.attention(encoder_output)))\n",
    "            else:\n",
    "                energy = self.activate(self.attention(encoder_output))\n",
    "        else:\n",
    "            energy = self.activate(torch.matmul(encoder_output,weights[0].t())+weights[1])\n",
    "        return encoder_output.bmm(energy.permute(0, 2, 1))\n",
    "\n",
    "    def forward(self, encoder_outputs, mask=None,is_train=True):\n",
    "        # (batch_size,length,dim)\n",
    "        if self.method == \"general\":\n",
    "            attention_energies = self.general_score(encoder_outputs,is_train=is_train)\n",
    "        elif self.method == \"dot\":\n",
    "            attention_energies = self.dot_score(encoder_outputs,is_train=is_train)\n",
    "\n",
    "        #  (batch_size,length,length)\n",
    "        attention_energies.div_(torch.sqrt(torch.tensor(self.hidden_size, dtype=torch.float)))\n",
    "        if mask is not None:\n",
    "            new_mask = (1 - (1 - mask.float()).unsqueeze(1).permute(0, 2, 1).bmm(\n",
    "                (1 - mask.float()).unsqueeze(1)))\n",
    "\n",
    "            attention_energies = attention_energies - new_mask*1e12\n",
    "            weights = F.softmax(attention_energies, dim=2)\n",
    "            weights = weights*(1-new_mask)\n",
    "            # batch_size,length,length)*(batch_size,length,dim)->(batch_size,length,dim)->(batch_size,1,dim)->(batch_size,dim)\n",
    "            outputs = weights.bmm(encoder_outputs)\n",
    "            outputs.div_(mask.shape[1]-torch.sum(mask,dim=1).unsqueeze(1).unsqueeze(2).repeat((1,mask.shape[1],outputs.shape[2])).float())\n",
    "            outputs = outputs.sum(dim=1).squeeze(1)\n",
    "        else:\n",
    "            weights = F.softmax(attention_energies, dim=2)\n",
    "            # (batch_size,length,length)*(batch_size,length,dim)->(batch_size,length,dim)->(batch_size,1,dim)->(batch_size,dim)\n",
    "            outputs = (weights.bmm(encoder_outputs).sum(dim=1) / encoder_outputs.shape[1]).squeeze(1)\n",
    "        sa_weights = weights.sum(dim=1).squeeze(1)\n",
    "        return outputs, sa_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-23T01:53:36.843Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aVIrdlmKbtUq"
   },
   "outputs": [],
   "source": [
    "class POEM(torch.nn.Module):\n",
    "    def __init__(self, hidden_size=64, itemNum=0, posNum=0, padding_idx=0, dropout=0.5,attention_method=\"dot\",head_num=4,\n",
    "                 activate=\"selu\",session_length=20):\n",
    "        super(POEM, self).__init__()\n",
    "        self.padding_idx = padding_idx\n",
    "        self.hidden_size = hidden_size\n",
    "        self.head_num = head_num\n",
    "        self.session_length = session_length\n",
    "        if activate == \"sigmoid\":\n",
    "            self.activate = torch.sigmoid\n",
    "        elif activate == \"tanh\":\n",
    "            self.activate = torch.tanh\n",
    "        elif activate == \"relu\":\n",
    "            self.activate = torch.relu\n",
    "        elif activate == \"elu\":\n",
    "            self.activate = torch.nn.ELU()\n",
    "        else:\n",
    "            self.activate = torch.selu\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.item_embedding = torch.nn.Embedding(itemNum, hidden_size, padding_idx=self.padding_idx,max_norm=1.5)\n",
    "        \n",
    "        self.position_embedding = torch.nn.Embedding(posNum,hidden_size,padding_idx=self.padding_idx,max_norm=1.5)\n",
    "    \n",
    "        self.position_weights = torch.nn.Embedding(posNum,1,padding_idx=self.padding_idx)\n",
    "        \n",
    "        self.self_attention = SelfAttention(attention_method, hidden_size,activate=activate,dropout=dropout).to(device)\n",
    "        torch.nn.init.constant_(self.item_embedding.weight[0],0)\n",
    "        torch.nn.init.constant_(self.position_embedding.weight[0],0)\n",
    "        torch.nn.init.constant_(self.position_weights.weight,1)\n",
    "        torch.nn.init.constant_(self.position_weights.weight[0],0)\n",
    "        \n",
    "        self.gen_mlp = torch.nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.cur_mlp = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.deep_mlp = torch.nn.Linear(hidden_size*3, hidden_size,bias=False)\n",
    "        \n",
    "        self.layer_norm1 = torch.nn.LayerNorm(hidden_size*2)\n",
    "        self.layer_norm2 = torch.nn.LayerNorm(hidden_size)\n",
    "        \n",
    "    def forward(self, session,item=None,bpr_loss=False,neg_num=50):\n",
    "\n",
    "        mask = (session!=0).float()\n",
    "        length = torch.sum(mask,1).unsqueeze(1).expand((session.shape[0],self.hidden_size))\n",
    "        mask = mask.unsqueeze(2).expand((session.shape[0],session.shape[1],self.hidden_size))\n",
    "        session_item_embeddings = self.item_embedding(session) * mask\n",
    "        positions = session.shape[1] - torch.arange(0,session.shape[1]).unsqueeze(0).expand_as(session).to(device)\n",
    "        session_position_embeddings = self.dropout(self.position_embedding(positions))*mask\n",
    "        session_item_vecs = torch.cat((session_item_embeddings,session_position_embeddings), dim=2)\n",
    "        attention_mask = (session == self.padding_idx)\n",
    "        sa_output, sa_weights = self.self_attention(session_item_vecs, attention_mask)\n",
    "        sa_output = self.layer_norm1(sa_output)\n",
    "\n",
    "        session_position_weights = self.dropout(self.position_weights(positions))*mask\n",
    "        sa_weights = sa_weights.unsqueeze(2).expand_as(session_item_embeddings)\n",
    "        session_item_vecs2 = session_item_embeddings * session_position_weights * sa_weights\n",
    "        psa_output = torch.sum(session_item_vecs2, dim=1)/length\n",
    "        psa_output = self.layer_norm2(psa_output)\n",
    "\n",
    "        gen_output = self.dropout(self.activate(self.gen_mlp(sa_output)))\n",
    "        cur_output = self.dropout(self.activate(self.cur_mlp(session_item_embeddings[:,-1])))\n",
    "        deep_output = self.dropout(self.activate(self.deep_mlp(torch.cat((sa_output,session_item_embeddings[:,-1]),1))))\n",
    "        \n",
    "        session_output = self.layer_norm2(gen_output* cur_output+deep_output +psa_output)\n",
    "        \n",
    "        result = torch.matmul(session_output,self.item_embedding.weight[1:].t())\n",
    "        return result\n",
    "    \n",
    "    def predict_top_k(self, session, k=20):\n",
    "        mask = (session!=0).float()\n",
    "        length = torch.sum(mask,1).unsqueeze(1).expand((session.shape[0],self.hidden_size))\n",
    "        mask = mask.unsqueeze(2).expand((session.shape[0],session.shape[1],self.hidden_size))\n",
    "        session_item_embeddings = self.item_embedding(session) * mask\n",
    "        positions = session.shape[1] - torch.arange(0,session.shape[1]).unsqueeze(0).expand_as(session).to(device)\n",
    "        session_position_embeddings = self.position_embedding(positions)*mask\n",
    "        session_item_vecs = torch.cat((session_item_embeddings,session_position_embeddings), dim=2)\n",
    "        attention_mask = (session == self.padding_idx)\n",
    "        sa_output, sa_weights = self.self_attention(session_item_vecs, attention_mask,is_train=False)\n",
    "        sa_output = self.layer_norm1(sa_output)\n",
    "\n",
    "        session_position_weights = self.position_weights(positions)*mask\n",
    "        sa_weights = sa_weights.unsqueeze(2).expand_as(session_item_embeddings)\n",
    "        session_item_vecs2 = session_item_embeddings * session_position_weights * sa_weights\n",
    "        psa_output = torch.sum(session_item_vecs2, dim=1)/length\n",
    "        psa_output = self.layer_norm2(psa_output)\n",
    "\n",
    "        gen_output =self.activate(self.gen_mlp(sa_output))\n",
    "\n",
    "        cur_output = self.activate(self.cur_mlp(session_item_embeddings[:,-1]))\n",
    "        deep_output = self.activate(self.deep_mlp(torch.cat((sa_output,session_item_embeddings[:,-1]),1)))\n",
    "        session_output = self.layer_norm2(gen_output* cur_output+deep_output +psa_output)\n",
    "\n",
    "        result = torch.matmul(session_output,self.item_embedding.weight[1:].t())\n",
    "        result = torch.topk(result,k,dim=1)[1]\n",
    "        \n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-23T01:53:36.845Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Jhrg56xebung"
   },
   "outputs": [],
   "source": [
    "epochs=50\n",
    "def train(args):\n",
    "    hidden_size = args[\"hidden_size\"] if \"hidden_size\" in args.keys() else 100\n",
    "    dropout = args[\"dropout\"] if \"dropout\" in args.keys()  else 0.5\n",
    "    attention_method = args[\"method\"] if \"method\" in args.keys()  else \"general\"\n",
    "    lr = args[\"lr\"] if \"lr\" in args.keys()  else 5e-4\n",
    "    weight_decay = args[\"weight_decay\"] if \"weight_decay\" in args.keys()  else 1e-5\n",
    "    amsgrad = args[\"amsgrad\"] if \"amsgrad\" in args.keys() else True\n",
    "    session_length = args[\"session_length\"] if \"session_length\" in args.keys() else 20\n",
    "    model = POEM(hidden_size=hidden_size, itemNum=dataset.index_count+1, posNum=session_length+1, padding_idx=0, dropout=dropout,\n",
    "                 activate=\"selu\",attention_method=attention_method).to(device)\n",
    "    opti = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay,amsgrad=amsgrad)\n",
    "    patience = args[\"patience\"] if \"patience\" in args.keys() else 5\n",
    "    best_model_hr = 0.0\n",
    "    best_model_mrr = 0.0\n",
    "    best_r1m = 0.0\n",
    "    best_model = None\n",
    "    predict_nums = [1,5,10,20]\n",
    "    no_improvement_epoch = 0\n",
    "    for epoch in range(epochs):\n",
    "        batch_losses = []\n",
    "        epoch_losses = []\n",
    "        for i,batch_data in enumerate(dataset.get_batch(batch_size,session_length,phase=\"train\")):\n",
    "            sessions = torch.tensor(batch_data[0]).to(device)\n",
    "            target_items = torch.tensor(batch_data[1]).squeeze().to(device)-1\n",
    "            result_pos = model(sessions)\n",
    "            loss = loss_function(result_pos,target_items)\n",
    "            opti.zero_grad()\n",
    "            loss.backward()\n",
    "            norm = torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=110)\n",
    "            opti.step()\n",
    "            batch_losses.append(loss.cpu().detach().numpy())\n",
    "            epoch_losses.append(loss.cpu().detach().numpy())\n",
    "            if i % plot_num == 0:\n",
    "                time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                print(\"[%s] [%d/%d] %d mean_batch_loss : %0.6f\" % (time, epoch+1, epochs, i, np.mean(batch_losses)))\n",
    "                batch_losses = []\n",
    "        with torch.no_grad():\n",
    "            start_test_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(\"Start predicting\",start_test_time)\n",
    "            rrs = [0 for _ in range(len(predict_nums))]\n",
    "            hit_nums = [0 for _ in range(len(predict_nums))]\n",
    "            ndcgs = [0 for _ in range(len(predict_nums))]\n",
    "            for i,batch_data in enumerate(dataset.get_batch(batch_size,session_length,phase=\"test\")):\n",
    "                \n",
    "                sessions = torch.tensor(batch_data[0]).to(device)\n",
    "                target_items = np.array(batch_data[1])-1\n",
    "                y_pred = model.predict_top_k(sessions,20).cpu().numpy()\n",
    "                \n",
    "                for j,predict_num in enumerate(predict_nums):\n",
    "                    hit_nums[j]+=get_hit_num(y_pred[:,:predict_num],target_items)\n",
    "                    rrs[j]+=get_rr(y_pred[:,:predict_num],target_items)\n",
    "                    ndcgs[j]+=get_ndcg(y_pred[:,:predict_num],target_items)\n",
    "                    \n",
    "            end_test_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            hrs = [hit_num/len(dataset.all_testing_data) for hit_num in hit_nums]\n",
    "            mrrs = [rr/len(dataset.all_testing_data) for rr in rrs]\n",
    "            mndcgs = [ndcg/len(dataset.all_testing_data) for ndcg in ndcgs]\n",
    "            if hrs[-1] + mrrs[-1] > best_r1m:\n",
    "                print(\"change best\")\n",
    "                best_model = deepcopy(model)\n",
    "                best_model_hr = hrs[-1]\n",
    "                best_model_mrr = mrrs[-1]\n",
    "                best_r1m = hrs[-1] + mrrs[-1]\n",
    "                no_improvement_epoch = 0\n",
    "            else:\n",
    "                no_improvement_epoch +=1\n",
    "            print(\"testing finish [%s] \"%end_test_time)\n",
    "            for k,predict_num in enumerate(predict_nums):\n",
    "                print(\"\\tHR@%d=%.5f  MRR@%d=%.5f  NDCG@%d=%.5f\"%(predict_num,hrs[k],predict_num,mrrs[k],predict_num,mndcgs[k]))\n",
    "        if no_improvement_epoch>=patience:\n",
    "            print(\"early stopping\")\n",
    "            break\n",
    "    return best_model,best_model_hr,best_model_mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2H2SFJ7F77Z0"
   },
   "source": [
    "# CIKM-Session >= 2\n",
    "    HR@20=0.65834  MRR@20=0.31324, hyper-parameters: session_length-20, hidden_size-100, lr-0.0005 , amsgrad-True, method-general, dropout-0.5, weight_decay-0.000000. \n",
    "        HR@1=0.19843  MRR@1=0.19843  NDCG@1=0.19843\n",
    "        HR@5=0.44970  MRR@5=0.29180  NDCG@5=0.33116\n",
    "        HR@10=0.55705  MRR@10=0.30616  NDCG@10=0.36591\n",
    "        HR@20=0.65834  MRR@20=0.31324  NDCG@20=0.39157\n",
    "# RR-Session >= 2\n",
    "    HR@20=0.62795  MRR@20=0.36291, hyper-parameters: session_length-20, hidden_size-100, lr-0.0005 , amsgrad-True, method-general, dropout-0.5, weight_decay-0.000000. \n",
    "        HR@1=0.27038  MRR@1=0.27038  NDCG@1=0.27038\n",
    "        HR@5=0.47748  MRR@5=0.34741  NDCG@5=0.37984\n",
    "        HR@10=0.55384  MRR@10=0.35770  NDCG@10=0.40462\n",
    "        HR@20=0.62795  MRR@20=0.36291  NDCG@20=0.42345\n",
    "# RSC64-Session >= 2\n",
    "    HR@20=0.71886  MRR@20=0.31580， hyper-parameters: session_length-20, hidden_size-100, lr-0.0005 , amsgrad-True, method-general, dropout-0.3, weight_decay-0.000000. \n",
    "        HR@1=0.18341  MRR@1=0.18341  NDCG@1=0.18341\n",
    "        HR@5=0.48034  MRR@5=0.29042  NDCG@5=0.33760\n",
    "        HR@10=0.61417  MRR@10=0.30842  NDCG@10=0.38101\n",
    "        HR@20=0.71886  MRR@20=0.31580  NDCG@20=0.40762\n",
    "# RSC4-Session >= 2\n",
    "    HR@20=0.72482  MRR@20=0.31616， hyper-parameters: session_length-20, hidden_size-100, lr-0.0003 , amsgrad-True, method-general, dropout-0.3, weight_decay-0.000000. \n",
    "        HR@1=0.18267  MRR@1=0.18267  NDCG@1=0.18267\n",
    "        HR@5=0.48286  MRR@5=0.29065  NDCG@5=0.33837\n",
    "        HR@10=0.61471  MRR@10=0.30837  NDCG@10=0.38114\n",
    "        HR@20=0.72482  MRR@20=0.31616  NDCG@20=0.40915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-23T01:53:36.846Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "S8pn0Z7bbv4t",
    "outputId": "c1aa9692-56a0-40d2-d99b-e75b4f1e537e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0003, amsgrad=True, method=general, dropout=0.3, weight_decay=0.000000. \n",
      "\n",
      "Start building the all training dataset\n",
      "The total number of training samples is： (369859, 21)\n",
      "[2019-12-23 09:53:43] [1/50] 0 mean_batch_loss : 37.880951\n",
      "Start predicting 2019-12-23 09:53:56\n",
      "The total number of testing samples is： (55898, 21)\n",
      "change best\n",
      "testing finish [2019-12-23 09:53:59] \n",
      "\tHR@1=0.02136  MRR@1=0.02136  NDCG@1=0.02136\n",
      "\tHR@5=0.07072  MRR@5=0.03898  NDCG@5=0.04682\n",
      "\tHR@10=0.10507  MRR@10=0.04343  NDCG@10=0.05779\n",
      "\tHR@20=0.15761  MRR@20=0.04704  NDCG@20=0.07105\n",
      "[2019-12-23 09:53:59] [2/50] 0 mean_batch_loss : 9.409584\n",
      "Start predicting 2019-12-23 09:54:12\n",
      "change best\n",
      "testing finish [2019-12-23 09:54:16] \n",
      "\tHR@1=0.08197  MRR@1=0.08197  NDCG@1=0.08197\n",
      "\tHR@5=0.15984  MRR@5=0.11016  NDCG@5=0.12250\n",
      "\tHR@10=0.19838  MRR@10=0.11525  NDCG@10=0.13491\n",
      "\tHR@20=0.24351  MRR@20=0.11834  NDCG@20=0.14626\n",
      "[2019-12-23 09:54:16] [3/50] 0 mean_batch_loss : 7.537191\n",
      "Start predicting 2019-12-23 09:54:28\n",
      "change best\n",
      "testing finish [2019-12-23 09:54:32] \n",
      "\tHR@1=0.11720  MRR@1=0.11720  NDCG@1=0.11720\n",
      "\tHR@5=0.25334  MRR@5=0.16717  NDCG@5=0.18861\n",
      "\tHR@10=0.31293  MRR@10=0.17509  NDCG@10=0.20785\n",
      "\tHR@20=0.37944  MRR@20=0.17965  NDCG@20=0.22459\n",
      "[2019-12-23 09:54:32] [4/50] 0 mean_batch_loss : 7.002310\n",
      "Start predicting 2019-12-23 09:54:44\n",
      "change best\n",
      "testing finish [2019-12-23 09:54:48] \n",
      "\tHR@1=0.12789  MRR@1=0.12789  NDCG@1=0.12789\n",
      "\tHR@5=0.30112  MRR@5=0.19204  NDCG@5=0.21921\n",
      "\tHR@10=0.37831  MRR@10=0.20237  NDCG@10=0.24420\n",
      "\tHR@20=0.45812  MRR@20=0.20791  NDCG@20=0.26437\n",
      "[2019-12-23 09:54:48] [5/50] 0 mean_batch_loss : 6.548748\n",
      "Start predicting 2019-12-23 09:55:02\n",
      "change best\n",
      "testing finish [2019-12-23 09:55:05] \n",
      "\tHR@1=0.13435  MRR@1=0.13435  NDCG@1=0.13435\n",
      "\tHR@5=0.33962  MRR@5=0.21071  NDCG@5=0.24284\n",
      "\tHR@10=0.42533  MRR@10=0.22211  NDCG@10=0.27052\n",
      "\tHR@20=0.51404  MRR@20=0.22828  NDCG@20=0.29296\n",
      "[2019-12-23 09:55:05] [6/50] 0 mean_batch_loss : 5.917305\n",
      "Start predicting 2019-12-23 09:55:19\n",
      "change best\n",
      "testing finish [2019-12-23 09:55:22] \n",
      "\tHR@1=0.13879  MRR@1=0.13879  NDCG@1=0.13879\n",
      "\tHR@5=0.36477  MRR@5=0.22330  NDCG@5=0.25859\n",
      "\tHR@10=0.46249  MRR@10=0.23643  NDCG@10=0.29027\n",
      "\tHR@20=0.55612  MRR@20=0.24297  NDCG@20=0.31400\n",
      "[2019-12-23 09:55:22] [7/50] 0 mean_batch_loss : 5.769737\n",
      "Start predicting 2019-12-23 09:55:35\n",
      "change best\n",
      "testing finish [2019-12-23 09:55:39] \n",
      "\tHR@1=0.14251  MRR@1=0.14251  NDCG@1=0.14251\n",
      "\tHR@5=0.38667  MRR@5=0.23374  NDCG@5=0.27189\n",
      "\tHR@10=0.49585  MRR@10=0.24839  NDCG@10=0.30727\n",
      "\tHR@20=0.58898  MRR@20=0.25495  NDCG@20=0.33094\n",
      "[2019-12-23 09:55:39] [8/50] 0 mean_batch_loss : 5.655376\n",
      "Start predicting 2019-12-23 09:55:51\n",
      "change best\n",
      "testing finish [2019-12-23 09:55:55] \n",
      "\tHR@1=0.14573  MRR@1=0.14573  NDCG@1=0.14573\n",
      "\tHR@5=0.40450  MRR@5=0.24193  NDCG@5=0.28244\n",
      "\tHR@10=0.51946  MRR@10=0.25736  NDCG@10=0.31971\n",
      "\tHR@20=0.61317  MRR@20=0.26396  NDCG@20=0.34352\n",
      "[2019-12-23 09:55:55] [9/50] 0 mean_batch_loss : 5.501721\n",
      "Start predicting 2019-12-23 09:56:08\n",
      "change best\n",
      "testing finish [2019-12-23 09:56:11] \n",
      "\tHR@1=0.14823  MRR@1=0.14823  NDCG@1=0.14823\n",
      "\tHR@5=0.41755  MRR@5=0.24833  NDCG@5=0.29051\n",
      "\tHR@10=0.53553  MRR@10=0.26420  NDCG@10=0.32878\n",
      "\tHR@20=0.63111  MRR@20=0.27093  NDCG@20=0.35307\n",
      "[2019-12-23 09:56:11] [10/50] 0 mean_batch_loss : 5.229735\n",
      "Start predicting 2019-12-23 09:56:24\n",
      "change best\n",
      "testing finish [2019-12-23 09:56:27] \n",
      "\tHR@1=0.15054  MRR@1=0.15054  NDCG@1=0.15054\n",
      "\tHR@5=0.42724  MRR@5=0.25340  NDCG@5=0.29672\n",
      "\tHR@10=0.54837  MRR@10=0.26972  NDCG@10=0.33605\n",
      "\tHR@20=0.64546  MRR@20=0.27655  NDCG@20=0.36071\n",
      "[2019-12-23 09:56:28] [11/50] 0 mean_batch_loss : 4.992107\n",
      "Start predicting 2019-12-23 09:56:40\n",
      "change best\n",
      "testing finish [2019-12-23 09:56:44] \n",
      "\tHR@1=0.15183  MRR@1=0.15183  NDCG@1=0.15183\n",
      "\tHR@5=0.43476  MRR@5=0.25695  NDCG@5=0.30127\n",
      "\tHR@10=0.55786  MRR@10=0.27350  NDCG@10=0.34119\n",
      "\tHR@20=0.65605  MRR@20=0.28042  NDCG@20=0.36615\n",
      "[2019-12-23 09:56:44] [12/50] 0 mean_batch_loss : 5.054518\n",
      "Start predicting 2019-12-23 09:56:56\n",
      "change best\n",
      "testing finish [2019-12-23 09:57:00] \n",
      "\tHR@1=0.15314  MRR@1=0.15314  NDCG@1=0.15314\n",
      "\tHR@5=0.43939  MRR@5=0.25948  NDCG@5=0.30433\n",
      "\tHR@10=0.56544  MRR@10=0.27649  NDCG@10=0.34527\n",
      "\tHR@20=0.66519  MRR@20=0.28349  NDCG@20=0.37059\n",
      "[2019-12-23 09:57:00] [13/50] 0 mean_batch_loss : 4.818284\n",
      "Start predicting 2019-12-23 09:57:14\n",
      "change best\n",
      "testing finish [2019-12-23 09:57:17] \n",
      "\tHR@1=0.15383  MRR@1=0.15383  NDCG@1=0.15383\n",
      "\tHR@5=0.44547  MRR@5=0.26201  NDCG@5=0.30772\n",
      "\tHR@10=0.57170  MRR@10=0.27898  NDCG@10=0.34867\n",
      "\tHR@20=0.67357  MRR@20=0.28616  NDCG@20=0.37456\n",
      "[2019-12-23 09:57:18] [14/50] 0 mean_batch_loss : 4.551120\n",
      "Start predicting 2019-12-23 09:57:31\n",
      "change best\n",
      "testing finish [2019-12-23 09:57:34] \n",
      "\tHR@1=0.15677  MRR@1=0.15677  NDCG@1=0.15677\n",
      "\tHR@5=0.44919  MRR@5=0.26491  NDCG@5=0.31083\n",
      "\tHR@10=0.57689  MRR@10=0.28214  NDCG@10=0.35230\n",
      "\tHR@20=0.67926  MRR@20=0.28936  NDCG@20=0.37834\n",
      "[2019-12-23 09:57:35] [15/50] 0 mean_batch_loss : 4.562739\n",
      "Start predicting 2019-12-23 09:57:47\n",
      "change best\n",
      "testing finish [2019-12-23 09:57:51] \n",
      "\tHR@1=0.15761  MRR@1=0.15761  NDCG@1=0.15761\n",
      "\tHR@5=0.45354  MRR@5=0.26688  NDCG@5=0.31337\n",
      "\tHR@10=0.58167  MRR@10=0.28419  NDCG@10=0.35501\n",
      "\tHR@20=0.68362  MRR@20=0.29139  NDCG@20=0.38095\n",
      "[2019-12-23 09:57:51] [16/50] 0 mean_batch_loss : 4.641008\n",
      "Start predicting 2019-12-23 09:58:03\n",
      "change best\n",
      "testing finish [2019-12-23 09:58:07] \n",
      "\tHR@1=0.15820  MRR@1=0.15820  NDCG@1=0.15820\n",
      "\tHR@5=0.45744  MRR@5=0.26862  NDCG@5=0.31563\n",
      "\tHR@10=0.58521  MRR@10=0.28583  NDCG@10=0.35711\n",
      "\tHR@20=0.68795  MRR@20=0.29309  NDCG@20=0.38325\n",
      "[2019-12-23 09:58:07] [17/50] 0 mean_batch_loss : 4.433512\n",
      "Start predicting 2019-12-23 09:58:19\n",
      "change best\n",
      "testing finish [2019-12-23 09:58:23] \n",
      "\tHR@1=0.15977  MRR@1=0.15977  NDCG@1=0.15977\n",
      "\tHR@5=0.45918  MRR@5=0.27005  NDCG@5=0.31714\n",
      "\tHR@10=0.58938  MRR@10=0.28758  NDCG@10=0.35939\n",
      "\tHR@20=0.69144  MRR@20=0.29479  NDCG@20=0.38536\n",
      "[2019-12-23 09:58:23] [18/50] 0 mean_batch_loss : 4.481375\n",
      "Start predicting 2019-12-23 09:58:36\n",
      "change best\n",
      "testing finish [2019-12-23 09:58:40] \n",
      "\tHR@1=0.16042  MRR@1=0.16042  NDCG@1=0.16042\n",
      "\tHR@5=0.46161  MRR@5=0.27157  NDCG@5=0.31891\n",
      "\tHR@10=0.59183  MRR@10=0.28911  NDCG@10=0.36118\n",
      "\tHR@20=0.69432  MRR@20=0.29636  NDCG@20=0.38726\n",
      "[2019-12-23 09:58:40] [19/50] 0 mean_batch_loss : 4.187540\n",
      "Start predicting 2019-12-23 09:58:52\n",
      "change best\n",
      "testing finish [2019-12-23 09:58:56] \n",
      "\tHR@1=0.15984  MRR@1=0.15984  NDCG@1=0.15984\n",
      "\tHR@5=0.46442  MRR@5=0.27206  NDCG@5=0.31996\n",
      "\tHR@10=0.59430  MRR@10=0.28953  NDCG@10=0.36209\n",
      "\tHR@20=0.69672  MRR@20=0.29677  NDCG@20=0.38815\n",
      "[2019-12-23 09:58:56] [20/50] 0 mean_batch_loss : 4.139911\n",
      "Start predicting 2019-12-23 09:59:09\n",
      "change best\n",
      "testing finish [2019-12-23 09:59:12] \n",
      "\tHR@1=0.16181  MRR@1=0.16181  NDCG@1=0.16181\n",
      "\tHR@5=0.46510  MRR@5=0.27341  NDCG@5=0.32114\n",
      "\tHR@10=0.59732  MRR@10=0.29118  NDCG@10=0.36402\n",
      "\tHR@20=0.69913  MRR@20=0.29837  NDCG@20=0.38991\n",
      "[2019-12-23 09:59:12] [21/50] 0 mean_batch_loss : 4.326814\n",
      "Start predicting 2019-12-23 09:59:26\n",
      "change best\n",
      "testing finish [2019-12-23 09:59:30] \n",
      "\tHR@1=0.16029  MRR@1=0.16029  NDCG@1=0.16029\n",
      "\tHR@5=0.46608  MRR@5=0.27285  NDCG@5=0.32096\n",
      "\tHR@10=0.59802  MRR@10=0.29061  NDCG@10=0.36378\n",
      "\tHR@20=0.70101  MRR@20=0.29790  NDCG@20=0.39000\n",
      "[2019-12-23 09:59:30] [22/50] 0 mean_batch_loss : 4.342696\n",
      "Start predicting 2019-12-23 09:59:43\n",
      "change best\n",
      "testing finish [2019-12-23 09:59:47] \n",
      "\tHR@1=0.16017  MRR@1=0.16017  NDCG@1=0.16017\n",
      "\tHR@5=0.46694  MRR@5=0.27345  NDCG@5=0.32164\n",
      "\tHR@10=0.59929  MRR@10=0.29126  NDCG@10=0.36459\n",
      "\tHR@20=0.70264  MRR@20=0.29858  NDCG@20=0.39090\n",
      "[2019-12-23 09:59:47] [23/50] 0 mean_batch_loss : 4.333587\n",
      "Start predicting 2019-12-23 09:59:59\n",
      "change best\n",
      "testing finish [2019-12-23 10:00:03] \n",
      "\tHR@1=0.16239  MRR@1=0.16239  NDCG@1=0.16239\n",
      "\tHR@5=0.46900  MRR@5=0.27492  NDCG@5=0.32322\n",
      "\tHR@10=0.60156  MRR@10=0.29275  NDCG@10=0.36623\n",
      "\tHR@20=0.70462  MRR@20=0.30004  NDCG@20=0.39246\n",
      "[2019-12-23 10:00:03] [24/50] 0 mean_batch_loss : 4.122229\n",
      "Start predicting 2019-12-23 10:00:16\n",
      "change best\n",
      "testing finish [2019-12-23 10:00:19] \n",
      "\tHR@1=0.16255  MRR@1=0.16255  NDCG@1=0.16255\n",
      "\tHR@5=0.47154  MRR@5=0.27595  NDCG@5=0.32463\n",
      "\tHR@10=0.60247  MRR@10=0.29352  NDCG@10=0.36706\n",
      "\tHR@20=0.70582  MRR@20=0.30083  NDCG@20=0.39337\n",
      "[2019-12-23 10:00:20] [25/50] 0 mean_batch_loss : 4.233634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 10:00:32\n",
      "change best\n",
      "testing finish [2019-12-23 10:00:36] \n",
      "\tHR@1=0.16378  MRR@1=0.16378  NDCG@1=0.16378\n",
      "\tHR@5=0.47191  MRR@5=0.27705  NDCG@5=0.32557\n",
      "\tHR@10=0.60322  MRR@10=0.29470  NDCG@10=0.36815\n",
      "\tHR@20=0.70702  MRR@20=0.30206  NDCG@20=0.39459\n",
      "[2019-12-23 10:00:36] [26/50] 0 mean_batch_loss : 4.118276\n",
      "Start predicting 2019-12-23 10:00:48\n",
      "change best\n",
      "testing finish [2019-12-23 10:00:52] \n",
      "\tHR@1=0.16366  MRR@1=0.16366  NDCG@1=0.16366\n",
      "\tHR@5=0.47114  MRR@5=0.27646  NDCG@5=0.32492\n",
      "\tHR@10=0.60446  MRR@10=0.29439  NDCG@10=0.36817\n",
      "\tHR@20=0.70747  MRR@20=0.30170  NDCG@20=0.39441\n",
      "[2019-12-23 10:00:52] [27/50] 0 mean_batch_loss : 4.108572\n",
      "Start predicting 2019-12-23 10:01:05\n",
      "change best\n",
      "testing finish [2019-12-23 10:01:08] \n",
      "\tHR@1=0.16262  MRR@1=0.16262  NDCG@1=0.16262\n",
      "\tHR@5=0.47200  MRR@5=0.27649  NDCG@5=0.32517\n",
      "\tHR@10=0.60478  MRR@10=0.29432  NDCG@10=0.36821\n",
      "\tHR@20=0.70895  MRR@20=0.30170  NDCG@20=0.39475\n",
      "[2019-12-23 10:01:09] [28/50] 0 mean_batch_loss : 4.116536\n",
      "Start predicting 2019-12-23 10:01:21\n",
      "change best\n",
      "testing finish [2019-12-23 10:01:25] \n",
      "\tHR@1=0.16473  MRR@1=0.16473  NDCG@1=0.16473\n",
      "\tHR@5=0.47311  MRR@5=0.27741  NDCG@5=0.32610\n",
      "\tHR@10=0.60514  MRR@10=0.29514  NDCG@10=0.36889\n",
      "\tHR@20=0.70899  MRR@20=0.30251  NDCG@20=0.39535\n",
      "[2019-12-23 10:01:25] [29/50] 0 mean_batch_loss : 4.044630\n",
      "Start predicting 2019-12-23 10:01:38\n",
      "change best\n",
      "testing finish [2019-12-23 10:01:42] \n",
      "\tHR@1=0.16496  MRR@1=0.16496  NDCG@1=0.16496\n",
      "\tHR@5=0.47474  MRR@5=0.27833  NDCG@5=0.32720\n",
      "\tHR@10=0.60660  MRR@10=0.29604  NDCG@10=0.36995\n",
      "\tHR@20=0.71067  MRR@20=0.30340  NDCG@20=0.39644\n",
      "[2019-12-23 10:01:42] [30/50] 0 mean_batch_loss : 4.091710\n",
      "Start predicting 2019-12-23 10:01:56\n",
      "change best\n",
      "testing finish [2019-12-23 10:01:59] \n",
      "\tHR@1=0.16484  MRR@1=0.16484  NDCG@1=0.16484\n",
      "\tHR@5=0.47325  MRR@5=0.27832  NDCG@5=0.32686\n",
      "\tHR@10=0.60711  MRR@10=0.29631  NDCG@10=0.37028\n",
      "\tHR@20=0.71124  MRR@20=0.30370  NDCG@20=0.39680\n",
      "[2019-12-23 10:02:00] [31/50] 0 mean_batch_loss : 4.020726\n",
      "Start predicting 2019-12-23 10:02:12\n",
      "change best\n",
      "testing finish [2019-12-23 10:02:16] \n",
      "\tHR@1=0.16475  MRR@1=0.16475  NDCG@1=0.16475\n",
      "\tHR@5=0.47517  MRR@5=0.27857  NDCG@5=0.32750\n",
      "\tHR@10=0.60848  MRR@10=0.29645  NDCG@10=0.37070\n",
      "\tHR@20=0.71133  MRR@20=0.30373  NDCG@20=0.39689\n",
      "[2019-12-23 10:02:16] [32/50] 0 mean_batch_loss : 4.135042\n",
      "Start predicting 2019-12-23 10:02:28\n",
      "change best\n",
      "testing finish [2019-12-23 10:02:32] \n",
      "\tHR@1=0.16498  MRR@1=0.16498  NDCG@1=0.16498\n",
      "\tHR@5=0.47401  MRR@5=0.27844  NDCG@5=0.32713\n",
      "\tHR@10=0.60780  MRR@10=0.29646  NDCG@10=0.37055\n",
      "\tHR@20=0.71198  MRR@20=0.30384  NDCG@20=0.39708\n",
      "[2019-12-23 10:02:32] [33/50] 0 mean_batch_loss : 4.179839\n",
      "Start predicting 2019-12-23 10:02:42\n",
      "change best\n",
      "testing finish [2019-12-23 10:02:46] \n",
      "\tHR@1=0.16544  MRR@1=0.16544  NDCG@1=0.16544\n",
      "\tHR@5=0.47515  MRR@5=0.27900  NDCG@5=0.32782\n",
      "\tHR@10=0.60875  MRR@10=0.29696  NDCG@10=0.37115\n",
      "\tHR@20=0.71291  MRR@20=0.30435  NDCG@20=0.39770\n",
      "[2019-12-23 10:02:46] [34/50] 0 mean_batch_loss : 3.924983\n",
      "Start predicting 2019-12-23 10:02:52\n",
      "change best\n",
      "testing finish [2019-12-23 10:02:56] \n",
      "\tHR@1=0.16509  MRR@1=0.16509  NDCG@1=0.16509\n",
      "\tHR@5=0.47630  MRR@5=0.27928  NDCG@5=0.32831\n",
      "\tHR@10=0.60963  MRR@10=0.29711  NDCG@10=0.37147\n",
      "\tHR@20=0.71353  MRR@20=0.30449  NDCG@20=0.39794\n",
      "[2019-12-23 10:02:56] [35/50] 0 mean_batch_loss : 4.119326\n",
      "Start predicting 2019-12-23 10:03:02\n",
      "change best\n",
      "testing finish [2019-12-23 10:03:06] \n",
      "\tHR@1=0.16639  MRR@1=0.16639  NDCG@1=0.16639\n",
      "\tHR@5=0.47528  MRR@5=0.27971  NDCG@5=0.32839\n",
      "\tHR@10=0.61015  MRR@10=0.29786  NDCG@10=0.37215\n",
      "\tHR@20=0.71373  MRR@20=0.30522  NDCG@20=0.39856\n",
      "[2019-12-23 10:03:06] [36/50] 0 mean_batch_loss : 3.973091\n",
      "Start predicting 2019-12-23 10:03:12\n",
      "change best\n",
      "testing finish [2019-12-23 10:03:16] \n",
      "\tHR@1=0.16693  MRR@1=0.16693  NDCG@1=0.16693\n",
      "\tHR@5=0.47583  MRR@5=0.27999  NDCG@5=0.32872\n",
      "\tHR@10=0.61086  MRR@10=0.29814  NDCG@10=0.37252\n",
      "\tHR@20=0.71375  MRR@20=0.30545  NDCG@20=0.39875\n",
      "[2019-12-23 10:03:16] [37/50] 0 mean_batch_loss : 4.023469\n",
      "Start predicting 2019-12-23 10:03:22\n",
      "change best\n",
      "testing finish [2019-12-23 10:03:26] \n",
      "\tHR@1=0.16750  MRR@1=0.16750  NDCG@1=0.16750\n",
      "\tHR@5=0.47667  MRR@5=0.28054  NDCG@5=0.32934\n",
      "\tHR@10=0.61245  MRR@10=0.29873  NDCG@10=0.37332\n",
      "\tHR@20=0.71503  MRR@20=0.30599  NDCG@20=0.39943\n",
      "[2019-12-23 10:03:26] [38/50] 0 mean_batch_loss : 3.979290\n",
      "Start predicting 2019-12-23 10:03:32\n",
      "testing finish [2019-12-23 10:03:36] \n",
      "\tHR@1=0.16730  MRR@1=0.16730  NDCG@1=0.16730\n",
      "\tHR@5=0.47648  MRR@5=0.28032  NDCG@5=0.32913\n",
      "\tHR@10=0.61242  MRR@10=0.29860  NDCG@10=0.37322\n",
      "\tHR@20=0.71475  MRR@20=0.30586  NDCG@20=0.39930\n",
      "[2019-12-23 10:03:36] [39/50] 0 mean_batch_loss : 3.733793\n",
      "Start predicting 2019-12-23 10:03:42\n",
      "change best\n",
      "testing finish [2019-12-23 10:03:46] \n",
      "\tHR@1=0.16645  MRR@1=0.16645  NDCG@1=0.16645\n",
      "\tHR@5=0.47810  MRR@5=0.28028  NDCG@5=0.32949\n",
      "\tHR@10=0.61194  MRR@10=0.29823  NDCG@10=0.37286\n",
      "\tHR@20=0.71559  MRR@20=0.30558  NDCG@20=0.39926\n",
      "[2019-12-23 10:03:46] [40/50] 0 mean_batch_loss : 3.750776\n",
      "Start predicting 2019-12-23 10:03:52\n",
      "change best\n",
      "testing finish [2019-12-23 10:03:56] \n",
      "\tHR@1=0.16696  MRR@1=0.16696  NDCG@1=0.16696\n",
      "\tHR@5=0.47660  MRR@5=0.28040  NDCG@5=0.32923\n",
      "\tHR@10=0.61201  MRR@10=0.29862  NDCG@10=0.37317\n",
      "\tHR@20=0.71645  MRR@20=0.30603  NDCG@20=0.39978\n",
      "[2019-12-23 10:03:56] [41/50] 0 mean_batch_loss : 3.845798\n",
      "Start predicting 2019-12-23 10:04:02\n",
      "testing finish [2019-12-23 10:04:06] \n",
      "\tHR@1=0.16666  MRR@1=0.16666  NDCG@1=0.16666\n",
      "\tHR@5=0.47767  MRR@5=0.28055  NDCG@5=0.32960\n",
      "\tHR@10=0.61224  MRR@10=0.29866  NDCG@10=0.37327\n",
      "\tHR@20=0.71591  MRR@20=0.30601  NDCG@20=0.39968\n",
      "[2019-12-23 10:04:06] [42/50] 0 mean_batch_loss : 3.820857\n",
      "Start predicting 2019-12-23 10:04:12\n",
      "change best\n",
      "testing finish [2019-12-23 10:04:16] \n",
      "\tHR@1=0.16743  MRR@1=0.16743  NDCG@1=0.16743\n",
      "\tHR@5=0.47783  MRR@5=0.28081  NDCG@5=0.32982\n",
      "\tHR@10=0.61297  MRR@10=0.29892  NDCG@10=0.37360\n",
      "\tHR@20=0.71654  MRR@20=0.30627  NDCG@20=0.39998\n",
      "[2019-12-23 10:04:16] [43/50] 0 mean_batch_loss : 3.785712\n",
      "Start predicting 2019-12-23 10:04:22\n",
      "change best\n",
      "testing finish [2019-12-23 10:04:26] \n",
      "\tHR@1=0.16718  MRR@1=0.16718  NDCG@1=0.16718\n",
      "\tHR@5=0.47782  MRR@5=0.28094  NDCG@5=0.32994\n",
      "\tHR@10=0.61303  MRR@10=0.29913  NDCG@10=0.37381\n",
      "\tHR@20=0.71672  MRR@20=0.30650  NDCG@20=0.40024\n",
      "[2019-12-23 10:04:26] [44/50] 0 mean_batch_loss : 4.107102\n",
      "Start predicting 2019-12-23 10:04:32\n",
      "change best\n",
      "testing finish [2019-12-23 10:04:36] \n",
      "\tHR@1=0.16763  MRR@1=0.16763  NDCG@1=0.16763\n",
      "\tHR@5=0.47862  MRR@5=0.28137  NDCG@5=0.33045\n",
      "\tHR@10=0.61287  MRR@10=0.29937  NDCG@10=0.37394\n",
      "\tHR@20=0.71707  MRR@20=0.30676  NDCG@20=0.40049\n",
      "[2019-12-23 10:04:36] [45/50] 0 mean_batch_loss : 3.870020\n",
      "Start predicting 2019-12-23 10:04:42\n",
      "change best\n",
      "testing finish [2019-12-23 10:04:46] \n",
      "\tHR@1=0.16777  MRR@1=0.16777  NDCG@1=0.16777\n",
      "\tHR@5=0.47814  MRR@5=0.28134  NDCG@5=0.33031\n",
      "\tHR@10=0.61224  MRR@10=0.29941  NDCG@10=0.37384\n",
      "\tHR@20=0.71772  MRR@20=0.30690  NDCG@20=0.40073\n",
      "[2019-12-23 10:04:46] [46/50] 0 mean_batch_loss : 3.766788\n",
      "Start predicting 2019-12-23 10:04:52\n",
      "change best\n",
      "testing finish [2019-12-23 10:04:55] \n",
      "\tHR@1=0.16854  MRR@1=0.16854  NDCG@1=0.16854\n",
      "\tHR@5=0.47848  MRR@5=0.28191  NDCG@5=0.33083\n",
      "\tHR@10=0.61235  MRR@10=0.29995  NDCG@10=0.37429\n",
      "\tHR@20=0.71747  MRR@20=0.30742  NDCG@20=0.40108\n",
      "[2019-12-23 10:04:55] [47/50] 0 mean_batch_loss : 3.959487\n",
      "Start predicting 2019-12-23 10:05:02\n",
      "testing finish [2019-12-23 10:05:05] \n",
      "\tHR@1=0.16713  MRR@1=0.16713  NDCG@1=0.16713\n",
      "\tHR@5=0.47995  MRR@5=0.28148  NDCG@5=0.33086\n",
      "\tHR@10=0.61326  MRR@10=0.29937  NDCG@10=0.37406\n",
      "\tHR@20=0.71799  MRR@20=0.30677  NDCG@20=0.40071\n",
      "[2019-12-23 10:05:05] [48/50] 0 mean_batch_loss : 3.942329\n",
      "Start predicting 2019-12-23 10:05:12\n",
      "change best\n",
      "testing finish [2019-12-23 10:05:15] \n",
      "\tHR@1=0.16861  MRR@1=0.16861  NDCG@1=0.16861\n",
      "\tHR@5=0.47814  MRR@5=0.28208  NDCG@5=0.33087\n",
      "\tHR@10=0.61392  MRR@10=0.30036  NDCG@10=0.37494\n",
      "\tHR@20=0.71829  MRR@20=0.30775  NDCG@20=0.40152\n",
      "[2019-12-23 10:05:15] [49/50] 0 mean_batch_loss : 3.875238\n",
      "Start predicting 2019-12-23 10:05:22\n",
      "testing finish [2019-12-23 10:05:25] \n",
      "\tHR@1=0.16863  MRR@1=0.16863  NDCG@1=0.16863\n",
      "\tHR@5=0.47918  MRR@5=0.28202  NDCG@5=0.33107\n",
      "\tHR@10=0.61424  MRR@10=0.30016  NDCG@10=0.37486\n",
      "\tHR@20=0.71843  MRR@20=0.30755  NDCG@20=0.40139\n",
      "[2019-12-23 10:05:25] [50/50] 0 mean_batch_loss : 3.850985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 10:05:32\n",
      "change best\n",
      "testing finish [2019-12-23 10:05:35] \n",
      "\tHR@1=0.16967  MRR@1=0.16967  NDCG@1=0.16967\n",
      "\tHR@5=0.48025  MRR@5=0.28289  NDCG@5=0.33197\n",
      "\tHR@10=0.61364  MRR@10=0.30081  NDCG@10=0.37522\n",
      "\tHR@20=0.71838  MRR@20=0.30824  NDCG@20=0.40191\n",
      "best model change\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0003, amsgrad=True, method=general, dropout=0.3, weight_decay=0.000000. \n",
      "\n",
      "current model HR@20=0.71838  MRR@20=0.30824.\n",
      "the best result so far. HR@20=0.71838  MRR@20=0.30824， hyper-parameters: session_length-20, hidden_size-100, lr-0.0003 , amsgrad-True, method-general, dropout-0.3, weight_decay-0.000000. \n",
      "\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0005, amsgrad=True, method=general, dropout=0.3, weight_decay=0.000000. \n",
      "\n",
      "[2019-12-23 10:05:35] [1/50] 0 mean_batch_loss : 38.193760\n",
      "Start predicting 2019-12-23 10:05:42\n",
      "change best\n",
      "testing finish [2019-12-23 10:05:45] \n",
      "\tHR@1=0.03387  MRR@1=0.03387  NDCG@1=0.03387\n",
      "\tHR@5=0.08505  MRR@5=0.05195  NDCG@5=0.06014\n",
      "\tHR@10=0.11328  MRR@10=0.05570  NDCG@10=0.06925\n",
      "\tHR@20=0.15754  MRR@20=0.05870  NDCG@20=0.08034\n",
      "[2019-12-23 10:05:45] [2/50] 0 mean_batch_loss : 7.828574\n",
      "Start predicting 2019-12-23 10:05:51\n",
      "change best\n",
      "testing finish [2019-12-23 10:05:55] \n",
      "\tHR@1=0.11703  MRR@1=0.11703  NDCG@1=0.11703\n",
      "\tHR@5=0.25954  MRR@5=0.16936  NDCG@5=0.19179\n",
      "\tHR@10=0.32541  MRR@10=0.17820  NDCG@10=0.21314\n",
      "\tHR@20=0.39093  MRR@20=0.18271  NDCG@20=0.22966\n",
      "[2019-12-23 10:05:55] [3/50] 0 mean_batch_loss : 6.956260\n",
      "Start predicting 2019-12-23 10:06:01\n",
      "change best\n",
      "testing finish [2019-12-23 10:06:05] \n",
      "\tHR@1=0.13530  MRR@1=0.13530  NDCG@1=0.13530\n",
      "\tHR@5=0.34581  MRR@5=0.21359  NDCG@5=0.24654\n",
      "\tHR@10=0.43748  MRR@10=0.22588  NDCG@10=0.27624\n",
      "\tHR@20=0.53038  MRR@20=0.23237  NDCG@20=0.29979\n",
      "[2019-12-23 10:06:05] [4/50] 0 mean_batch_loss : 6.085354\n",
      "Start predicting 2019-12-23 10:06:11\n",
      "change best\n",
      "testing finish [2019-12-23 10:06:15] \n",
      "\tHR@1=0.14342  MRR@1=0.14342  NDCG@1=0.14342\n",
      "\tHR@5=0.39284  MRR@5=0.23642  NDCG@5=0.27542\n",
      "\tHR@10=0.50415  MRR@10=0.25133  NDCG@10=0.31147\n",
      "\tHR@20=0.59934  MRR@20=0.25798  NDCG@20=0.33560\n",
      "[2019-12-23 10:06:15] [5/50] 0 mean_batch_loss : 5.603332\n",
      "Start predicting 2019-12-23 10:06:21\n",
      "change best\n",
      "testing finish [2019-12-23 10:06:25] \n",
      "\tHR@1=0.14918  MRR@1=0.14918  NDCG@1=0.14918\n",
      "\tHR@5=0.42134  MRR@5=0.25072  NDCG@5=0.29327\n",
      "\tHR@10=0.53914  MRR@10=0.26649  NDCG@10=0.33141\n",
      "\tHR@20=0.63789  MRR@20=0.27342  NDCG@20=0.35648\n",
      "[2019-12-23 10:06:25] [6/50] 0 mean_batch_loss : 5.360992\n",
      "Start predicting 2019-12-23 10:06:31\n",
      "change best\n",
      "testing finish [2019-12-23 10:06:35] \n",
      "\tHR@1=0.15435  MRR@1=0.15435  NDCG@1=0.15435\n",
      "\tHR@5=0.43869  MRR@5=0.25954  NDCG@5=0.30416\n",
      "\tHR@10=0.55952  MRR@10=0.27576  NDCG@10=0.34333\n",
      "\tHR@20=0.65942  MRR@20=0.28280  NDCG@20=0.36872\n",
      "[2019-12-23 10:06:35] [7/50] 0 mean_batch_loss : 4.782475\n",
      "Start predicting 2019-12-23 10:06:41\n",
      "change best\n",
      "testing finish [2019-12-23 10:06:45] \n",
      "\tHR@1=0.15628  MRR@1=0.15628  NDCG@1=0.15628\n",
      "\tHR@5=0.44817  MRR@5=0.26466  NDCG@5=0.31039\n",
      "\tHR@10=0.57381  MRR@10=0.28154  NDCG@10=0.35114\n",
      "\tHR@20=0.67219  MRR@20=0.28849  NDCG@20=0.37617\n",
      "[2019-12-23 10:06:45] [8/50] 0 mean_batch_loss : 4.884831\n",
      "Start predicting 2019-12-23 10:06:51\n",
      "change best\n",
      "testing finish [2019-12-23 10:06:55] \n",
      "\tHR@1=0.16135  MRR@1=0.16135  NDCG@1=0.16135\n",
      "\tHR@5=0.45608  MRR@5=0.26985  NDCG@5=0.31622\n",
      "\tHR@10=0.58210  MRR@10=0.28673  NDCG@10=0.35703\n",
      "\tHR@20=0.68210  MRR@20=0.29380  NDCG@20=0.38248\n",
      "[2019-12-23 10:06:55] [9/50] 0 mean_batch_loss : 4.466465\n",
      "Start predicting 2019-12-23 10:07:01\n",
      "change best\n",
      "testing finish [2019-12-23 10:07:04] \n",
      "\tHR@1=0.16072  MRR@1=0.16072  NDCG@1=0.16072\n",
      "\tHR@5=0.45952  MRR@5=0.27114  NDCG@5=0.31806\n",
      "\tHR@10=0.58947  MRR@10=0.28867  NDCG@10=0.36027\n",
      "\tHR@20=0.69049  MRR@20=0.29580  NDCG@20=0.38596\n",
      "[2019-12-23 10:07:05] [10/50] 0 mean_batch_loss : 4.336804\n",
      "Start predicting 2019-12-23 10:07:11\n",
      "change best\n",
      "testing finish [2019-12-23 10:07:14] \n",
      "\tHR@1=0.16476  MRR@1=0.16476  NDCG@1=0.16476\n",
      "\tHR@5=0.46359  MRR@5=0.27424  NDCG@5=0.32136\n",
      "\tHR@10=0.59423  MRR@10=0.29179  NDCG@10=0.36372\n",
      "\tHR@20=0.69634  MRR@20=0.29901  NDCG@20=0.38971\n",
      "[2019-12-23 10:07:14] [11/50] 0 mean_batch_loss : 4.325963\n",
      "Start predicting 2019-12-23 10:07:21\n",
      "change best\n",
      "testing finish [2019-12-23 10:07:24] \n",
      "\tHR@1=0.16432  MRR@1=0.16432  NDCG@1=0.16432\n",
      "\tHR@5=0.46667  MRR@5=0.27528  NDCG@5=0.32292\n",
      "\tHR@10=0.59718  MRR@10=0.29288  NDCG@10=0.36530\n",
      "\tHR@20=0.70040  MRR@20=0.30019  NDCG@20=0.39158\n",
      "[2019-12-23 10:07:24] [12/50] 0 mean_batch_loss : 4.438473\n",
      "Start predicting 2019-12-23 10:07:31\n",
      "change best\n",
      "testing finish [2019-12-23 10:07:34] \n",
      "\tHR@1=0.16659  MRR@1=0.16659  NDCG@1=0.16659\n",
      "\tHR@5=0.46834  MRR@5=0.27696  NDCG@5=0.32457\n",
      "\tHR@10=0.59950  MRR@10=0.29461  NDCG@10=0.36714\n",
      "\tHR@20=0.70264  MRR@20=0.30192  NDCG@20=0.39341\n",
      "[2019-12-23 10:07:34] [13/50] 0 mean_batch_loss : 4.414989\n",
      "Start predicting 2019-12-23 10:07:41\n",
      "change best\n",
      "testing finish [2019-12-23 10:07:44] \n",
      "\tHR@1=0.16720  MRR@1=0.16720  NDCG@1=0.16720\n",
      "\tHR@5=0.47143  MRR@5=0.27847  NDCG@5=0.32648\n",
      "\tHR@10=0.60149  MRR@10=0.29593  NDCG@10=0.36865\n",
      "\tHR@20=0.70528  MRR@20=0.30329  NDCG@20=0.39509\n",
      "[2019-12-23 10:07:44] [14/50] 0 mean_batch_loss : 4.230989\n",
      "Start predicting 2019-12-23 10:07:51\n",
      "change best\n",
      "testing finish [2019-12-23 10:07:54] \n",
      "\tHR@1=0.16791  MRR@1=0.16791  NDCG@1=0.16791\n",
      "\tHR@5=0.47207  MRR@5=0.27910  NDCG@5=0.32711\n",
      "\tHR@10=0.60392  MRR@10=0.29684  NDCG@10=0.36988\n",
      "\tHR@20=0.70704  MRR@20=0.30416  NDCG@20=0.39616\n",
      "[2019-12-23 10:07:54] [15/50] 0 mean_batch_loss : 3.994966\n",
      "Start predicting 2019-12-23 10:08:01\n",
      "change best\n",
      "testing finish [2019-12-23 10:08:04] \n",
      "\tHR@1=0.16845  MRR@1=0.16845  NDCG@1=0.16845\n",
      "\tHR@5=0.47224  MRR@5=0.27960  NDCG@5=0.32752\n",
      "\tHR@10=0.60449  MRR@10=0.29737  NDCG@10=0.37042\n",
      "\tHR@20=0.70902  MRR@20=0.30477  NDCG@20=0.39702\n",
      "[2019-12-23 10:08:04] [16/50] 0 mean_batch_loss : 4.179765\n",
      "Start predicting 2019-12-23 10:08:11\n",
      "change best\n",
      "testing finish [2019-12-23 10:08:14] \n",
      "\tHR@1=0.16750  MRR@1=0.16750  NDCG@1=0.16750\n",
      "\tHR@5=0.47351  MRR@5=0.27931  NDCG@5=0.32762\n",
      "\tHR@10=0.60723  MRR@10=0.29725  NDCG@10=0.37097\n",
      "\tHR@20=0.71094  MRR@20=0.30458  NDCG@20=0.39735\n",
      "[2019-12-23 10:08:14] [17/50] 0 mean_batch_loss : 4.208086\n",
      "Start predicting 2019-12-23 10:08:21\n",
      "change best\n",
      "testing finish [2019-12-23 10:08:24] \n",
      "\tHR@1=0.16863  MRR@1=0.16863  NDCG@1=0.16863\n",
      "\tHR@5=0.47413  MRR@5=0.28031  NDCG@5=0.32853\n",
      "\tHR@10=0.60755  MRR@10=0.29825  NDCG@10=0.37182\n",
      "\tHR@20=0.71096  MRR@20=0.30559  NDCG@20=0.39817\n",
      "[2019-12-23 10:08:24] [18/50] 0 mean_batch_loss : 4.126389\n",
      "Start predicting 2019-12-23 10:08:31\n",
      "change best\n",
      "testing finish [2019-12-23 10:08:34] \n",
      "\tHR@1=0.16836  MRR@1=0.16836  NDCG@1=0.16836\n",
      "\tHR@5=0.47504  MRR@5=0.28034  NDCG@5=0.32878\n",
      "\tHR@10=0.60920  MRR@10=0.29836  NDCG@10=0.37228\n",
      "\tHR@20=0.71274  MRR@20=0.30569  NDCG@20=0.39863\n",
      "[2019-12-23 10:08:34] [19/50] 0 mean_batch_loss : 3.992710\n",
      "Start predicting 2019-12-23 10:08:41\n",
      "change best\n",
      "testing finish [2019-12-23 10:08:44] \n",
      "\tHR@1=0.16983  MRR@1=0.16983  NDCG@1=0.16983\n",
      "\tHR@5=0.47522  MRR@5=0.28116  NDCG@5=0.32943\n",
      "\tHR@10=0.61006  MRR@10=0.29932  NDCG@10=0.37320\n",
      "\tHR@20=0.71486  MRR@20=0.30671  NDCG@20=0.39984\n",
      "[2019-12-23 10:08:44] [20/50] 0 mean_batch_loss : 4.028995\n",
      "Start predicting 2019-12-23 10:08:51\n",
      "testing finish [2019-12-23 10:08:54] \n",
      "\tHR@1=0.16942  MRR@1=0.16942  NDCG@1=0.16942\n",
      "\tHR@5=0.47658  MRR@5=0.28129  NDCG@5=0.32986\n",
      "\tHR@10=0.60949  MRR@10=0.29913  NDCG@10=0.37294\n",
      "\tHR@20=0.71478  MRR@20=0.30659  NDCG@20=0.39975\n",
      "[2019-12-23 10:08:54] [21/50] 0 mean_batch_loss : 3.935782\n",
      "Start predicting 2019-12-23 10:09:01\n",
      "change best\n",
      "testing finish [2019-12-23 10:09:04] \n",
      "\tHR@1=0.17129  MRR@1=0.17129  NDCG@1=0.17129\n",
      "\tHR@5=0.47821  MRR@5=0.28285  NDCG@5=0.33142\n",
      "\tHR@10=0.60991  MRR@10=0.30058  NDCG@10=0.37417\n",
      "\tHR@20=0.71579  MRR@20=0.30810  NDCG@20=0.40115\n",
      "[2019-12-23 10:09:04] [22/50] 0 mean_batch_loss : 3.774295\n",
      "Start predicting 2019-12-23 10:09:11\n",
      "change best\n",
      "testing finish [2019-12-23 10:09:14] \n",
      "\tHR@1=0.17135  MRR@1=0.17135  NDCG@1=0.17135\n",
      "\tHR@5=0.47900  MRR@5=0.28332  NDCG@5=0.33198\n",
      "\tHR@10=0.60995  MRR@10=0.30095  NDCG@10=0.37449\n",
      "\tHR@20=0.71554  MRR@20=0.30844  NDCG@20=0.40137\n",
      "[2019-12-23 10:09:14] [23/50] 0 mean_batch_loss : 3.783789\n",
      "Start predicting 2019-12-23 10:09:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change best\n",
      "testing finish [2019-12-23 10:09:24] \n",
      "\tHR@1=0.17289  MRR@1=0.17289  NDCG@1=0.17289\n",
      "\tHR@5=0.47835  MRR@5=0.28369  NDCG@5=0.33208\n",
      "\tHR@10=0.61004  MRR@10=0.30143  NDCG@10=0.37482\n",
      "\tHR@20=0.71591  MRR@20=0.30893  NDCG@20=0.40179\n",
      "[2019-12-23 10:09:24] [24/50] 0 mean_batch_loss : 3.955426\n",
      "Start predicting 2019-12-23 10:09:31\n",
      "change best\n",
      "testing finish [2019-12-23 10:09:34] \n",
      "\tHR@1=0.17239  MRR@1=0.17239  NDCG@1=0.17239\n",
      "\tHR@5=0.47887  MRR@5=0.28367  NDCG@5=0.33220\n",
      "\tHR@10=0.61110  MRR@10=0.30145  NDCG@10=0.37509\n",
      "\tHR@20=0.71664  MRR@20=0.30894  NDCG@20=0.40199\n",
      "[2019-12-23 10:09:34] [25/50] 0 mean_batch_loss : 3.955344\n",
      "Start predicting 2019-12-23 10:09:41\n",
      "change best\n",
      "testing finish [2019-12-23 10:09:44] \n",
      "\tHR@1=0.17496  MRR@1=0.17496  NDCG@1=0.17496\n",
      "\tHR@5=0.47751  MRR@5=0.28485  NDCG@5=0.33276\n",
      "\tHR@10=0.61229  MRR@10=0.30305  NDCG@10=0.37655\n",
      "\tHR@20=0.71795  MRR@20=0.31052  NDCG@20=0.40344\n",
      "[2019-12-23 10:09:44] [26/50] 0 mean_batch_loss : 3.809392\n",
      "Start predicting 2019-12-23 10:09:51\n",
      "testing finish [2019-12-23 10:09:54] \n",
      "\tHR@1=0.17190  MRR@1=0.17190  NDCG@1=0.17190\n",
      "\tHR@5=0.47912  MRR@5=0.28382  NDCG@5=0.33239\n",
      "\tHR@10=0.61237  MRR@10=0.30178  NDCG@10=0.37566\n",
      "\tHR@20=0.71836  MRR@20=0.30927  NDCG@20=0.40263\n",
      "[2019-12-23 10:09:54] [27/50] 0 mean_batch_loss : 3.721620\n",
      "Start predicting 2019-12-23 10:10:01\n",
      "testing finish [2019-12-23 10:10:04] \n",
      "\tHR@1=0.17400  MRR@1=0.17400  NDCG@1=0.17400\n",
      "\tHR@5=0.47830  MRR@5=0.28452  NDCG@5=0.33270\n",
      "\tHR@10=0.61294  MRR@10=0.30271  NDCG@10=0.37646\n",
      "\tHR@20=0.71752  MRR@20=0.31012  NDCG@20=0.40309\n",
      "[2019-12-23 10:10:04] [28/50] 0 mean_batch_loss : 3.523804\n",
      "Start predicting 2019-12-23 10:10:11\n",
      "change best\n",
      "testing finish [2019-12-23 10:10:14] \n",
      "\tHR@1=0.17435  MRR@1=0.17435  NDCG@1=0.17435\n",
      "\tHR@5=0.47980  MRR@5=0.28533  NDCG@5=0.33368\n",
      "\tHR@10=0.61312  MRR@10=0.30330  NDCG@10=0.37697\n",
      "\tHR@20=0.71960  MRR@20=0.31081  NDCG@20=0.40404\n",
      "[2019-12-23 10:10:14] [29/50] 0 mean_batch_loss : 3.898788\n",
      "Start predicting 2019-12-23 10:10:21\n",
      "testing finish [2019-12-23 10:10:24] \n",
      "\tHR@1=0.17434  MRR@1=0.17434  NDCG@1=0.17434\n",
      "\tHR@5=0.47982  MRR@5=0.28523  NDCG@5=0.33360\n",
      "\tHR@10=0.61439  MRR@10=0.30334  NDCG@10=0.37728\n",
      "\tHR@20=0.71927  MRR@20=0.31075  NDCG@20=0.40395\n",
      "[2019-12-23 10:10:24] [30/50] 0 mean_batch_loss : 3.926157\n",
      "Start predicting 2019-12-23 10:10:31\n",
      "testing finish [2019-12-23 10:10:34] \n",
      "\tHR@1=0.17580  MRR@1=0.17580  NDCG@1=0.17580\n",
      "\tHR@5=0.47889  MRR@5=0.28564  NDCG@5=0.33367\n",
      "\tHR@10=0.61276  MRR@10=0.30366  NDCG@10=0.37712\n",
      "\tHR@20=0.71817  MRR@20=0.31114  NDCG@20=0.40397\n",
      "[2019-12-23 10:10:34] [31/50] 0 mean_batch_loss : 3.580637\n",
      "Start predicting 2019-12-23 10:10:41\n",
      "change best\n",
      "testing finish [2019-12-23 10:10:44] \n",
      "\tHR@1=0.17659  MRR@1=0.17659  NDCG@1=0.17659\n",
      "\tHR@5=0.47982  MRR@5=0.28657  NDCG@5=0.33461\n",
      "\tHR@10=0.61449  MRR@10=0.30476  NDCG@10=0.37837\n",
      "\tHR@20=0.71979  MRR@20=0.31221  NDCG@20=0.40517\n",
      "[2019-12-23 10:10:44] [32/50] 0 mean_batch_loss : 3.788904\n",
      "Start predicting 2019-12-23 10:10:51\n",
      "testing finish [2019-12-23 10:10:54] \n",
      "\tHR@1=0.17682  MRR@1=0.17682  NDCG@1=0.17682\n",
      "\tHR@5=0.47952  MRR@5=0.28614  NDCG@5=0.33418\n",
      "\tHR@10=0.61362  MRR@10=0.30419  NDCG@10=0.37770\n",
      "\tHR@20=0.71897  MRR@20=0.31164  NDCG@20=0.40452\n",
      "[2019-12-23 10:10:54] [33/50] 0 mean_batch_loss : 3.893149\n",
      "Start predicting 2019-12-23 10:11:01\n",
      "testing finish [2019-12-23 10:11:04] \n",
      "\tHR@1=0.17791  MRR@1=0.17791  NDCG@1=0.17791\n",
      "\tHR@5=0.48029  MRR@5=0.28720  NDCG@5=0.33518\n",
      "\tHR@10=0.61417  MRR@10=0.30520  NDCG@10=0.37860\n",
      "\tHR@20=0.71915  MRR@20=0.31261  NDCG@20=0.40530\n",
      "[2019-12-23 10:11:04] [34/50] 0 mean_batch_loss : 3.727952\n",
      "Start predicting 2019-12-23 10:11:11\n",
      "testing finish [2019-12-23 10:11:14] \n",
      "\tHR@1=0.17720  MRR@1=0.17720  NDCG@1=0.17720\n",
      "\tHR@5=0.48029  MRR@5=0.28680  NDCG@5=0.33488\n",
      "\tHR@10=0.61462  MRR@10=0.30485  NDCG@10=0.37844\n",
      "\tHR@20=0.71944  MRR@20=0.31224  NDCG@20=0.40509\n",
      "[2019-12-23 10:11:14] [35/50] 0 mean_batch_loss : 3.737621\n",
      "Start predicting 2019-12-23 10:11:20\n",
      "testing finish [2019-12-23 10:11:24] \n",
      "\tHR@1=0.17768  MRR@1=0.17768  NDCG@1=0.17768\n",
      "\tHR@5=0.48095  MRR@5=0.28729  NDCG@5=0.33541\n",
      "\tHR@10=0.61254  MRR@10=0.30505  NDCG@10=0.37816\n",
      "\tHR@20=0.71911  MRR@20=0.31263  NDCG@20=0.40533\n",
      "[2019-12-23 10:11:24] [36/50] 0 mean_batch_loss : 3.668217\n",
      "Start predicting 2019-12-23 10:11:30\n",
      "change best\n",
      "testing finish [2019-12-23 10:11:34] \n",
      "\tHR@1=0.17870  MRR@1=0.17870  NDCG@1=0.17870\n",
      "\tHR@5=0.48116  MRR@5=0.28815  NDCG@5=0.33611\n",
      "\tHR@10=0.61410  MRR@10=0.30604  NDCG@10=0.37925\n",
      "\tHR@20=0.71938  MRR@20=0.31348  NDCG@20=0.40603\n",
      "[2019-12-23 10:11:34] [37/50] 0 mean_batch_loss : 3.646974\n",
      "Start predicting 2019-12-23 10:11:40\n",
      "testing finish [2019-12-23 10:11:44] \n",
      "\tHR@1=0.17800  MRR@1=0.17800  NDCG@1=0.17800\n",
      "\tHR@5=0.48004  MRR@5=0.28721  NDCG@5=0.33513\n",
      "\tHR@10=0.61462  MRR@10=0.30530  NDCG@10=0.37878\n",
      "\tHR@20=0.71983  MRR@20=0.31272  NDCG@20=0.40552\n",
      "[2019-12-23 10:11:44] [38/50] 0 mean_batch_loss : 3.716861\n",
      "Start predicting 2019-12-23 10:11:50\n",
      "change best\n",
      "testing finish [2019-12-23 10:11:54] \n",
      "\tHR@1=0.17865  MRR@1=0.17865  NDCG@1=0.17865\n",
      "\tHR@5=0.47977  MRR@5=0.28778  NDCG@5=0.33550\n",
      "\tHR@10=0.61317  MRR@10=0.30579  NDCG@10=0.37885\n",
      "\tHR@20=0.71972  MRR@20=0.31334  NDCG@20=0.40598\n",
      "[2019-12-23 10:11:54] [39/50] 0 mean_batch_loss : 3.534327\n",
      "Start predicting 2019-12-23 10:12:00\n",
      "change best\n",
      "testing finish [2019-12-23 10:12:04] \n",
      "\tHR@1=0.17967  MRR@1=0.17967  NDCG@1=0.17967\n",
      "\tHR@5=0.48086  MRR@5=0.28843  NDCG@5=0.33623\n",
      "\tHR@10=0.61408  MRR@10=0.30632  NDCG@10=0.37942\n",
      "\tHR@20=0.71983  MRR@20=0.31378  NDCG@20=0.40631\n",
      "[2019-12-23 10:12:04] [40/50] 0 mean_batch_loss : 3.802929\n",
      "Start predicting 2019-12-23 10:12:10\n",
      "testing finish [2019-12-23 10:12:14] \n",
      "\tHR@1=0.17834  MRR@1=0.17834  NDCG@1=0.17834\n",
      "\tHR@5=0.48000  MRR@5=0.28756  NDCG@5=0.33538\n",
      "\tHR@10=0.61364  MRR@10=0.30557  NDCG@10=0.37877\n",
      "\tHR@20=0.72013  MRR@20=0.31308  NDCG@20=0.40585\n",
      "[2019-12-23 10:12:14] [41/50] 0 mean_batch_loss : 3.667025\n",
      "Start predicting 2019-12-23 10:12:20\n",
      "change best\n",
      "testing finish [2019-12-23 10:12:24] \n",
      "\tHR@1=0.17985  MRR@1=0.17985  NDCG@1=0.17985\n",
      "\tHR@5=0.48218  MRR@5=0.28926  NDCG@5=0.33721\n",
      "\tHR@10=0.61449  MRR@10=0.30709  NDCG@10=0.38016\n",
      "\tHR@20=0.71944  MRR@20=0.31450  NDCG@20=0.40686\n",
      "[2019-12-23 10:12:24] [42/50] 0 mean_batch_loss : 3.656698\n",
      "Start predicting 2019-12-23 10:12:30\n",
      "testing finish [2019-12-23 10:12:34] \n",
      "\tHR@1=0.17893  MRR@1=0.17893  NDCG@1=0.17893\n",
      "\tHR@5=0.48023  MRR@5=0.28783  NDCG@5=0.33564\n",
      "\tHR@10=0.61206  MRR@10=0.30561  NDCG@10=0.37846\n",
      "\tHR@20=0.71986  MRR@20=0.31322  NDCG@20=0.40587\n",
      "[2019-12-23 10:12:34] [43/50] 0 mean_batch_loss : 3.588046\n",
      "Start predicting 2019-12-23 10:12:40\n",
      "testing finish [2019-12-23 10:12:44] \n",
      "\tHR@1=0.17929  MRR@1=0.17929  NDCG@1=0.17929\n",
      "\tHR@5=0.47952  MRR@5=0.28790  NDCG@5=0.33552\n",
      "\tHR@10=0.61390  MRR@10=0.30602  NDCG@10=0.37916\n",
      "\tHR@20=0.71986  MRR@20=0.31348  NDCG@20=0.40609\n",
      "[2019-12-23 10:12:44] [44/50] 0 mean_batch_loss : 3.566940\n",
      "Start predicting 2019-12-23 10:12:50\n",
      "testing finish [2019-12-23 10:12:54] \n",
      "\tHR@1=0.18217  MRR@1=0.18217  NDCG@1=0.18217\n",
      "\tHR@5=0.48105  MRR@5=0.28997  NDCG@5=0.33744\n",
      "\tHR@10=0.61238  MRR@10=0.30765  NDCG@10=0.38005\n",
      "\tHR@20=0.71829  MRR@20=0.31514  NDCG@20=0.40700\n",
      "[2019-12-23 10:12:54] [45/50] 0 mean_batch_loss : 3.665995\n",
      "Start predicting 2019-12-23 10:13:01\n",
      "change best\n",
      "testing finish [2019-12-23 10:13:04] \n",
      "\tHR@1=0.18341  MRR@1=0.18341  NDCG@1=0.18341\n",
      "\tHR@5=0.48034  MRR@5=0.29042  NDCG@5=0.33760\n",
      "\tHR@10=0.61417  MRR@10=0.30842  NDCG@10=0.38101\n",
      "\tHR@20=0.71886  MRR@20=0.31580  NDCG@20=0.40762\n",
      "[2019-12-23 10:13:04] [46/50] 0 mean_batch_loss : 3.614001\n",
      "Start predicting 2019-12-23 10:13:11\n",
      "testing finish [2019-12-23 10:13:14] \n",
      "\tHR@1=0.18051  MRR@1=0.18051  NDCG@1=0.18051\n",
      "\tHR@5=0.47898  MRR@5=0.28866  NDCG@5=0.33596\n",
      "\tHR@10=0.61317  MRR@10=0.30673  NDCG@10=0.37952\n",
      "\tHR@20=0.71856  MRR@20=0.31417  NDCG@20=0.40632\n",
      "[2019-12-23 10:13:14] [47/50] 0 mean_batch_loss : 3.603731\n",
      "Start predicting 2019-12-23 10:13:21\n",
      "testing finish [2019-12-23 10:13:24] \n",
      "\tHR@1=0.18294  MRR@1=0.18294  NDCG@1=0.18294\n",
      "\tHR@5=0.47955  MRR@5=0.29003  NDCG@5=0.33711\n",
      "\tHR@10=0.61330  MRR@10=0.30809  NDCG@10=0.38058\n",
      "\tHR@20=0.71874  MRR@20=0.31554  NDCG@20=0.40740\n",
      "[2019-12-23 10:13:24] [48/50] 0 mean_batch_loss : 3.662775\n",
      "Start predicting 2019-12-23 10:13:31\n",
      "testing finish [2019-12-23 10:13:34] \n",
      "\tHR@1=0.18305  MRR@1=0.18305  NDCG@1=0.18305\n",
      "\tHR@5=0.48050  MRR@5=0.29033  NDCG@5=0.33757\n",
      "\tHR@10=0.61278  MRR@10=0.30808  NDCG@10=0.38043\n",
      "\tHR@20=0.71890  MRR@20=0.31553  NDCG@20=0.40738\n",
      "[2019-12-23 10:13:34] [49/50] 0 mean_batch_loss : 3.523135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 10:13:41\n",
      "testing finish [2019-12-23 10:13:44] \n",
      "\tHR@1=0.18457  MRR@1=0.18457  NDCG@1=0.18457\n",
      "\tHR@5=0.47876  MRR@5=0.29028  NDCG@5=0.33708\n",
      "\tHR@10=0.61224  MRR@10=0.30820  NDCG@10=0.38035\n",
      "\tHR@20=0.71754  MRR@20=0.31562  NDCG@20=0.40712\n",
      "[2019-12-23 10:13:44] [50/50] 0 mean_batch_loss : 3.675073\n",
      "Start predicting 2019-12-23 10:13:51\n",
      "testing finish [2019-12-23 10:13:54] \n",
      "\tHR@1=0.18471  MRR@1=0.18471  NDCG@1=0.18471\n",
      "\tHR@5=0.47910  MRR@5=0.29098  NDCG@5=0.33772\n",
      "\tHR@10=0.61240  MRR@10=0.30895  NDCG@10=0.38100\n",
      "\tHR@20=0.71774  MRR@20=0.31639  NDCG@20=0.40779\n",
      "best model change\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0005, amsgrad=True, method=general, dropout=0.3, weight_decay=0.000000. \n",
      "\n",
      "current model HR@20=0.71886  MRR@20=0.31580.\n",
      "the best result so far. HR@20=0.71886  MRR@20=0.31580， hyper-parameters: session_length-20, hidden_size-100, lr-0.0005 , amsgrad-True, method-general, dropout-0.3, weight_decay-0.000000. \n",
      "\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0010, amsgrad=True, method=general, dropout=0.3, weight_decay=0.000000. \n",
      "\n",
      "[2019-12-23 10:13:55] [1/50] 0 mean_batch_loss : 38.615108\n",
      "Start predicting 2019-12-23 10:14:01\n",
      "change best\n",
      "testing finish [2019-12-23 10:14:04] \n",
      "\tHR@1=0.10403  MRR@1=0.10403  NDCG@1=0.10403\n",
      "\tHR@5=0.22856  MRR@5=0.15003  NDCG@5=0.16958\n",
      "\tHR@10=0.29443  MRR@10=0.15860  NDCG@10=0.19066\n",
      "\tHR@20=0.36255  MRR@20=0.16334  NDCG@20=0.20790\n",
      "[2019-12-23 10:14:05] [2/50] 0 mean_batch_loss : 6.870951\n",
      "Start predicting 2019-12-23 10:14:11\n",
      "change best\n",
      "testing finish [2019-12-23 10:14:15] \n",
      "\tHR@1=0.14646  MRR@1=0.14646  NDCG@1=0.14646\n",
      "\tHR@5=0.40468  MRR@5=0.24171  NDCG@5=0.28229\n",
      "\tHR@10=0.51082  MRR@10=0.25603  NDCG@10=0.31677\n",
      "\tHR@20=0.61052  MRR@20=0.26301  NDCG@20=0.34205\n",
      "[2019-12-23 10:14:15] [3/50] 0 mean_batch_loss : 5.439197\n",
      "Start predicting 2019-12-23 10:14:21\n",
      "change best\n",
      "testing finish [2019-12-23 10:14:25] \n",
      "\tHR@1=0.15587  MRR@1=0.15587  NDCG@1=0.15587\n",
      "\tHR@5=0.44447  MRR@5=0.26265  NDCG@5=0.30794\n",
      "\tHR@10=0.56655  MRR@10=0.27902  NDCG@10=0.34750\n",
      "\tHR@20=0.66986  MRR@20=0.28630  NDCG@20=0.37376\n",
      "[2019-12-23 10:14:25] [4/50] 0 mean_batch_loss : 4.760159\n",
      "Start predicting 2019-12-23 10:14:31\n",
      "change best\n",
      "testing finish [2019-12-23 10:14:35] \n",
      "\tHR@1=0.15886  MRR@1=0.15886  NDCG@1=0.15886\n",
      "\tHR@5=0.45984  MRR@5=0.26970  NDCG@5=0.31704\n",
      "\tHR@10=0.58744  MRR@10=0.28677  NDCG@10=0.35834\n",
      "\tHR@20=0.69006  MRR@20=0.29405  NDCG@20=0.38449\n",
      "[2019-12-23 10:14:35] [5/50] 0 mean_batch_loss : 4.479285\n",
      "Start predicting 2019-12-23 10:14:41\n",
      "change best\n",
      "testing finish [2019-12-23 10:14:45] \n",
      "\tHR@1=0.16328  MRR@1=0.16328  NDCG@1=0.16328\n",
      "\tHR@5=0.46569  MRR@5=0.27431  NDCG@5=0.32195\n",
      "\tHR@10=0.59793  MRR@10=0.29213  NDCG@10=0.36488\n",
      "\tHR@20=0.70164  MRR@20=0.29950  NDCG@20=0.39131\n",
      "[2019-12-23 10:14:45] [6/50] 0 mean_batch_loss : 4.300933\n",
      "Start predicting 2019-12-23 10:14:51\n",
      "change best\n",
      "testing finish [2019-12-23 10:14:55] \n",
      "\tHR@1=0.16201  MRR@1=0.16201  NDCG@1=0.16201\n",
      "\tHR@5=0.46989  MRR@5=0.27474  NDCG@5=0.32330\n",
      "\tHR@10=0.60342  MRR@10=0.29265  NDCG@10=0.36657\n",
      "\tHR@20=0.70774  MRR@20=0.30004  NDCG@20=0.39313\n",
      "[2019-12-23 10:14:55] [7/50] 0 mean_batch_loss : 4.079992\n",
      "Start predicting 2019-12-23 10:15:01\n",
      "change best\n",
      "testing finish [2019-12-23 10:15:05] \n",
      "\tHR@1=0.16298  MRR@1=0.16298  NDCG@1=0.16298\n",
      "\tHR@5=0.47109  MRR@5=0.27592  NDCG@5=0.32449\n",
      "\tHR@10=0.60585  MRR@10=0.29402  NDCG@10=0.36818\n",
      "\tHR@20=0.71158  MRR@20=0.30152  NDCG@20=0.39512\n",
      "[2019-12-23 10:15:05] [8/50] 0 mean_batch_loss : 3.813130\n",
      "Start predicting 2019-12-23 10:15:11\n",
      "change best\n",
      "testing finish [2019-12-23 10:15:15] \n",
      "\tHR@1=0.16478  MRR@1=0.16478  NDCG@1=0.16478\n",
      "\tHR@5=0.47444  MRR@5=0.27819  NDCG@5=0.32703\n",
      "\tHR@10=0.60838  MRR@10=0.29622  NDCG@10=0.37049\n",
      "\tHR@20=0.71432  MRR@20=0.30371  NDCG@20=0.39745\n",
      "[2019-12-23 10:15:15] [9/50] 0 mean_batch_loss : 3.887090\n",
      "Start predicting 2019-12-23 10:15:21\n",
      "change best\n",
      "testing finish [2019-12-23 10:15:25] \n",
      "\tHR@1=0.16646  MRR@1=0.16646  NDCG@1=0.16646\n",
      "\tHR@5=0.47381  MRR@5=0.27870  NDCG@5=0.32724\n",
      "\tHR@10=0.60807  MRR@10=0.29681  NDCG@10=0.37085\n",
      "\tHR@20=0.71444  MRR@20=0.30431  NDCG@20=0.39789\n",
      "[2019-12-23 10:15:25] [10/50] 0 mean_batch_loss : 3.737073\n",
      "Start predicting 2019-12-23 10:15:31\n",
      "change best\n",
      "testing finish [2019-12-23 10:15:35] \n",
      "\tHR@1=0.16918  MRR@1=0.16918  NDCG@1=0.16918\n",
      "\tHR@5=0.47438  MRR@5=0.28029  NDCG@5=0.32856\n",
      "\tHR@10=0.61056  MRR@10=0.29867  NDCG@10=0.37281\n",
      "\tHR@20=0.71647  MRR@20=0.30617  NDCG@20=0.39977\n",
      "[2019-12-23 10:15:35] [11/50] 0 mean_batch_loss : 3.763222\n",
      "Start predicting 2019-12-23 10:15:41\n",
      "change best\n",
      "testing finish [2019-12-23 10:15:45] \n",
      "\tHR@1=0.17001  MRR@1=0.17001  NDCG@1=0.17001\n",
      "\tHR@5=0.47569  MRR@5=0.28121  NDCG@5=0.32957\n",
      "\tHR@10=0.60977  MRR@10=0.29919  NDCG@10=0.37301\n",
      "\tHR@20=0.71698  MRR@20=0.30679  NDCG@20=0.40032\n",
      "[2019-12-23 10:15:45] [12/50] 0 mean_batch_loss : 3.847082\n",
      "Start predicting 2019-12-23 10:15:52\n",
      "change best\n",
      "testing finish [2019-12-23 10:15:55] \n",
      "\tHR@1=0.17260  MRR@1=0.17260  NDCG@1=0.17260\n",
      "\tHR@5=0.47648  MRR@5=0.28280  NDCG@5=0.33094\n",
      "\tHR@10=0.61160  MRR@10=0.30103  NDCG@10=0.37483\n",
      "\tHR@20=0.71765  MRR@20=0.30854  NDCG@20=0.40183\n",
      "[2019-12-23 10:15:55] [13/50] 0 mean_batch_loss : 3.836968\n",
      "Start predicting 2019-12-23 10:16:02\n",
      "change best\n",
      "testing finish [2019-12-23 10:16:05] \n",
      "\tHR@1=0.17233  MRR@1=0.17233  NDCG@1=0.17233\n",
      "\tHR@5=0.47665  MRR@5=0.28282  NDCG@5=0.33101\n",
      "\tHR@10=0.61102  MRR@10=0.30097  NDCG@10=0.37468\n",
      "\tHR@20=0.71775  MRR@20=0.30853  NDCG@20=0.40186\n",
      "[2019-12-23 10:16:05] [14/50] 0 mean_batch_loss : 3.765003\n",
      "Start predicting 2019-12-23 10:16:12\n",
      "change best\n",
      "testing finish [2019-12-23 10:16:15] \n",
      "\tHR@1=0.17323  MRR@1=0.17323  NDCG@1=0.17323\n",
      "\tHR@5=0.47812  MRR@5=0.28358  NDCG@5=0.33193\n",
      "\tHR@10=0.61156  MRR@10=0.30157  NDCG@10=0.37526\n",
      "\tHR@20=0.71813  MRR@20=0.30909  NDCG@20=0.40235\n",
      "[2019-12-23 10:16:15] [15/50] 0 mean_batch_loss : 3.869300\n",
      "Start predicting 2019-12-23 10:16:22\n",
      "testing finish [2019-12-23 10:16:25] \n",
      "\tHR@1=0.17430  MRR@1=0.17430  NDCG@1=0.17430\n",
      "\tHR@5=0.47651  MRR@5=0.28349  NDCG@5=0.33144\n",
      "\tHR@10=0.60748  MRR@10=0.30117  NDCG@10=0.37399\n",
      "\tHR@20=0.71716  MRR@20=0.30892  NDCG@20=0.40190\n",
      "[2019-12-23 10:16:26] [16/50] 0 mean_batch_loss : 3.740819\n",
      "Start predicting 2019-12-23 10:16:32\n",
      "testing finish [2019-12-23 10:16:36] \n",
      "\tHR@1=0.17485  MRR@1=0.17485  NDCG@1=0.17485\n",
      "\tHR@5=0.47744  MRR@5=0.28442  NDCG@5=0.33239\n",
      "\tHR@10=0.61312  MRR@10=0.30269  NDCG@10=0.37643\n",
      "\tHR@20=0.71659  MRR@20=0.31001  NDCG@20=0.40276\n",
      "[2019-12-23 10:16:36] [17/50] 0 mean_batch_loss : 3.706017\n",
      "Start predicting 2019-12-23 10:16:42\n",
      "change best\n",
      "testing finish [2019-12-23 10:16:46] \n",
      "\tHR@1=0.17450  MRR@1=0.17450  NDCG@1=0.17450\n",
      "\tHR@5=0.47850  MRR@5=0.28452  NDCG@5=0.33272\n",
      "\tHR@10=0.61237  MRR@10=0.30261  NDCG@10=0.37624\n",
      "\tHR@20=0.71747  MRR@20=0.31000  NDCG@20=0.40293\n",
      "[2019-12-23 10:16:46] [18/50] 0 mean_batch_loss : 3.705460\n",
      "Start predicting 2019-12-23 10:16:52\n",
      "change best\n",
      "testing finish [2019-12-23 10:16:56] \n",
      "\tHR@1=0.17768  MRR@1=0.17768  NDCG@1=0.17768\n",
      "\tHR@5=0.47794  MRR@5=0.28626  NDCG@5=0.33389\n",
      "\tHR@10=0.61088  MRR@10=0.30417  NDCG@10=0.37705\n",
      "\tHR@20=0.71745  MRR@20=0.31171  NDCG@20=0.40417\n",
      "[2019-12-23 10:16:56] [19/50] 0 mean_batch_loss : 3.416160\n",
      "Start predicting 2019-12-23 10:17:08\n",
      "testing finish [2019-12-23 10:17:12] \n",
      "\tHR@1=0.17770  MRR@1=0.17770  NDCG@1=0.17770\n",
      "\tHR@5=0.47864  MRR@5=0.28577  NDCG@5=0.33366\n",
      "\tHR@10=0.61133  MRR@10=0.30359  NDCG@10=0.37668\n",
      "\tHR@20=0.71741  MRR@20=0.31108  NDCG@20=0.40366\n",
      "[2019-12-23 10:17:12] [20/50] 0 mean_batch_loss : 3.596082\n",
      "Start predicting 2019-12-23 10:17:26\n",
      "testing finish [2019-12-23 10:17:30] \n",
      "\tHR@1=0.17895  MRR@1=0.17895  NDCG@1=0.17895\n",
      "\tHR@5=0.47701  MRR@5=0.28662  NDCG@5=0.33393\n",
      "\tHR@10=0.60965  MRR@10=0.30451  NDCG@10=0.37702\n",
      "\tHR@20=0.71681  MRR@20=0.31210  NDCG@20=0.40429\n",
      "[2019-12-23 10:17:30] [21/50] 0 mean_batch_loss : 3.582357\n",
      "Start predicting 2019-12-23 10:17:43\n",
      "change best\n",
      "testing finish [2019-12-23 10:17:47] \n",
      "\tHR@1=0.18115  MRR@1=0.18115  NDCG@1=0.18115\n",
      "\tHR@5=0.47710  MRR@5=0.28785  NDCG@5=0.33485\n",
      "\tHR@10=0.61036  MRR@10=0.30574  NDCG@10=0.37805\n",
      "\tHR@20=0.71652  MRR@20=0.31324  NDCG@20=0.40507\n",
      "[2019-12-23 10:17:47] [22/50] 0 mean_batch_loss : 3.801932\n",
      "Start predicting 2019-12-23 10:18:01\n",
      "testing finish [2019-12-23 10:18:05] \n",
      "\tHR@1=0.17764  MRR@1=0.17764  NDCG@1=0.17764\n",
      "\tHR@5=0.47639  MRR@5=0.28552  NDCG@5=0.33293\n",
      "\tHR@10=0.60877  MRR@10=0.30334  NDCG@10=0.37590\n",
      "\tHR@20=0.71514  MRR@20=0.31084  NDCG@20=0.40294\n",
      "[2019-12-23 10:18:05] [23/50] 0 mean_batch_loss : 3.504148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 10:18:19\n",
      "testing finish [2019-12-23 10:18:23] \n",
      "\tHR@1=0.17929  MRR@1=0.17929  NDCG@1=0.17929\n",
      "\tHR@5=0.47594  MRR@5=0.28605  NDCG@5=0.33320\n",
      "\tHR@10=0.60773  MRR@10=0.30376  NDCG@10=0.37594\n",
      "\tHR@20=0.71439  MRR@20=0.31130  NDCG@20=0.40309\n",
      "[2019-12-23 10:18:23] [24/50] 0 mean_batch_loss : 3.574958\n",
      "Start predicting 2019-12-23 10:18:37\n",
      "testing finish [2019-12-23 10:18:41] \n",
      "\tHR@1=0.17972  MRR@1=0.17972  NDCG@1=0.17972\n",
      "\tHR@5=0.47581  MRR@5=0.28667  NDCG@5=0.33365\n",
      "\tHR@10=0.60770  MRR@10=0.30439  NDCG@10=0.37642\n",
      "\tHR@20=0.71373  MRR@20=0.31187  NDCG@20=0.40338\n",
      "[2019-12-23 10:18:41] [25/50] 0 mean_batch_loss : 3.620137\n",
      "Start predicting 2019-12-23 10:18:55\n",
      "testing finish [2019-12-23 10:18:59] \n",
      "\tHR@1=0.18144  MRR@1=0.18144  NDCG@1=0.18144\n",
      "\tHR@5=0.47687  MRR@5=0.28799  NDCG@5=0.33490\n",
      "\tHR@10=0.60732  MRR@10=0.30550  NDCG@10=0.37719\n",
      "\tHR@20=0.71405  MRR@20=0.31300  NDCG@20=0.40429\n",
      "[2019-12-23 10:18:59] [26/50] 0 mean_batch_loss : 3.619580\n",
      "Start predicting 2019-12-23 10:19:13\n",
      "testing finish [2019-12-23 10:19:17] \n",
      "\tHR@1=0.18142  MRR@1=0.18142  NDCG@1=0.18142\n",
      "\tHR@5=0.47517  MRR@5=0.28728  NDCG@5=0.33395\n",
      "\tHR@10=0.60582  MRR@10=0.30491  NDCG@10=0.37639\n",
      "\tHR@20=0.71317  MRR@20=0.31251  NDCG@20=0.40372\n",
      "[2019-12-23 10:19:17] [27/50] 0 mean_batch_loss : 3.466236\n",
      "Start predicting 2019-12-23 10:19:31\n",
      "testing finish [2019-12-23 10:19:35] \n",
      "\tHR@1=0.18274  MRR@1=0.18274  NDCG@1=0.18274\n",
      "\tHR@5=0.47619  MRR@5=0.28793  NDCG@5=0.33465\n",
      "\tHR@10=0.60580  MRR@10=0.30538  NDCG@10=0.37672\n",
      "\tHR@20=0.71176  MRR@20=0.31288  NDCG@20=0.40369\n",
      "[2019-12-23 10:19:35] [28/50] 0 mean_batch_loss : 3.463843\n",
      "Start predicting 2019-12-23 10:19:49\n",
      "testing finish [2019-12-23 10:19:53] \n",
      "\tHR@1=0.18079  MRR@1=0.18079  NDCG@1=0.18079\n",
      "\tHR@5=0.47499  MRR@5=0.28684  NDCG@5=0.33357\n",
      "\tHR@10=0.60530  MRR@10=0.30432  NDCG@10=0.37581\n",
      "\tHR@20=0.71024  MRR@20=0.31172  NDCG@20=0.40249\n",
      "[2019-12-23 10:19:53] [29/50] 0 mean_batch_loss : 3.520484\n",
      "Start predicting 2019-12-23 10:20:06\n",
      "testing finish [2019-12-23 10:20:10] \n",
      "\tHR@1=0.17983  MRR@1=0.17983  NDCG@1=0.17983\n",
      "\tHR@5=0.47517  MRR@5=0.28559  NDCG@5=0.33264\n",
      "\tHR@10=0.60455  MRR@10=0.30302  NDCG@10=0.37464\n",
      "\tHR@20=0.71092  MRR@20=0.31053  NDCG@20=0.40170\n",
      "[2019-12-23 10:20:10] [30/50] 0 mean_batch_loss : 3.546140\n",
      "Start predicting 2019-12-23 10:20:23\n",
      "testing finish [2019-12-23 10:20:27] \n",
      "\tHR@1=0.17883  MRR@1=0.17883  NDCG@1=0.17883\n",
      "\tHR@5=0.47383  MRR@5=0.28549  NDCG@5=0.33229\n",
      "\tHR@10=0.60474  MRR@10=0.30312  NDCG@10=0.37478\n",
      "\tHR@20=0.71096  MRR@20=0.31060  NDCG@20=0.40177\n",
      "[2019-12-23 10:20:27] [31/50] 0 mean_batch_loss : 3.376148\n",
      "Start predicting 2019-12-23 10:20:40\n",
      "testing finish [2019-12-23 10:20:44] \n",
      "\tHR@1=0.17874  MRR@1=0.17874  NDCG@1=0.17874\n",
      "\tHR@5=0.47454  MRR@5=0.28533  NDCG@5=0.33231\n",
      "\tHR@10=0.60362  MRR@10=0.30271  NDCG@10=0.37421\n",
      "\tHR@20=0.71024  MRR@20=0.31024  NDCG@20=0.40134\n",
      "early stopping\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0010, amsgrad=True, method=general, dropout=0.3, weight_decay=0.000000. \n",
      "\n",
      "current model HR@20=0.71652  MRR@20=0.31324.\n",
      "the best result so far. HR@20=0.71886  MRR@20=0.31580， hyper-parameters: session_length-20, hidden_size-100, lr-0.0005 , amsgrad-True, method-general, dropout-0.3, weight_decay-0.000000. \n",
      "\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0003, amsgrad=True, method=general, dropout=0.5, weight_decay=0.000000. \n",
      "\n",
      "[2019-12-23 10:20:44] [1/50] 0 mean_batch_loss : 38.838703\n",
      "Start predicting 2019-12-23 10:20:57\n",
      "change best\n",
      "testing finish [2019-12-23 10:21:01] \n",
      "\tHR@1=0.00479  MRR@1=0.00479  NDCG@1=0.00479\n",
      "\tHR@5=0.01800  MRR@5=0.00879  NDCG@5=0.01102\n",
      "\tHR@10=0.03149  MRR@10=0.01052  NDCG@10=0.01532\n",
      "\tHR@20=0.06553  MRR@20=0.01284  NDCG@20=0.02387\n",
      "[2019-12-23 10:21:01] [2/50] 0 mean_batch_loss : 13.552893\n",
      "Start predicting 2019-12-23 10:21:14\n",
      "change best\n",
      "testing finish [2019-12-23 10:21:18] \n",
      "\tHR@1=0.04252  MRR@1=0.04252  NDCG@1=0.04252\n",
      "\tHR@5=0.09265  MRR@5=0.05957  NDCG@5=0.06773\n",
      "\tHR@10=0.11983  MRR@10=0.06319  NDCG@10=0.07651\n",
      "\tHR@20=0.16727  MRR@20=0.06633  NDCG@20=0.08831\n",
      "[2019-12-23 10:21:18] [3/50] 0 mean_batch_loss : 8.041924\n",
      "Start predicting 2019-12-23 10:21:31\n",
      "change best\n",
      "testing finish [2019-12-23 10:21:35] \n",
      "\tHR@1=0.09616  MRR@1=0.09616  NDCG@1=0.09616\n",
      "\tHR@5=0.18487  MRR@5=0.12771  NDCG@5=0.14188\n",
      "\tHR@10=0.23054  MRR@10=0.13379  NDCG@10=0.15663\n",
      "\tHR@20=0.28099  MRR@20=0.13729  NDCG@20=0.16939\n",
      "[2019-12-23 10:21:35] [4/50] 0 mean_batch_loss : 7.424239\n",
      "Start predicting 2019-12-23 10:21:48\n",
      "change best\n",
      "testing finish [2019-12-23 10:21:52] \n",
      "\tHR@1=0.12126  MRR@1=0.12126  NDCG@1=0.12126\n",
      "\tHR@5=0.26561  MRR@5=0.17386  NDCG@5=0.19665\n",
      "\tHR@10=0.32951  MRR@10=0.18236  NDCG@10=0.21730\n",
      "\tHR@20=0.40130  MRR@20=0.18731  NDCG@20=0.23540\n",
      "[2019-12-23 10:21:52] [5/50] 0 mean_batch_loss : 6.727652\n",
      "Start predicting 2019-12-23 10:22:05\n",
      "change best\n",
      "testing finish [2019-12-23 10:22:09] \n",
      "\tHR@1=0.12915  MRR@1=0.12915  NDCG@1=0.12915\n",
      "\tHR@5=0.30720  MRR@5=0.19471  NDCG@5=0.22272\n",
      "\tHR@10=0.38701  MRR@10=0.20533  NDCG@10=0.24849\n",
      "\tHR@20=0.47488  MRR@20=0.21144  NDCG@20=0.27073\n",
      "[2019-12-23 10:22:09] [6/50] 0 mean_batch_loss : 6.666899\n",
      "Start predicting 2019-12-23 10:22:22\n",
      "change best\n",
      "testing finish [2019-12-23 10:22:26] \n",
      "\tHR@1=0.13403  MRR@1=0.13403  NDCG@1=0.13403\n",
      "\tHR@5=0.33939  MRR@5=0.21026  NDCG@5=0.24244\n",
      "\tHR@10=0.42633  MRR@10=0.22179  NDCG@10=0.27048\n",
      "\tHR@20=0.52091  MRR@20=0.22839  NDCG@20=0.29445\n",
      "[2019-12-23 10:22:26] [7/50] 0 mean_batch_loss : 6.186198\n",
      "Start predicting 2019-12-23 10:22:39\n",
      "change best\n",
      "testing finish [2019-12-23 10:22:43] \n",
      "\tHR@1=0.13743  MRR@1=0.13743  NDCG@1=0.13743\n",
      "\tHR@5=0.36415  MRR@5=0.22110  NDCG@5=0.25672\n",
      "\tHR@10=0.46184  MRR@10=0.23415  NDCG@10=0.28832\n",
      "\tHR@20=0.55768  MRR@20=0.24089  NDCG@20=0.31266\n",
      "[2019-12-23 10:22:44] [8/50] 0 mean_batch_loss : 6.207619\n",
      "Start predicting 2019-12-23 10:22:57\n",
      "change best\n",
      "testing finish [2019-12-23 10:23:00] \n",
      "\tHR@1=0.14120  MRR@1=0.14120  NDCG@1=0.14120\n",
      "\tHR@5=0.38246  MRR@5=0.23032  NDCG@5=0.26821\n",
      "\tHR@10=0.48803  MRR@10=0.24435  NDCG@10=0.30230\n",
      "\tHR@20=0.58503  MRR@20=0.25119  NDCG@20=0.32695\n",
      "[2019-12-23 10:23:01] [9/50] 0 mean_batch_loss : 5.815969\n",
      "Start predicting 2019-12-23 10:23:14\n",
      "change best\n",
      "testing finish [2019-12-23 10:23:18] \n",
      "\tHR@1=0.14371  MRR@1=0.14371  NDCG@1=0.14371\n",
      "\tHR@5=0.39778  MRR@5=0.23769  NDCG@5=0.27757\n",
      "\tHR@10=0.50962  MRR@10=0.25264  NDCG@10=0.31376\n",
      "\tHR@20=0.60705  MRR@20=0.25947  NDCG@20=0.33848\n",
      "[2019-12-23 10:23:18] [10/50] 0 mean_batch_loss : 5.447421\n",
      "Start predicting 2019-12-23 10:23:31\n",
      "change best\n",
      "testing finish [2019-12-23 10:23:35] \n",
      "\tHR@1=0.14646  MRR@1=0.14646  NDCG@1=0.14646\n",
      "\tHR@5=0.40967  MRR@5=0.24393  NDCG@5=0.28522\n",
      "\tHR@10=0.52576  MRR@10=0.25951  NDCG@10=0.32285\n",
      "\tHR@20=0.62417  MRR@20=0.26644  NDCG@20=0.34786\n",
      "[2019-12-23 10:23:35] [11/50] 0 mean_batch_loss : 5.262824\n",
      "Start predicting 2019-12-23 10:23:48\n",
      "change best\n",
      "testing finish [2019-12-23 10:23:52] \n",
      "\tHR@1=0.14999  MRR@1=0.14999  NDCG@1=0.14999\n",
      "\tHR@5=0.42188  MRR@5=0.25054  NDCG@5=0.29321\n",
      "\tHR@10=0.53852  MRR@10=0.26613  NDCG@10=0.33096\n",
      "\tHR@20=0.63904  MRR@20=0.27322  NDCG@20=0.35650\n",
      "[2019-12-23 10:23:52] [12/50] 0 mean_batch_loss : 5.330950\n",
      "Start predicting 2019-12-23 10:24:05\n",
      "change best\n",
      "testing finish [2019-12-23 10:24:09] \n",
      "\tHR@1=0.15310  MRR@1=0.15310  NDCG@1=0.15310\n",
      "\tHR@5=0.42848  MRR@5=0.25471  NDCG@5=0.29798\n",
      "\tHR@10=0.54823  MRR@10=0.27079  NDCG@10=0.33681\n",
      "\tHR@20=0.64814  MRR@20=0.27786  NDCG@20=0.36225\n",
      "[2019-12-23 10:24:09] [13/50] 0 mean_batch_loss : 5.021770\n",
      "Start predicting 2019-12-23 10:24:22\n",
      "change best\n",
      "testing finish [2019-12-23 10:24:26] \n",
      "\tHR@1=0.15206  MRR@1=0.15206  NDCG@1=0.15206\n",
      "\tHR@5=0.43515  MRR@5=0.25737  NDCG@5=0.30169\n",
      "\tHR@10=0.55732  MRR@10=0.27380  NDCG@10=0.34132\n",
      "\tHR@20=0.65700  MRR@20=0.28085  NDCG@20=0.36670\n",
      "[2019-12-23 10:24:26] [14/50] 0 mean_batch_loss : 5.000025\n",
      "Start predicting 2019-12-23 10:24:37\n",
      "change best\n",
      "testing finish [2019-12-23 10:24:41] \n",
      "\tHR@1=0.15401  MRR@1=0.15401  NDCG@1=0.15401\n",
      "\tHR@5=0.44129  MRR@5=0.26041  NDCG@5=0.30547\n",
      "\tHR@10=0.56381  MRR@10=0.27690  NDCG@10=0.34523\n",
      "\tHR@20=0.66451  MRR@20=0.28403  NDCG@20=0.37087\n",
      "[2019-12-23 10:24:41] [15/50] 0 mean_batch_loss : 5.010852\n",
      "Start predicting 2019-12-23 10:24:47\n",
      "change best\n",
      "testing finish [2019-12-23 10:24:51] \n",
      "\tHR@1=0.15466  MRR@1=0.15466  NDCG@1=0.15466\n",
      "\tHR@5=0.44458  MRR@5=0.26244  NDCG@5=0.30785\n",
      "\tHR@10=0.57029  MRR@10=0.27934  NDCG@10=0.34862\n",
      "\tHR@20=0.67010  MRR@20=0.28641  NDCG@20=0.37403\n",
      "[2019-12-23 10:24:51] [16/50] 0 mean_batch_loss : 4.657585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 10:25:04\n",
      "change best\n",
      "testing finish [2019-12-23 10:25:08] \n",
      "\tHR@1=0.15906  MRR@1=0.15906  NDCG@1=0.15906\n",
      "\tHR@5=0.44932  MRR@5=0.26625  NDCG@5=0.31184\n",
      "\tHR@10=0.57521  MRR@10=0.28314  NDCG@10=0.35264\n",
      "\tHR@20=0.67550  MRR@20=0.29024  NDCG@20=0.37817\n",
      "[2019-12-23 10:25:08] [17/50] 0 mean_batch_loss : 4.976556\n",
      "Start predicting 2019-12-23 10:25:21\n",
      "change best\n",
      "testing finish [2019-12-23 10:25:24] \n",
      "\tHR@1=0.16061  MRR@1=0.16061  NDCG@1=0.16061\n",
      "\tHR@5=0.45311  MRR@5=0.26841  NDCG@5=0.31441\n",
      "\tHR@10=0.57990  MRR@10=0.28542  NDCG@10=0.35549\n",
      "\tHR@20=0.68053  MRR@20=0.29254  NDCG@20=0.38111\n",
      "[2019-12-23 10:25:24] [18/50] 0 mean_batch_loss : 4.703499\n",
      "Start predicting 2019-12-23 10:25:39\n",
      "change best\n",
      "testing finish [2019-12-23 10:25:43] \n",
      "\tHR@1=0.15940  MRR@1=0.15940  NDCG@1=0.15940\n",
      "\tHR@5=0.45590  MRR@5=0.26900  NDCG@5=0.31556\n",
      "\tHR@10=0.58313  MRR@10=0.28607  NDCG@10=0.35680\n",
      "\tHR@20=0.68425  MRR@20=0.29321  NDCG@20=0.38252\n",
      "[2019-12-23 10:25:43] [19/50] 0 mean_batch_loss : 4.602868\n",
      "Start predicting 2019-12-23 10:25:55\n",
      "change best\n",
      "testing finish [2019-12-23 10:25:59] \n",
      "\tHR@1=0.16069  MRR@1=0.16069  NDCG@1=0.16069\n",
      "\tHR@5=0.45796  MRR@5=0.27039  NDCG@5=0.31711\n",
      "\tHR@10=0.58566  MRR@10=0.28752  NDCG@10=0.35849\n",
      "\tHR@20=0.68750  MRR@20=0.29473  NDCG@20=0.38442\n",
      "[2019-12-23 10:25:59] [20/50] 0 mean_batch_loss : 4.617153\n",
      "Start predicting 2019-12-23 10:26:14\n",
      "change best\n",
      "testing finish [2019-12-23 10:26:18] \n",
      "\tHR@1=0.15993  MRR@1=0.15993  NDCG@1=0.15993\n",
      "\tHR@5=0.45912  MRR@5=0.27059  NDCG@5=0.31756\n",
      "\tHR@10=0.58889  MRR@10=0.28802  NDCG@10=0.35964\n",
      "\tHR@20=0.68992  MRR@20=0.29516  NDCG@20=0.38534\n",
      "[2019-12-23 10:26:18] [21/50] 0 mean_batch_loss : 4.601451\n",
      "Start predicting 2019-12-23 10:26:33\n",
      "change best\n",
      "testing finish [2019-12-23 10:26:37] \n",
      "\tHR@1=0.16081  MRR@1=0.16081  NDCG@1=0.16081\n",
      "\tHR@5=0.46057  MRR@5=0.27156  NDCG@5=0.31865\n",
      "\tHR@10=0.59092  MRR@10=0.28906  NDCG@10=0.36090\n",
      "\tHR@20=0.69257  MRR@20=0.29623  NDCG@20=0.38675\n",
      "[2019-12-23 10:26:37] [22/50] 0 mean_batch_loss : 4.327336\n",
      "Start predicting 2019-12-23 10:26:49\n",
      "change best\n",
      "testing finish [2019-12-23 10:26:53] \n",
      "\tHR@1=0.16027  MRR@1=0.16027  NDCG@1=0.16027\n",
      "\tHR@5=0.46367  MRR@5=0.27239  NDCG@5=0.32004\n",
      "\tHR@10=0.59419  MRR@10=0.28994  NDCG@10=0.36237\n",
      "\tHR@20=0.69450  MRR@20=0.29702  NDCG@20=0.38790\n",
      "[2019-12-23 10:26:53] [23/50] 0 mean_batch_loss : 4.492549\n",
      "Start predicting 2019-12-23 10:27:12\n",
      "change best\n",
      "testing finish [2019-12-23 10:27:16] \n",
      "\tHR@1=0.16208  MRR@1=0.16208  NDCG@1=0.16208\n",
      "\tHR@5=0.46388  MRR@5=0.27341  NDCG@5=0.32085\n",
      "\tHR@10=0.59517  MRR@10=0.29110  NDCG@10=0.36348\n",
      "\tHR@20=0.69648  MRR@20=0.29826  NDCG@20=0.38925\n",
      "[2019-12-23 10:27:16] [24/50] 0 mean_batch_loss : 4.571442\n",
      "Start predicting 2019-12-23 10:27:35\n",
      "change best\n",
      "testing finish [2019-12-23 10:27:40] \n",
      "\tHR@1=0.16255  MRR@1=0.16255  NDCG@1=0.16255\n",
      "\tHR@5=0.46665  MRR@5=0.27465  NDCG@5=0.32246\n",
      "\tHR@10=0.59664  MRR@10=0.29206  NDCG@10=0.36456\n",
      "\tHR@20=0.69800  MRR@20=0.29922  NDCG@20=0.39034\n",
      "[2019-12-23 10:27:40] [25/50] 0 mean_batch_loss : 4.348506\n",
      "Start predicting 2019-12-23 10:28:00\n",
      "change best\n",
      "testing finish [2019-12-23 10:28:04] \n",
      "\tHR@1=0.16247  MRR@1=0.16247  NDCG@1=0.16247\n",
      "\tHR@5=0.46605  MRR@5=0.27426  NDCG@5=0.32201\n",
      "\tHR@10=0.59852  MRR@10=0.29207  NDCG@10=0.36499\n",
      "\tHR@20=0.70003  MRR@20=0.29923  NDCG@20=0.39080\n",
      "[2019-12-23 10:28:04] [26/50] 0 mean_batch_loss : 4.437300\n",
      "Start predicting 2019-12-23 10:28:24\n",
      "change best\n",
      "testing finish [2019-12-23 10:28:28] \n",
      "\tHR@1=0.16253  MRR@1=0.16253  NDCG@1=0.16253\n",
      "\tHR@5=0.46705  MRR@5=0.27479  NDCG@5=0.32268\n",
      "\tHR@10=0.59895  MRR@10=0.29259  NDCG@10=0.36552\n",
      "\tHR@20=0.70083  MRR@20=0.29980  NDCG@20=0.39146\n",
      "[2019-12-23 10:28:28] [27/50] 0 mean_batch_loss : 4.207291\n",
      "Start predicting 2019-12-23 10:28:48\n",
      "change best\n",
      "testing finish [2019-12-23 10:28:52] \n",
      "\tHR@1=0.16400  MRR@1=0.16400  NDCG@1=0.16400\n",
      "\tHR@5=0.46875  MRR@5=0.27587  NDCG@5=0.32387\n",
      "\tHR@10=0.59991  MRR@10=0.29350  NDCG@10=0.36641\n",
      "\tHR@20=0.70239  MRR@20=0.30075  NDCG@20=0.39250\n",
      "[2019-12-23 10:28:52] [28/50] 0 mean_batch_loss : 4.448031\n",
      "Start predicting 2019-12-23 10:29:12\n",
      "change best\n",
      "testing finish [2019-12-23 10:29:17] \n",
      "\tHR@1=0.16374  MRR@1=0.16374  NDCG@1=0.16374\n",
      "\tHR@5=0.46769  MRR@5=0.27553  NDCG@5=0.32338\n",
      "\tHR@10=0.60133  MRR@10=0.29350  NDCG@10=0.36672\n",
      "\tHR@20=0.70299  MRR@20=0.30070  NDCG@20=0.39261\n",
      "[2019-12-23 10:29:17] [29/50] 0 mean_batch_loss : 4.337715\n",
      "Start predicting 2019-12-23 10:29:36\n",
      "change best\n",
      "testing finish [2019-12-23 10:29:40] \n",
      "\tHR@1=0.16324  MRR@1=0.16324  NDCG@1=0.16324\n",
      "\tHR@5=0.46885  MRR@5=0.27584  NDCG@5=0.32391\n",
      "\tHR@10=0.60319  MRR@10=0.29387  NDCG@10=0.36746\n",
      "\tHR@20=0.70468  MRR@20=0.30104  NDCG@20=0.39327\n",
      "[2019-12-23 10:29:40] [30/50] 0 mean_batch_loss : 3.916593\n",
      "Start predicting 2019-12-23 10:30:01\n",
      "change best\n",
      "testing finish [2019-12-23 10:30:05] \n",
      "\tHR@1=0.16451  MRR@1=0.16451  NDCG@1=0.16451\n",
      "\tHR@5=0.46946  MRR@5=0.27667  NDCG@5=0.32466\n",
      "\tHR@10=0.60362  MRR@10=0.29473  NDCG@10=0.36820\n",
      "\tHR@20=0.70647  MRR@20=0.30200  NDCG@20=0.39437\n",
      "[2019-12-23 10:30:05] [31/50] 0 mean_batch_loss : 4.250267\n",
      "Start predicting 2019-12-23 10:30:25\n",
      "change best\n",
      "testing finish [2019-12-23 10:30:29] \n",
      "\tHR@1=0.16528  MRR@1=0.16528  NDCG@1=0.16528\n",
      "\tHR@5=0.46912  MRR@5=0.27677  NDCG@5=0.32465\n",
      "\tHR@10=0.60408  MRR@10=0.29496  NDCG@10=0.36847\n",
      "\tHR@20=0.70716  MRR@20=0.30224  NDCG@20=0.39469\n",
      "[2019-12-23 10:30:29] [32/50] 0 mean_batch_loss : 4.216937\n",
      "Start predicting 2019-12-23 10:30:49\n",
      "testing finish [2019-12-23 10:30:53] \n",
      "\tHR@1=0.16190  MRR@1=0.16190  NDCG@1=0.16190\n",
      "\tHR@5=0.47141  MRR@5=0.27572  NDCG@5=0.32444\n",
      "\tHR@10=0.60401  MRR@10=0.29356  NDCG@10=0.36747\n",
      "\tHR@20=0.70811  MRR@20=0.30094  NDCG@20=0.39398\n",
      "[2019-12-23 10:30:53] [33/50] 0 mean_batch_loss : 4.274555\n",
      "Start predicting 2019-12-23 10:31:13\n",
      "change best\n",
      "testing finish [2019-12-23 10:31:17] \n",
      "\tHR@1=0.16292  MRR@1=0.16292  NDCG@1=0.16292\n",
      "\tHR@5=0.47107  MRR@5=0.27625  NDCG@5=0.32476\n",
      "\tHR@10=0.60455  MRR@10=0.29420  NDCG@10=0.36805\n",
      "\tHR@20=0.70842  MRR@20=0.30154  NDCG@20=0.39448\n",
      "[2019-12-23 10:31:17] [34/50] 0 mean_batch_loss : 4.324592\n",
      "Start predicting 2019-12-23 10:31:37\n",
      "change best\n",
      "testing finish [2019-12-23 10:31:41] \n",
      "\tHR@1=0.16194  MRR@1=0.16194  NDCG@1=0.16194\n",
      "\tHR@5=0.47177  MRR@5=0.27607  NDCG@5=0.32480\n",
      "\tHR@10=0.60643  MRR@10=0.29418  NDCG@10=0.36848\n",
      "\tHR@20=0.70967  MRR@20=0.30146  NDCG@20=0.39473\n",
      "[2019-12-23 10:31:41] [35/50] 0 mean_batch_loss : 4.171952\n",
      "Start predicting 2019-12-23 10:32:02\n",
      "change best\n",
      "testing finish [2019-12-23 10:32:06] \n",
      "\tHR@1=0.16501  MRR@1=0.16501  NDCG@1=0.16501\n",
      "\tHR@5=0.47281  MRR@5=0.27777  NDCG@5=0.32630\n",
      "\tHR@10=0.60734  MRR@10=0.29581  NDCG@10=0.36989\n",
      "\tHR@20=0.71067  MRR@20=0.30308  NDCG@20=0.39615\n",
      "[2019-12-23 10:32:06] [36/50] 0 mean_batch_loss : 3.832969\n",
      "Start predicting 2019-12-23 10:32:23\n",
      "testing finish [2019-12-23 10:32:27] \n",
      "\tHR@1=0.16355  MRR@1=0.16355  NDCG@1=0.16355\n",
      "\tHR@5=0.47247  MRR@5=0.27707  NDCG@5=0.32572\n",
      "\tHR@10=0.60671  MRR@10=0.29509  NDCG@10=0.36923\n",
      "\tHR@20=0.71103  MRR@20=0.30246  NDCG@20=0.39577\n",
      "[2019-12-23 10:32:27] [37/50] 0 mean_batch_loss : 4.137433\n",
      "Start predicting 2019-12-23 10:32:48\n",
      "testing finish [2019-12-23 10:32:52] \n",
      "\tHR@1=0.16264  MRR@1=0.16264  NDCG@1=0.16264\n",
      "\tHR@5=0.47336  MRR@5=0.27669  NDCG@5=0.32564\n",
      "\tHR@10=0.60757  MRR@10=0.29471  NDCG@10=0.36915\n",
      "\tHR@20=0.71108  MRR@20=0.30202  NDCG@20=0.39548\n",
      "[2019-12-23 10:32:52] [38/50] 0 mean_batch_loss : 4.060600\n",
      "Start predicting 2019-12-23 10:33:12\n",
      "change best\n",
      "testing finish [2019-12-23 10:33:17] \n",
      "\tHR@1=0.16450  MRR@1=0.16450  NDCG@1=0.16450\n",
      "\tHR@5=0.47211  MRR@5=0.27727  NDCG@5=0.32576\n",
      "\tHR@10=0.60793  MRR@10=0.29552  NDCG@10=0.36981\n",
      "\tHR@20=0.71151  MRR@20=0.30286  NDCG@20=0.39618\n",
      "[2019-12-23 10:33:17] [39/50] 0 mean_batch_loss : 4.077611\n",
      "Start predicting 2019-12-23 10:33:36\n",
      "change best\n",
      "testing finish [2019-12-23 10:33:40] \n",
      "\tHR@1=0.16682  MRR@1=0.16682  NDCG@1=0.16682\n",
      "\tHR@5=0.47322  MRR@5=0.27883  NDCG@5=0.32720\n",
      "\tHR@10=0.60804  MRR@10=0.29692  NDCG@10=0.37089\n",
      "\tHR@20=0.71206  MRR@20=0.30428  NDCG@20=0.39737\n",
      "[2019-12-23 10:33:40] [40/50] 0 mean_batch_loss : 4.034790\n",
      "Start predicting 2019-12-23 10:34:01\n",
      "testing finish [2019-12-23 10:34:05] \n",
      "\tHR@1=0.16369  MRR@1=0.16369  NDCG@1=0.16369\n",
      "\tHR@5=0.47379  MRR@5=0.27747  NDCG@5=0.32633\n",
      "\tHR@10=0.60805  MRR@10=0.29551  NDCG@10=0.36988\n",
      "\tHR@20=0.71199  MRR@20=0.30289  NDCG@20=0.39637\n",
      "[2019-12-23 10:34:05] [41/50] 0 mean_batch_loss : 3.836187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 10:34:25\n",
      "testing finish [2019-12-23 10:34:29] \n",
      "\tHR@1=0.16414  MRR@1=0.16414  NDCG@1=0.16414\n",
      "\tHR@5=0.47297  MRR@5=0.27743  NDCG@5=0.32609\n",
      "\tHR@10=0.60897  MRR@10=0.29568  NDCG@10=0.37018\n",
      "\tHR@20=0.71294  MRR@20=0.30303  NDCG@20=0.39664\n",
      "[2019-12-23 10:34:29] [42/50] 0 mean_batch_loss : 3.965297\n",
      "Start predicting 2019-12-23 10:34:49\n",
      "change best\n",
      "testing finish [2019-12-23 10:34:53] \n",
      "\tHR@1=0.16544  MRR@1=0.16544  NDCG@1=0.16544\n",
      "\tHR@5=0.47433  MRR@5=0.27858  NDCG@5=0.32730\n",
      "\tHR@10=0.60931  MRR@10=0.29673  NDCG@10=0.37107\n",
      "\tHR@20=0.71262  MRR@20=0.30405  NDCG@20=0.39739\n",
      "[2019-12-23 10:34:54] [43/50] 0 mean_batch_loss : 4.018471\n",
      "Start predicting 2019-12-23 10:35:13\n",
      "change best\n",
      "testing finish [2019-12-23 10:35:17] \n",
      "\tHR@1=0.16419  MRR@1=0.16419  NDCG@1=0.16419\n",
      "\tHR@5=0.47572  MRR@5=0.27825  NDCG@5=0.32738\n",
      "\tHR@10=0.60915  MRR@10=0.29620  NDCG@10=0.37068\n",
      "\tHR@20=0.71366  MRR@20=0.30363  NDCG@20=0.39731\n",
      "[2019-12-23 10:35:17] [44/50] 0 mean_batch_loss : 3.882136\n",
      "Start predicting 2019-12-23 10:35:37\n",
      "change best\n",
      "testing finish [2019-12-23 10:35:42] \n",
      "\tHR@1=0.16555  MRR@1=0.16555  NDCG@1=0.16555\n",
      "\tHR@5=0.47488  MRR@5=0.27869  NDCG@5=0.32750\n",
      "\tHR@10=0.61058  MRR@10=0.29690  NDCG@10=0.37148\n",
      "\tHR@20=0.71367  MRR@20=0.30420  NDCG@20=0.39774\n",
      "[2019-12-23 10:35:42] [45/50] 0 mean_batch_loss : 4.192025\n",
      "Start predicting 2019-12-23 10:36:02\n",
      "change best\n",
      "testing finish [2019-12-23 10:36:06] \n",
      "\tHR@1=0.16664  MRR@1=0.16664  NDCG@1=0.16664\n",
      "\tHR@5=0.47474  MRR@5=0.27911  NDCG@5=0.32777\n",
      "\tHR@10=0.61079  MRR@10=0.29735  NDCG@10=0.37185\n",
      "\tHR@20=0.71493  MRR@20=0.30471  NDCG@20=0.39834\n",
      "[2019-12-23 10:36:06] [46/50] 0 mean_batch_loss : 3.731263\n",
      "Start predicting 2019-12-23 10:36:26\n",
      "testing finish [2019-12-23 10:36:30] \n",
      "\tHR@1=0.16550  MRR@1=0.16550  NDCG@1=0.16550\n",
      "\tHR@5=0.47451  MRR@5=0.27856  NDCG@5=0.32731\n",
      "\tHR@10=0.61084  MRR@10=0.29688  NDCG@10=0.37153\n",
      "\tHR@20=0.71496  MRR@20=0.30425  NDCG@20=0.39804\n",
      "[2019-12-23 10:36:30] [47/50] 0 mean_batch_loss : 3.940945\n",
      "Start predicting 2019-12-23 10:36:51\n",
      "testing finish [2019-12-23 10:36:55] \n",
      "\tHR@1=0.16507  MRR@1=0.16507  NDCG@1=0.16507\n",
      "\tHR@5=0.47345  MRR@5=0.27830  NDCG@5=0.32688\n",
      "\tHR@10=0.61115  MRR@10=0.29681  NDCG@10=0.37155\n",
      "\tHR@20=0.71430  MRR@20=0.30411  NDCG@20=0.39781\n",
      "[2019-12-23 10:36:55] [48/50] 0 mean_batch_loss : 3.905888\n",
      "Start predicting 2019-12-23 10:37:14\n",
      "testing finish [2019-12-23 10:37:18] \n",
      "\tHR@1=0.16231  MRR@1=0.16231  NDCG@1=0.16231\n",
      "\tHR@5=0.47465  MRR@5=0.27728  NDCG@5=0.32643\n",
      "\tHR@10=0.61140  MRR@10=0.29568  NDCG@10=0.37080\n",
      "\tHR@20=0.71489  MRR@20=0.30302  NDCG@20=0.39716\n",
      "[2019-12-23 10:37:18] [49/50] 0 mean_batch_loss : 3.878094\n",
      "Start predicting 2019-12-23 10:37:39\n",
      "testing finish [2019-12-23 10:37:43] \n",
      "\tHR@1=0.16434  MRR@1=0.16434  NDCG@1=0.16434\n",
      "\tHR@5=0.47504  MRR@5=0.27830  NDCG@5=0.32728\n",
      "\tHR@10=0.60993  MRR@10=0.29648  NDCG@10=0.37108\n",
      "\tHR@20=0.71550  MRR@20=0.30397  NDCG@20=0.39797\n",
      "[2019-12-23 10:37:43] [50/50] 0 mean_batch_loss : 3.946967\n",
      "Start predicting 2019-12-23 10:38:03\n",
      "change best\n",
      "testing finish [2019-12-23 10:38:07] \n",
      "\tHR@1=0.16544  MRR@1=0.16544  NDCG@1=0.16544\n",
      "\tHR@5=0.47488  MRR@5=0.27910  NDCG@5=0.32784\n",
      "\tHR@10=0.61174  MRR@10=0.29749  NDCG@10=0.37222\n",
      "\tHR@20=0.71650  MRR@20=0.30490  NDCG@20=0.39888\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0003, amsgrad=True, method=general, dropout=0.5, weight_decay=0.000000. \n",
      "\n",
      "current model HR@20=0.71650  MRR@20=0.30490.\n",
      "the best result so far. HR@20=0.71886  MRR@20=0.31580， hyper-parameters: session_length-20, hidden_size-100, lr-0.0005 , amsgrad-True, method-general, dropout-0.3, weight_decay-0.000000. \n",
      "\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0005, amsgrad=True, method=general, dropout=0.5, weight_decay=0.000000. \n",
      "\n",
      "[2019-12-23 10:38:07] [1/50] 0 mean_batch_loss : 39.122353\n",
      "Start predicting 2019-12-23 10:38:27\n",
      "change best\n",
      "testing finish [2019-12-23 10:38:31] \n",
      "\tHR@1=0.01013  MRR@1=0.01013  NDCG@1=0.01013\n",
      "\tHR@5=0.04338  MRR@5=0.02168  NDCG@5=0.02706\n",
      "\tHR@10=0.05837  MRR@10=0.02367  NDCG@10=0.03190\n",
      "\tHR@20=0.09485  MRR@20=0.02608  NDCG@20=0.04096\n",
      "[2019-12-23 10:38:31] [2/50] 0 mean_batch_loss : 8.960351\n",
      "Start predicting 2019-12-23 10:38:52\n",
      "change best\n",
      "testing finish [2019-12-23 10:38:56] \n",
      "\tHR@1=0.08081  MRR@1=0.08081  NDCG@1=0.08081\n",
      "\tHR@5=0.15439  MRR@5=0.10727  NDCG@5=0.11895\n",
      "\tHR@10=0.19799  MRR@10=0.11303  NDCG@10=0.13300\n",
      "\tHR@20=0.25097  MRR@20=0.11670  NDCG@20=0.14638\n",
      "[2019-12-23 10:38:56] [3/50] 0 mean_batch_loss : 7.435985\n",
      "Start predicting 2019-12-23 10:39:15\n",
      "change best\n",
      "testing finish [2019-12-23 10:39:20] \n",
      "\tHR@1=0.12426  MRR@1=0.12426  NDCG@1=0.12426\n",
      "\tHR@5=0.29355  MRR@5=0.18673  NDCG@5=0.21332\n",
      "\tHR@10=0.36964  MRR@10=0.19689  NDCG@10=0.23794\n",
      "\tHR@20=0.44390  MRR@20=0.20206  NDCG@20=0.25673\n",
      "[2019-12-23 10:39:20] [4/50] 0 mean_batch_loss : 6.399933\n",
      "Start predicting 2019-12-23 10:39:40\n",
      "change best\n",
      "testing finish [2019-12-23 10:39:44] \n",
      "\tHR@1=0.13412  MRR@1=0.13412  NDCG@1=0.13412\n",
      "\tHR@5=0.34810  MRR@5=0.21335  NDCG@5=0.24693\n",
      "\tHR@10=0.44356  MRR@10=0.22609  NDCG@10=0.27780\n",
      "\tHR@20=0.53880  MRR@20=0.23273  NDCG@20=0.30191\n",
      "[2019-12-23 10:39:44] [5/50] 0 mean_batch_loss : 5.835097\n",
      "Start predicting 2019-12-23 10:40:04\n",
      "change best\n",
      "testing finish [2019-12-23 10:40:08] \n",
      "\tHR@1=0.13992  MRR@1=0.13992  NDCG@1=0.13992\n",
      "\tHR@5=0.38824  MRR@5=0.23178  NDCG@5=0.27076\n",
      "\tHR@10=0.49589  MRR@10=0.24620  NDCG@10=0.30561\n",
      "\tHR@20=0.59276  MRR@20=0.25295  NDCG@20=0.33014\n",
      "[2019-12-23 10:40:08] [6/50] 0 mean_batch_loss : 5.556220\n",
      "Start predicting 2019-12-23 10:40:28\n",
      "change best\n",
      "testing finish [2019-12-23 10:40:32] \n",
      "\tHR@1=0.14671  MRR@1=0.14671  NDCG@1=0.14671\n",
      "\tHR@5=0.41209  MRR@5=0.24515  NDCG@5=0.28674\n",
      "\tHR@10=0.52918  MRR@10=0.26082  NDCG@10=0.32465\n",
      "\tHR@20=0.62793  MRR@20=0.26776  NDCG@20=0.34972\n",
      "[2019-12-23 10:40:32] [7/50] 0 mean_batch_loss : 5.373514\n",
      "Start predicting 2019-12-23 10:40:53\n",
      "change best\n",
      "testing finish [2019-12-23 10:40:57] \n",
      "\tHR@1=0.14961  MRR@1=0.14961  NDCG@1=0.14961\n",
      "\tHR@5=0.43089  MRR@5=0.25414  NDCG@5=0.29819\n",
      "\tHR@10=0.54981  MRR@10=0.27014  NDCG@10=0.33677\n",
      "\tHR@20=0.65117  MRR@20=0.27729  NDCG@20=0.36254\n",
      "[2019-12-23 10:40:57] [8/50] 0 mean_batch_loss : 4.944367\n",
      "Start predicting 2019-12-23 10:41:17\n",
      "change best\n",
      "testing finish [2019-12-23 10:41:21] \n",
      "\tHR@1=0.15695  MRR@1=0.15695  NDCG@1=0.15695\n",
      "\tHR@5=0.44154  MRR@5=0.26186  NDCG@5=0.30660\n",
      "\tHR@10=0.56519  MRR@10=0.27852  NDCG@10=0.34675\n",
      "\tHR@20=0.66553  MRR@20=0.28561  NDCG@20=0.37227\n",
      "[2019-12-23 10:41:21] [9/50] 0 mean_batch_loss : 4.814596\n",
      "Start predicting 2019-12-23 10:41:42\n",
      "change best\n",
      "testing finish [2019-12-23 10:41:46] \n",
      "\tHR@1=0.15582  MRR@1=0.15582  NDCG@1=0.15582\n",
      "\tHR@5=0.45071  MRR@5=0.26493  NDCG@5=0.31121\n",
      "\tHR@10=0.57469  MRR@10=0.28156  NDCG@10=0.35139\n",
      "\tHR@20=0.67671  MRR@20=0.28874  NDCG@20=0.37732\n",
      "[2019-12-23 10:41:46] [10/50] 0 mean_batch_loss : 4.760521\n",
      "Start predicting 2019-12-23 10:42:06\n",
      "change best\n",
      "testing finish [2019-12-23 10:42:10] \n",
      "\tHR@1=0.15789  MRR@1=0.15789  NDCG@1=0.15789\n",
      "\tHR@5=0.45388  MRR@5=0.26742  NDCG@5=0.31388\n",
      "\tHR@10=0.58092  MRR@10=0.28457  NDCG@10=0.35515\n",
      "\tHR@20=0.68360  MRR@20=0.29181  NDCG@20=0.38125\n",
      "[2019-12-23 10:42:10] [11/50] 0 mean_batch_loss : 4.754513\n",
      "Start predicting 2019-12-23 10:42:29\n",
      "change best\n",
      "testing finish [2019-12-23 10:42:33] \n",
      "\tHR@1=0.16153  MRR@1=0.16153  NDCG@1=0.16153\n",
      "\tHR@5=0.45878  MRR@5=0.27116  NDCG@5=0.31789\n",
      "\tHR@10=0.58709  MRR@10=0.28843  NDCG@10=0.35953\n",
      "\tHR@20=0.68852  MRR@20=0.29560  NDCG@20=0.38534\n",
      "[2019-12-23 10:42:33] [12/50] 0 mean_batch_loss : 4.458580\n",
      "Start predicting 2019-12-23 10:42:53\n",
      "change best\n",
      "testing finish [2019-12-23 10:42:57] \n",
      "\tHR@1=0.16124  MRR@1=0.16124  NDCG@1=0.16124\n",
      "\tHR@5=0.46281  MRR@5=0.27219  NDCG@5=0.31964\n",
      "\tHR@10=0.59206  MRR@10=0.28955  NDCG@10=0.36156\n",
      "\tHR@20=0.69423  MRR@20=0.29677  NDCG@20=0.38755\n",
      "[2019-12-23 10:42:57] [13/50] 0 mean_batch_loss : 4.316692\n",
      "Start predicting 2019-12-23 10:43:17\n",
      "change best\n",
      "testing finish [2019-12-23 10:43:21] \n",
      "\tHR@1=0.16253  MRR@1=0.16253  NDCG@1=0.16253\n",
      "\tHR@5=0.46374  MRR@5=0.27366  NDCG@5=0.32100\n",
      "\tHR@10=0.59582  MRR@10=0.29148  NDCG@10=0.36391\n",
      "\tHR@20=0.69709  MRR@20=0.29864  NDCG@20=0.38968\n",
      "[2019-12-23 10:43:21] [14/50] 0 mean_batch_loss : 4.507561\n",
      "Start predicting 2019-12-23 10:43:42\n",
      "change best\n",
      "testing finish [2019-12-23 10:43:46] \n",
      "\tHR@1=0.16303  MRR@1=0.16303  NDCG@1=0.16303\n",
      "\tHR@5=0.46633  MRR@5=0.27460  NDCG@5=0.32233\n",
      "\tHR@10=0.59612  MRR@10=0.29205  NDCG@10=0.36444\n",
      "\tHR@20=0.69986  MRR@20=0.29940  NDCG@20=0.39086\n",
      "[2019-12-23 10:43:46] [15/50] 0 mean_batch_loss : 4.275012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 10:44:06\n",
      "change best\n",
      "testing finish [2019-12-23 10:44:10] \n",
      "\tHR@1=0.16024  MRR@1=0.16024  NDCG@1=0.16024\n",
      "\tHR@5=0.46771  MRR@5=0.27377  NDCG@5=0.32207\n",
      "\tHR@10=0.59907  MRR@10=0.29146  NDCG@10=0.36471\n",
      "\tHR@20=0.70246  MRR@20=0.29877  NDCG@20=0.39102\n",
      "[2019-12-23 10:44:10] [16/50] 0 mean_batch_loss : 4.470697\n",
      "Start predicting 2019-12-23 10:44:30\n",
      "change best\n",
      "testing finish [2019-12-23 10:44:34] \n",
      "\tHR@1=0.16487  MRR@1=0.16487  NDCG@1=0.16487\n",
      "\tHR@5=0.46755  MRR@5=0.27606  NDCG@5=0.32373\n",
      "\tHR@10=0.60104  MRR@10=0.29405  NDCG@10=0.36707\n",
      "\tHR@20=0.70457  MRR@20=0.30138  NDCG@20=0.39342\n",
      "[2019-12-23 10:44:34] [17/50] 0 mean_batch_loss : 4.136858\n",
      "Start predicting 2019-12-23 10:44:54\n",
      "change best\n",
      "testing finish [2019-12-23 10:44:58] \n",
      "\tHR@1=0.16369  MRR@1=0.16369  NDCG@1=0.16369\n",
      "\tHR@5=0.47014  MRR@5=0.27584  NDCG@5=0.32418\n",
      "\tHR@10=0.60340  MRR@10=0.29380  NDCG@10=0.36745\n",
      "\tHR@20=0.70666  MRR@20=0.30110  NDCG@20=0.39373\n",
      "[2019-12-23 10:44:58] [18/50] 0 mean_batch_loss : 4.292415\n",
      "Start predicting 2019-12-23 10:45:19\n",
      "change best\n",
      "testing finish [2019-12-23 10:45:23] \n",
      "\tHR@1=0.16451  MRR@1=0.16451  NDCG@1=0.16451\n",
      "\tHR@5=0.47002  MRR@5=0.27654  NDCG@5=0.32469\n",
      "\tHR@10=0.60401  MRR@10=0.29462  NDCG@10=0.36823\n",
      "\tHR@20=0.70818  MRR@20=0.30196  NDCG@20=0.39470\n",
      "[2019-12-23 10:45:23] [19/50] 0 mean_batch_loss : 4.240252\n",
      "Start predicting 2019-12-23 10:45:43\n",
      "change best\n",
      "testing finish [2019-12-23 10:45:48] \n",
      "\tHR@1=0.16323  MRR@1=0.16323  NDCG@1=0.16323\n",
      "\tHR@5=0.47059  MRR@5=0.27631  NDCG@5=0.32468\n",
      "\tHR@10=0.60632  MRR@10=0.29459  NDCG@10=0.36874\n",
      "\tHR@20=0.70944  MRR@20=0.30186  NDCG@20=0.39494\n",
      "[2019-12-23 10:45:48] [20/50] 0 mean_batch_loss : 4.206256\n",
      "Start predicting 2019-12-23 10:46:07\n",
      "change best\n",
      "testing finish [2019-12-23 10:46:11] \n",
      "\tHR@1=0.16222  MRR@1=0.16222  NDCG@1=0.16222\n",
      "\tHR@5=0.47411  MRR@5=0.27663  NDCG@5=0.32577\n",
      "\tHR@10=0.60632  MRR@10=0.29437  NDCG@10=0.36862\n",
      "\tHR@20=0.71133  MRR@20=0.30179  NDCG@20=0.39535\n",
      "[2019-12-23 10:46:11] [21/50] 0 mean_batch_loss : 4.040004\n",
      "Start predicting 2019-12-23 10:46:32\n",
      "change best\n",
      "testing finish [2019-12-23 10:46:36] \n",
      "\tHR@1=0.16498  MRR@1=0.16498  NDCG@1=0.16498\n",
      "\tHR@5=0.47415  MRR@5=0.27842  NDCG@5=0.32713\n",
      "\tHR@10=0.60644  MRR@10=0.29620  NDCG@10=0.37004\n",
      "\tHR@20=0.71167  MRR@20=0.30364  NDCG@20=0.39682\n",
      "[2019-12-23 10:46:36] [22/50] 0 mean_batch_loss : 4.058585\n",
      "Start predicting 2019-12-23 10:46:56\n",
      "testing finish [2019-12-23 10:47:00] \n",
      "\tHR@1=0.16299  MRR@1=0.16299  NDCG@1=0.16299\n",
      "\tHR@5=0.47184  MRR@5=0.27644  NDCG@5=0.32509\n",
      "\tHR@10=0.60757  MRR@10=0.29472  NDCG@10=0.36915\n",
      "\tHR@20=0.71235  MRR@20=0.30210  NDCG@20=0.39578\n",
      "[2019-12-23 10:47:00] [23/50] 0 mean_batch_loss : 3.956598\n",
      "Start predicting 2019-12-23 10:47:20\n",
      "change best\n",
      "testing finish [2019-12-23 10:47:24] \n",
      "\tHR@1=0.16285  MRR@1=0.16285  NDCG@1=0.16285\n",
      "\tHR@5=0.47259  MRR@5=0.27702  NDCG@5=0.32573\n",
      "\tHR@10=0.60838  MRR@10=0.29530  NDCG@10=0.36980\n",
      "\tHR@20=0.71301  MRR@20=0.30271  NDCG@20=0.39643\n",
      "[2019-12-23 10:47:25] [24/50] 0 mean_batch_loss : 3.922581\n",
      "Start predicting 2019-12-23 10:47:42\n",
      "change best\n",
      "testing finish [2019-12-23 10:47:47] \n",
      "\tHR@1=0.16212  MRR@1=0.16212  NDCG@1=0.16212\n",
      "\tHR@5=0.47392  MRR@5=0.27671  NDCG@5=0.32580\n",
      "\tHR@10=0.60884  MRR@10=0.29491  NDCG@10=0.36963\n",
      "\tHR@20=0.71448  MRR@20=0.30239  NDCG@20=0.39652\n",
      "[2019-12-23 10:47:47] [25/50] 0 mean_batch_loss : 4.136428\n",
      "Start predicting 2019-12-23 10:48:07\n",
      "change best\n",
      "testing finish [2019-12-23 10:48:11] \n",
      "\tHR@1=0.16432  MRR@1=0.16432  NDCG@1=0.16432\n",
      "\tHR@5=0.47393  MRR@5=0.27788  NDCG@5=0.32668\n",
      "\tHR@10=0.60805  MRR@10=0.29597  NDCG@10=0.37024\n",
      "\tHR@20=0.71473  MRR@20=0.30356  NDCG@20=0.39744\n",
      "[2019-12-23 10:48:11] [26/50] 0 mean_batch_loss : 4.378836\n",
      "Start predicting 2019-12-23 10:48:32\n",
      "change best\n",
      "testing finish [2019-12-23 10:48:36] \n",
      "\tHR@1=0.16442  MRR@1=0.16442  NDCG@1=0.16442\n",
      "\tHR@5=0.47361  MRR@5=0.27774  NDCG@5=0.32649\n",
      "\tHR@10=0.60970  MRR@10=0.29612  NDCG@10=0.37072\n",
      "\tHR@20=0.71493  MRR@20=0.30355  NDCG@20=0.39748\n",
      "[2019-12-23 10:48:36] [27/50] 0 mean_batch_loss : 4.115526\n",
      "Start predicting 2019-12-23 10:48:55\n",
      "change best\n",
      "testing finish [2019-12-23 10:49:00] \n",
      "\tHR@1=0.16312  MRR@1=0.16312  NDCG@1=0.16312\n",
      "\tHR@5=0.47401  MRR@5=0.27734  NDCG@5=0.32630\n",
      "\tHR@10=0.60952  MRR@10=0.29562  NDCG@10=0.37031\n",
      "\tHR@20=0.71593  MRR@20=0.30314  NDCG@20=0.39738\n",
      "[2019-12-23 10:49:00] [28/50] 0 mean_batch_loss : 3.882778\n",
      "Start predicting 2019-12-23 10:49:20\n",
      "change best\n",
      "testing finish [2019-12-23 10:49:24] \n",
      "\tHR@1=0.16475  MRR@1=0.16475  NDCG@1=0.16475\n",
      "\tHR@5=0.47648  MRR@5=0.27889  NDCG@5=0.32806\n",
      "\tHR@10=0.61145  MRR@10=0.29708  NDCG@10=0.37188\n",
      "\tHR@20=0.71679  MRR@20=0.30453  NDCG@20=0.39869\n",
      "[2019-12-23 10:49:24] [29/50] 0 mean_batch_loss : 4.028464\n",
      "Start predicting 2019-12-23 10:49:44\n",
      "testing finish [2019-12-23 10:49:48] \n",
      "\tHR@1=0.16296  MRR@1=0.16296  NDCG@1=0.16296\n",
      "\tHR@5=0.47517  MRR@5=0.27761  NDCG@5=0.32679\n",
      "\tHR@10=0.61176  MRR@10=0.29602  NDCG@10=0.37114\n",
      "\tHR@20=0.71716  MRR@20=0.30347  NDCG@20=0.39796\n",
      "[2019-12-23 10:49:48] [30/50] 0 mean_batch_loss : 3.896271\n",
      "Start predicting 2019-12-23 10:50:08\n",
      "change best\n",
      "testing finish [2019-12-23 10:50:13] \n",
      "\tHR@1=0.16543  MRR@1=0.16543  NDCG@1=0.16543\n",
      "\tHR@5=0.47537  MRR@5=0.27912  NDCG@5=0.32796\n",
      "\tHR@10=0.61165  MRR@10=0.29744  NDCG@10=0.37217\n",
      "\tHR@20=0.71690  MRR@20=0.30489  NDCG@20=0.39896\n",
      "[2019-12-23 10:50:13] [31/50] 0 mean_batch_loss : 3.871293\n",
      "Start predicting 2019-12-23 10:50:32\n",
      "testing finish [2019-12-23 10:50:36] \n",
      "\tHR@1=0.16509  MRR@1=0.16509  NDCG@1=0.16509\n",
      "\tHR@5=0.47465  MRR@5=0.27842  NDCG@5=0.32725\n",
      "\tHR@10=0.61165  MRR@10=0.29682  NDCG@10=0.37167\n",
      "\tHR@20=0.71732  MRR@20=0.30427  NDCG@20=0.39853\n",
      "[2019-12-23 10:50:36] [32/50] 0 mean_batch_loss : 3.924636\n",
      "Start predicting 2019-12-23 10:50:56\n",
      "testing finish [2019-12-23 10:51:00] \n",
      "\tHR@1=0.16344  MRR@1=0.16344  NDCG@1=0.16344\n",
      "\tHR@5=0.47701  MRR@5=0.27820  NDCG@5=0.32766\n",
      "\tHR@10=0.61210  MRR@10=0.29635  NDCG@10=0.37147\n",
      "\tHR@20=0.71736  MRR@20=0.30380  NDCG@20=0.39826\n",
      "[2019-12-23 10:51:01] [33/50] 0 mean_batch_loss : 3.900818\n",
      "Start predicting 2019-12-23 10:51:21\n",
      "change best\n",
      "testing finish [2019-12-23 10:51:25] \n",
      "\tHR@1=0.16416  MRR@1=0.16416  NDCG@1=0.16416\n",
      "\tHR@5=0.47513  MRR@5=0.27858  NDCG@5=0.32752\n",
      "\tHR@10=0.61201  MRR@10=0.29704  NDCG@10=0.37198\n",
      "\tHR@20=0.71763  MRR@20=0.30453  NDCG@20=0.39889\n",
      "[2019-12-23 10:51:25] [34/50] 0 mean_batch_loss : 4.066698\n",
      "Start predicting 2019-12-23 10:51:45\n",
      "change best\n",
      "testing finish [2019-12-23 10:51:49] \n",
      "\tHR@1=0.16446  MRR@1=0.16446  NDCG@1=0.16446\n",
      "\tHR@5=0.47519  MRR@5=0.27843  NDCG@5=0.32741\n",
      "\tHR@10=0.61324  MRR@10=0.29698  NDCG@10=0.37218\n",
      "\tHR@20=0.71904  MRR@20=0.30444  NDCG@20=0.39908\n",
      "[2019-12-23 10:51:49] [35/50] 0 mean_batch_loss : 3.857649\n",
      "Start predicting 2019-12-23 10:52:09\n",
      "testing finish [2019-12-23 10:52:13] \n",
      "\tHR@1=0.16086  MRR@1=0.16086  NDCG@1=0.16086\n",
      "\tHR@5=0.47656  MRR@5=0.27705  NDCG@5=0.32672\n",
      "\tHR@10=0.61319  MRR@10=0.29542  NDCG@10=0.37104\n",
      "\tHR@20=0.71845  MRR@20=0.30285  NDCG@20=0.39782\n",
      "[2019-12-23 10:52:14] [36/50] 0 mean_batch_loss : 4.016937\n",
      "Start predicting 2019-12-23 10:52:33\n",
      "change best\n",
      "testing finish [2019-12-23 10:52:37] \n",
      "\tHR@1=0.16389  MRR@1=0.16389  NDCG@1=0.16389\n",
      "\tHR@5=0.47800  MRR@5=0.27887  NDCG@5=0.32842\n",
      "\tHR@10=0.61321  MRR@10=0.29706  NDCG@10=0.37229\n",
      "\tHR@20=0.71924  MRR@20=0.30455  NDCG@20=0.39926\n",
      "[2019-12-23 10:52:37] [37/50] 0 mean_batch_loss : 3.761025\n",
      "Start predicting 2019-12-23 10:52:56\n",
      "testing finish [2019-12-23 10:53:00] \n",
      "\tHR@1=0.16467  MRR@1=0.16467  NDCG@1=0.16467\n",
      "\tHR@5=0.47562  MRR@5=0.27867  NDCG@5=0.32769\n",
      "\tHR@10=0.61292  MRR@10=0.29715  NDCG@10=0.37224\n",
      "\tHR@20=0.71906  MRR@20=0.30467  NDCG@20=0.39927\n",
      "[2019-12-23 10:53:00] [38/50] 0 mean_batch_loss : 3.812261\n",
      "Start predicting 2019-12-23 10:53:20\n",
      "change best\n",
      "testing finish [2019-12-23 10:53:24] \n",
      "\tHR@1=0.16469  MRR@1=0.16469  NDCG@1=0.16469\n",
      "\tHR@5=0.47823  MRR@5=0.27941  NDCG@5=0.32888\n",
      "\tHR@10=0.61330  MRR@10=0.29756  NDCG@10=0.37268\n",
      "\tHR@20=0.71918  MRR@20=0.30504  NDCG@20=0.39962\n",
      "[2019-12-23 10:53:24] [39/50] 0 mean_batch_loss : 3.882149\n",
      "Start predicting 2019-12-23 10:53:44\n",
      "change best\n",
      "testing finish [2019-12-23 10:53:48] \n",
      "\tHR@1=0.16391  MRR@1=0.16391  NDCG@1=0.16391\n",
      "\tHR@5=0.47590  MRR@5=0.27844  NDCG@5=0.32760\n",
      "\tHR@10=0.61288  MRR@10=0.29690  NDCG@10=0.37207\n",
      "\tHR@20=0.72022  MRR@20=0.30450  NDCG@20=0.39940\n",
      "[2019-12-23 10:53:48] [40/50] 0 mean_batch_loss : 4.006578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 10:54:09\n",
      "testing finish [2019-12-23 10:54:13] \n",
      "\tHR@1=0.16403  MRR@1=0.16403  NDCG@1=0.16403\n",
      "\tHR@5=0.47560  MRR@5=0.27846  NDCG@5=0.32753\n",
      "\tHR@10=0.61201  MRR@10=0.29686  NDCG@10=0.37184\n",
      "\tHR@20=0.71969  MRR@20=0.30447  NDCG@20=0.39924\n",
      "[2019-12-23 10:54:13] [41/50] 0 mean_batch_loss : 3.637409\n",
      "Start predicting 2019-12-23 10:54:32\n",
      "change best\n",
      "testing finish [2019-12-23 10:54:36] \n",
      "\tHR@1=0.16582  MRR@1=0.16582  NDCG@1=0.16582\n",
      "\tHR@5=0.47769  MRR@5=0.27978  NDCG@5=0.32903\n",
      "\tHR@10=0.61401  MRR@10=0.29814  NDCG@10=0.37328\n",
      "\tHR@20=0.72090  MRR@20=0.30568  NDCG@20=0.40045\n",
      "[2019-12-23 10:54:37] [42/50] 0 mean_batch_loss : 4.011255\n",
      "Start predicting 2019-12-23 10:54:57\n",
      "testing finish [2019-12-23 10:55:01] \n",
      "\tHR@1=0.16315  MRR@1=0.16315  NDCG@1=0.16315\n",
      "\tHR@5=0.47730  MRR@5=0.27847  NDCG@5=0.32796\n",
      "\tHR@10=0.61364  MRR@10=0.29683  NDCG@10=0.37221\n",
      "\tHR@20=0.71911  MRR@20=0.30431  NDCG@20=0.39908\n",
      "[2019-12-23 10:55:01] [43/50] 0 mean_batch_loss : 3.923194\n",
      "Start predicting 2019-12-23 10:55:21\n",
      "testing finish [2019-12-23 10:55:25] \n",
      "\tHR@1=0.16568  MRR@1=0.16568  NDCG@1=0.16568\n",
      "\tHR@5=0.47757  MRR@5=0.27995  NDCG@5=0.32914\n",
      "\tHR@10=0.61419  MRR@10=0.29834  NDCG@10=0.37347\n",
      "\tHR@20=0.72049  MRR@20=0.30585  NDCG@20=0.40052\n",
      "[2019-12-23 10:55:25] [44/50] 0 mean_batch_loss : 3.792906\n",
      "Start predicting 2019-12-23 10:55:45\n",
      "testing finish [2019-12-23 10:55:49] \n",
      "\tHR@1=0.16498  MRR@1=0.16498  NDCG@1=0.16498\n",
      "\tHR@5=0.47671  MRR@5=0.27934  NDCG@5=0.32847\n",
      "\tHR@10=0.61337  MRR@10=0.29780  NDCG@10=0.37288\n",
      "\tHR@20=0.72026  MRR@20=0.30537  NDCG@20=0.40009\n",
      "[2019-12-23 10:55:49] [45/50] 0 mean_batch_loss : 3.904706\n",
      "Start predicting 2019-12-23 10:56:10\n",
      "testing finish [2019-12-23 10:56:14] \n",
      "\tHR@1=0.16659  MRR@1=0.16659  NDCG@1=0.16659\n",
      "\tHR@5=0.47714  MRR@5=0.28034  NDCG@5=0.32932\n",
      "\tHR@10=0.61263  MRR@10=0.29857  NDCG@10=0.37328\n",
      "\tHR@20=0.72008  MRR@20=0.30618  NDCG@20=0.40064\n",
      "[2019-12-23 10:56:14] [46/50] 0 mean_batch_loss : 3.749913\n",
      "Start predicting 2019-12-23 10:56:33\n",
      "change best\n",
      "testing finish [2019-12-23 10:56:38] \n",
      "\tHR@1=0.16627  MRR@1=0.16627  NDCG@1=0.16627\n",
      "\tHR@5=0.47690  MRR@5=0.28012  NDCG@5=0.32909\n",
      "\tHR@10=0.61237  MRR@10=0.29840  NDCG@10=0.37310\n",
      "\tHR@20=0.72080  MRR@20=0.30605  NDCG@20=0.40067\n",
      "[2019-12-23 10:56:38] [47/50] 0 mean_batch_loss : 3.734539\n",
      "Start predicting 2019-12-23 10:56:58\n",
      "testing finish [2019-12-23 10:57:02] \n",
      "\tHR@1=0.16340  MRR@1=0.16340  NDCG@1=0.16340\n",
      "\tHR@5=0.47859  MRR@5=0.27875  NDCG@5=0.32848\n",
      "\tHR@10=0.61342  MRR@10=0.29688  NDCG@10=0.37222\n",
      "\tHR@20=0.72047  MRR@20=0.30444  NDCG@20=0.39944\n",
      "[2019-12-23 10:57:02] [48/50] 0 mean_batch_loss : 3.881207\n",
      "Start predicting 2019-12-23 10:57:22\n",
      "testing finish [2019-12-23 10:57:26] \n",
      "\tHR@1=0.16340  MRR@1=0.16340  NDCG@1=0.16340\n",
      "\tHR@5=0.47673  MRR@5=0.27851  NDCG@5=0.32785\n",
      "\tHR@10=0.61339  MRR@10=0.29686  NDCG@10=0.37216\n",
      "\tHR@20=0.71969  MRR@20=0.30440  NDCG@20=0.39923\n",
      "[2019-12-23 10:57:26] [49/50] 0 mean_batch_loss : 3.674550\n",
      "Start predicting 2019-12-23 10:57:46\n",
      "testing finish [2019-12-23 10:57:51] \n",
      "\tHR@1=0.16328  MRR@1=0.16328  NDCG@1=0.16328\n",
      "\tHR@5=0.47712  MRR@5=0.27853  NDCG@5=0.32796\n",
      "\tHR@10=0.61444  MRR@10=0.29700  NDCG@10=0.37252\n",
      "\tHR@20=0.72087  MRR@20=0.30454  NDCG@20=0.39961\n",
      "[2019-12-23 10:57:51] [50/50] 0 mean_batch_loss : 3.819844\n",
      "Start predicting 2019-12-23 10:58:07\n",
      "testing finish [2019-12-23 10:58:11] \n",
      "\tHR@1=0.16509  MRR@1=0.16509  NDCG@1=0.16509\n",
      "\tHR@5=0.47671  MRR@5=0.27943  NDCG@5=0.32854\n",
      "\tHR@10=0.61231  MRR@10=0.29770  NDCG@10=0.37256\n",
      "\tHR@20=0.72033  MRR@20=0.30536  NDCG@20=0.40007\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0005, amsgrad=True, method=general, dropout=0.5, weight_decay=0.000000. \n",
      "\n",
      "current model HR@20=0.72080  MRR@20=0.30605.\n",
      "the best result so far. HR@20=0.71886  MRR@20=0.31580， hyper-parameters: session_length-20, hidden_size-100, lr-0.0005 , amsgrad-True, method-general, dropout-0.3, weight_decay-0.000000. \n",
      "\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0010, amsgrad=True, method=general, dropout=0.5, weight_decay=0.000000. \n",
      "\n",
      "[2019-12-23 10:58:11] [1/50] 0 mean_batch_loss : 38.938564\n",
      "Start predicting 2019-12-23 10:58:31\n",
      "change best\n",
      "testing finish [2019-12-23 10:58:35] \n",
      "\tHR@1=0.03617  MRR@1=0.03617  NDCG@1=0.03617\n",
      "\tHR@5=0.09247  MRR@5=0.05666  NDCG@5=0.06557\n",
      "\tHR@10=0.11891  MRR@10=0.06018  NDCG@10=0.07411\n",
      "\tHR@20=0.16457  MRR@20=0.06324  NDCG@20=0.08552\n",
      "[2019-12-23 10:58:35] [2/50] 0 mean_batch_loss : 7.451964\n",
      "Start predicting 2019-12-23 10:58:56\n",
      "change best\n",
      "testing finish [2019-12-23 10:59:00] \n",
      "\tHR@1=0.13333  MRR@1=0.13333  NDCG@1=0.13333\n",
      "\tHR@5=0.35048  MRR@5=0.21369  NDCG@5=0.24776\n",
      "\tHR@10=0.44127  MRR@10=0.22586  NDCG@10=0.27717\n",
      "\tHR@20=0.53367  MRR@20=0.23228  NDCG@20=0.30054\n",
      "[2019-12-23 10:59:00] [3/50] 0 mean_batch_loss : 6.181043\n",
      "Start predicting 2019-12-23 10:59:19\n",
      "change best\n",
      "testing finish [2019-12-23 10:59:24] \n",
      "\tHR@1=0.15280  MRR@1=0.15280  NDCG@1=0.15280\n",
      "\tHR@5=0.42535  MRR@5=0.25373  NDCG@5=0.29648\n",
      "\tHR@10=0.54077  MRR@10=0.26920  NDCG@10=0.33387\n",
      "\tHR@20=0.63807  MRR@20=0.27602  NDCG@20=0.35856\n",
      "[2019-12-23 10:59:24] [4/50] 0 mean_batch_loss : 5.188597\n",
      "Start predicting 2019-12-23 10:59:44\n",
      "change best\n",
      "testing finish [2019-12-23 10:59:48] \n",
      "\tHR@1=0.15965  MRR@1=0.15965  NDCG@1=0.15965\n",
      "\tHR@5=0.44962  MRR@5=0.26654  NDCG@5=0.31213\n",
      "\tHR@10=0.57054  MRR@10=0.28277  NDCG@10=0.35133\n",
      "\tHR@20=0.67312  MRR@20=0.29001  NDCG@20=0.37742\n",
      "[2019-12-23 10:59:48] [5/50] 0 mean_batch_loss : 4.936188\n",
      "Start predicting 2019-12-23 11:00:08\n",
      "change best\n",
      "testing finish [2019-12-23 11:00:12] \n",
      "\tHR@1=0.16120  MRR@1=0.16120  NDCG@1=0.16120\n",
      "\tHR@5=0.45826  MRR@5=0.27075  NDCG@5=0.31745\n",
      "\tHR@10=0.58539  MRR@10=0.28784  NDCG@10=0.35868\n",
      "\tHR@20=0.68892  MRR@20=0.29518  NDCG@20=0.38504\n",
      "[2019-12-23 11:00:12] [6/50] 0 mean_batch_loss : 4.481175\n",
      "Start predicting 2019-12-23 11:00:32\n",
      "change best\n",
      "testing finish [2019-12-23 11:00:37] \n",
      "\tHR@1=0.16382  MRR@1=0.16382  NDCG@1=0.16382\n",
      "\tHR@5=0.46356  MRR@5=0.27358  NDCG@5=0.32085\n",
      "\tHR@10=0.59383  MRR@10=0.29104  NDCG@10=0.36305\n",
      "\tHR@20=0.69675  MRR@20=0.29833  NDCG@20=0.38926\n",
      "[2019-12-23 11:00:37] [7/50] 0 mean_batch_loss : 4.543493\n",
      "Start predicting 2019-12-23 11:00:56\n",
      "change best\n",
      "testing finish [2019-12-23 11:01:00] \n",
      "\tHR@1=0.16206  MRR@1=0.16206  NDCG@1=0.16206\n",
      "\tHR@5=0.46463  MRR@5=0.27357  NDCG@5=0.32114\n",
      "\tHR@10=0.59897  MRR@10=0.29162  NDCG@10=0.36470\n",
      "\tHR@20=0.70375  MRR@20=0.29905  NDCG@20=0.39140\n",
      "[2019-12-23 11:01:00] [8/50] 0 mean_batch_loss : 4.081774\n",
      "Start predicting 2019-12-23 11:01:21\n",
      "change best\n",
      "testing finish [2019-12-23 11:01:25] \n",
      "\tHR@1=0.16562  MRR@1=0.16562  NDCG@1=0.16562\n",
      "\tHR@5=0.46866  MRR@5=0.27686  NDCG@5=0.32461\n",
      "\tHR@10=0.60165  MRR@10=0.29470  NDCG@10=0.36770\n",
      "\tHR@20=0.70675  MRR@20=0.30212  NDCG@20=0.39443\n",
      "[2019-12-23 11:01:25] [9/50] 0 mean_batch_loss : 4.340237\n"
     ]
    }
   ],
   "source": [
    "hidden_sizes = [100]\n",
    "dropouts = [0.3,0.5]\n",
    "attention_methods = [\"general\"]\n",
    "lrs = [3e-4,5e-4,1e-3]\n",
    "session_lengths = [20]\n",
    "weight_decays = [0]\n",
    "patience = 10\n",
    "amsgrads = [True]\n",
    "best_params = \"\"\n",
    "best_all_model = 0.0\n",
    "best_all_hr = 0.0\n",
    "best_all_mrr = 0.0\n",
    "best_all_r1m = 0.0\n",
    "for session_length in session_lengths:\n",
    "    for hidden_size in hidden_sizes:\n",
    "        for amsgrad in amsgrads:\n",
    "            for attention_method in attention_methods:\n",
    "                for dropout in dropouts:\n",
    "                    for weight_decay in weight_decays:\n",
    "                        for lr in lrs:\n",
    "                            args = {}\n",
    "                            print(\"current model hyper-parameters: session_length=%d, hidden_size=%d, lr=%.4f, amsgrad=%s, method=%s, dropout=%.1f, weight_decay=%.6f. \\n\" % (session_length,hidden_size,lr,str(amsgrad),attention_method,dropout,weight_decay))\n",
    "                            args[\"session_length\"] = session_length\n",
    "                            args[\"hidden_size\"] = hidden_size\n",
    "                            args[\"amsgrad\"] = amsgrad\n",
    "                            args[\"method\"] = attention_method\n",
    "                            args[\"dropout\"] = dropout\n",
    "                            args[\"weight_decay\"] = weight_decay\n",
    "                            args[\"lr\"] = lr\n",
    "                            args[\"patience\"] = patience\n",
    "                            best_model,best_model_hr,best_model_mrr = train(args)\n",
    "                            if best_model_hr + best_model_mrr > best_all_r1m:\n",
    "                                print(\"best model change\")\n",
    "                                best_all_r1m = best_model_hr + best_model_mrr\n",
    "                                best_all_hr = best_model_hr\n",
    "                                best_all_mrr = best_model_mrr\n",
    "                                best_all_model = best_model\n",
    "                                best_params = \"session_length-%d, hidden_size-%d, lr-%.4f , amsgrad-%s, method-%s, dropout-%.1f, weight_decay-%.6f\"%(session_length,hidden_size,lr,str(amsgrad),attention_method,dropout,weight_decay)\n",
    "                            best_model = None\n",
    "                            print(\"current model hyper-parameters: session_length=%d, hidden_size=%d, lr=%.4f, amsgrad=%s, method=%s, dropout=%.1f, weight_decay=%.6f. \\n\" % (session_length,hidden_size,lr,str(amsgrad),attention_method,dropout,weight_decay))\n",
    "                            print(\"current model HR@20=%.5f  MRR@20=%.5f.\"%(best_model_hr,best_model_mrr))\n",
    "                            print(\"the best result so far. HR@20=%.5f  MRR@20=%.5f， hyper-parameters: %s. \\n\"%(best_all_hr,best_all_mrr,best_params))\n",
    "print(\"The best result HR@20=%.5f  MRR@20=%.5f, hyper-parameters: %s. \"%(best_all_hr,best_all_mrr,best_params))\n",
    "print(\"over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "WDP-CE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "smy",
   "language": "python",
   "name": "smy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
