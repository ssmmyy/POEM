{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T11:48:49.494632Z",
     "start_time": "2019-12-26T11:48:49.065722Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MhcOrxNibMjb"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T11:48:49.498127Z",
     "start_time": "2019-12-26T11:48:49.495689Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EGxgHeR6bN0K"
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T11:48:49.507454Z",
     "start_time": "2019-12-26T11:48:49.499059Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tBeDjO8dbPzP"
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "plot_num = 50000\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T11:48:49.533469Z",
     "start_time": "2019-12-26T11:48:49.508312Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zef81a0tbRC4"
   },
   "outputs": [],
   "source": [
    "# this part is different form POEM\n",
    "class SessionData(object):\n",
    "    def __init__(self,session_index,session_id,items_indexes):\n",
    "        self.session_index = session_index\n",
    "        self.session_id = session_id\n",
    "        self.item_list = items_indexes\n",
    "    def generate_seq_datas(self,session_length,padding_idx=0,predict_length=1):\n",
    "        sessions = []\n",
    "        if len(self.item_list)<2:\n",
    "            self.item_list.append[self.item_list[0]]\n",
    "        if predict_length==1:\n",
    "#             # when session length>=3\n",
    "#             for i in range(1,len(self.item_list)-1):\n",
    "            # when session length >=2\n",
    "            for i in range(len(self.item_list)-1):\n",
    "                if i <session_length:\n",
    "                    train_data = [0 for _ in range(session_length-i-1)]\n",
    "                    train_data.extend(self.item_list[:i+1])\n",
    "                    train_data.append(self.item_list[i+1])\n",
    "                else:\n",
    "                    train_data = self.item_list[i+1-session_length:i+1]\n",
    "                    train_data.append(self.item_list[i+1])\n",
    "                sessions.append(train_data)\n",
    "        else:\n",
    "            # To be continue if necessary\n",
    "            pass\n",
    "        return self.session_index,sessions\n",
    "    def __str__(self):\n",
    "        info = \" session index = {}\\n session id = {} \\n the length of item list= {} \\n the fisrt item index in item list is {}\".format(self.session_index,self.session_id,len(self.item_list),self.item_list[0])\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T11:48:49.562061Z",
     "start_time": "2019-12-26T11:48:49.534839Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hl6NiyNJbTRg"
   },
   "outputs": [],
   "source": [
    "class SessionDataSet(object):\n",
    "    def __init__(self,train_file,test_file,padding_idx=0):\n",
    "        super(SessionDataSet,self).__init__()\n",
    "        self.index_count = 0\n",
    "        self.session_count = 0\n",
    "        self.train_count = 0\n",
    "        self.test_count = 0\n",
    "        self.max_session_length = 0\n",
    "\n",
    "        self.padding_idx = padding_idx\n",
    "        self.item2index = dict()\n",
    "        self.index2item = dict()\n",
    "        self.session2index = dict()\n",
    "        self.index2session = dict()\n",
    "        self.item_total_num = dict()\n",
    "        self.item2index[\"<pad>\"] = padding_idx\n",
    "        self.index2item[padding_idx] = \"<pad>\"\n",
    "        self.train_data = self.load_data(train_file)\n",
    "        print(\"training set is loaded, # index: \",len(self.item2index.keys()))\n",
    "        self.train_count = self.session_count\n",
    "        print(\"train_session_num\",self.train_count)\n",
    "        self.test_data = self.load_data(test_file)\n",
    "        print(\"testing set is loaded, # index: \",len(self.index2item.keys()))\n",
    "        print(\"# item\",self.index_count)\n",
    "        self.test_count = self.session_count-self.train_count\n",
    "        print(\"# test session:\",self.test_count)\n",
    "        self.all_training_data = []\n",
    "        self.all_testing_data = []\n",
    "        self.all_meta_training_data = []\n",
    "        self.all_meta_testing_data = []\n",
    "        self.train_session_length = 0\n",
    "        self.test_session_length = 0\n",
    "    \n",
    "    def load_data(self,file_path):\n",
    "        data =  pickle.load(open(file_path, 'rb'))\n",
    "        session_ids = data[0]\n",
    "        session_data = data[1]\n",
    "        session_label = data[2]\n",
    "\n",
    "        result_data = []\n",
    "        lenth = len(session_ids)\n",
    "        print(\"# session\",lenth)\n",
    "\n",
    "        last_session_id = session_ids[0]\n",
    "        \n",
    "        session_item_indexes = []\n",
    "\n",
    "        for item_id in session_data[0]:\n",
    "            if item_id not in self.item2index.keys():\n",
    "                self.index_count+=1\n",
    "                self.item2index[item_id] = self.index_count\n",
    "                self.index2item[self.index_count] = item_id\n",
    "                self.item_total_num[self.index_count] = 0\n",
    "            session_item_indexes.append(self.item2index[item_id])\n",
    "            self.item_total_num[self.item2index[item_id]] += 1\n",
    "        target_item = session_label[0]\n",
    "        if target_item not in self.item2index.keys():\n",
    "            self.index_count+=1\n",
    "            self.item2index[target_item] = self.index_count\n",
    "            self.index2item[self.index_count] = target_item\n",
    "            self.item_total_num[self.index_count] = 0\n",
    "        session_item_indexes.append(self.item2index[target_item])\n",
    "        self.item_total_num[self.item2index[target_item]] += 1\n",
    "\n",
    "        for session_id,items,target_item in zip(session_ids,session_data,session_label):\n",
    "            if session_id!=last_session_id:\n",
    "\n",
    "                self.session_count+=1\n",
    "                self.session2index[last_session_id] = self.session_count\n",
    "                self.index2session[self.session_count] = last_session_id\n",
    "                last_session_id = session_id\n",
    "                if len(session_item_indexes)>self.max_session_length:\n",
    "                    self.max_session_length = len(session_item_indexes)\n",
    "                new_session = SessionData(self.session_count,last_session_id,session_item_indexes)\n",
    "                result_data.append(new_session)\n",
    "                session_item_indexes = []\n",
    "                for item_id in items:\n",
    "                    if item_id not in self.item2index.keys():\n",
    "                        self.index_count+=1\n",
    "                        self.item2index[item_id] = self.index_count\n",
    "                        self.index2item[self.index_count] = item_id\n",
    "                        self.item_total_num[self.index_count] = 0\n",
    "                    session_item_indexes.append(self.item2index[item_id])\n",
    "                    self.item_total_num[self.item2index[item_id]] += 1\n",
    "                if target_item not in self.item2index.keys():\n",
    "                    self.index_count+=1\n",
    "                    self.item2index[target_item] = self.index_count\n",
    "                    self.index2item[self.index_count] = target_item\n",
    "                    self.item_total_num[self.index_count] = 0\n",
    "                session_item_indexes.append(self.item2index[target_item])\n",
    "                self.item_total_num[self.item2index[target_item]] += 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        self.session_count+=1\n",
    "        self.session2index[last_session_id] = self.session_count\n",
    "        new_session = SessionData(self.session_count,last_session_id,session_item_indexes)\n",
    "        result_data.append(new_session)\n",
    "        print(\"loaded\")\n",
    "        print(new_session)\n",
    "        \n",
    "        return result_data\n",
    "    \n",
    "\n",
    "    def get_batch(self,batch_size,session_length=10,predict_length=1,all_data=None,phase=\"train\",neg_num=1,sampling_mathod=\"random\"):\n",
    "\n",
    "        if phase == \"train\":\n",
    "            if all_data is None:\n",
    "                all_data = self.get_all_training_data(session_length)\n",
    "            indexes = np.random.permutation(all_data.shape[0])\n",
    "            all_data = all_data[indexes]\n",
    "        else:\n",
    "            if all_data is None:\n",
    "                all_data = self.get_all_testing_data(session_length)\n",
    "        \n",
    "        sindex = 0\n",
    "        eindex = batch_size\n",
    "        while eindex < all_data.shape[0]:\n",
    "            batch = all_data[sindex: eindex]\n",
    "\n",
    "            temp = eindex\n",
    "            eindex = eindex + batch_size\n",
    "            sindex = temp\n",
    "            if phase ==\"train\":\n",
    "                batch = self.divid_and_extend_negative_samples(batch,session_length=session_length,predict_length=predict_length,neg_num=neg_num,method=sampling_mathod)\n",
    "            else:\n",
    "                batch = [batch[:,:session_length],batch[:,session_length:]]\n",
    "            yield batch\n",
    "\n",
    "        if eindex >= all_data.shape[0]:\n",
    "            batch = all_data[sindex:]\n",
    "            if phase ==\"train\":\n",
    "                batch = self.divid_and_extend_negative_samples(batch,session_length=session_length,predict_length=predict_length,neg_num=neg_num,method=sampling_mathod)\n",
    "            else:\n",
    "                batch = [batch[:,:session_length],batch[:,session_length:]]\n",
    "            yield batch\n",
    "    \n",
    "    def divid_and_extend_negative_samples(self,batch_data,session_length,predict_length=1,neg_num=1,method=\"random\"):\n",
    "        \"\"\"\n",
    "        divid and extend negative samples\n",
    "        \"\"\"\n",
    "        neg_items = []\n",
    "        if method == \"random\":\n",
    "            for session_and_target in batch_data:\n",
    "                neg_item = []\n",
    "                for i in range(neg_num):\n",
    "                    rand_item = random.randint(1,self.index_count)\n",
    "                    while rand_item in session_and_target or rand_item in neg_item:\n",
    "                        rand_item = random.randint(1,self.index_count)\n",
    "                    neg_item.append(rand_item)\n",
    "                neg_items.append(neg_item)\n",
    "        else:\n",
    "\n",
    "            total_list = set()\n",
    "            for session in batch_data:\n",
    "                for i in session:\n",
    "                    total_list.add(i) \n",
    "            total_list = list(total_list)\n",
    "            total_list =  sorted(total_list, key=lambda item: self.item_total_num[item],reverse=True)\n",
    "            for i,session in enumerate(batch_data):\n",
    "                np.random.choice(total_list)\n",
    "        session_items = batch_data[:,:session_length]\n",
    "        target_item = batch_data[:,session_length:]\n",
    "        neg_items = np.array(neg_items)\n",
    "        return [session_items,target_item,neg_items]\n",
    "    \n",
    "    def get_all_training_data(self,session_length,predict_length=1):\n",
    "        if len(self.all_training_data)!=0 and self.train_session_length==session_length:\n",
    "#             print(\"The build is complete and there is no need to repeat the build\")\n",
    "            return self.all_training_data\n",
    "        print(\"Start building the all training dataset\")\n",
    "        all_sessions = []\n",
    "        for session_data in self.train_data:\n",
    "            # 前session_length为session，后predict_length为target_item\n",
    "            session_index,sessions = session_data.generate_seq_datas(session_length,padding_idx=self.padding_idx)\n",
    "            if sessions is not None:\n",
    "                all_sessions.extend(sessions)\n",
    "        all_sessions = np.array(all_sessions)\n",
    "        self.all_training_data = all_sessions\n",
    "        self.train_session_length=session_length\n",
    "        print(\"The total number of training samples is：\",all_sessions.shape)\n",
    "        return all_sessions\n",
    "    \n",
    "    def get_all_testing_data(self,session_length,predict_length=1):\n",
    "        if len(self.all_testing_data)!=0 and self.test_session_length==session_length:\n",
    "            return self.all_testing_data\n",
    "        all_sessions = []\n",
    "        for session_data in self.test_data:\n",
    "            session_index,sessions = session_data.generate_seq_datas(session_length,padding_idx=self.padding_idx)\n",
    "            if sessions is not None:\n",
    "                all_sessions.extend(sessions)\n",
    "        all_sessions = np.array(all_sessions)\n",
    "        self.all_testing_data = all_sessions\n",
    "        self.test_session_length=session_length\n",
    "        print(\"The total number of testing samples is：\",all_sessions.shape)\n",
    "        return all_sessions\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-26T11:48:48.096Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "ctSu0HF8bUqh",
    "outputId": "7287ecc0-f73d-4883-c8f6-20c9b8aeddb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# session 5917745\n",
      "loaded\n",
      " session index = 1922630\n",
      " session id = 11497318 \n",
      " the length of item list= 3 \n",
      " the fisrt item index in item list is 29411\n",
      "training set is loaded, # index:  30445\n",
      "train_session_num 1922630\n",
      "# session 55898\n",
      "loaded\n",
      " session index = 1937954\n",
      " session id = 11560908 \n",
      " the length of item list= 3 \n",
      " the fisrt item index in item list is 4105\n",
      "testing set is loaded, # index:  30471\n",
      "# item 30470\n",
      "# test session: 15324\n"
     ]
    }
   ],
   "source": [
    "# dataset = SessionDataSet(train_file=\"../data/retailrocket/train.txt\",test_file=\"../data/srgnn/retailrocket/test.txt\")\n",
    "# dataset = SessionDataSet(train_file=\"../data/diginetica/train.txt\",test_file=\"../data/srgnn/diginetica/test.txt\")\n",
    "dataset = SessionDataSet(train_file=\"../data/yoochoose1_4/train.txt\",test_file=\"../data/srgnn/yoochoose1_4/test.txt\")\n",
    "# dataset = SessionDataSet(train_file=\"../data/yoochoose1_64/train.txt\",test_file=\"../data/srgnn/yoochoose1_64/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-26T11:48:48.097Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "cm7qU4B6bq2i"
   },
   "outputs": [],
   "source": [
    "def bpr_loss(r):\n",
    "    return torch.sum(-torch.log(torch.sigmoid(r)))\n",
    "def get_hit_num(pred,y_truth):\n",
    "    \"\"\"\n",
    "        pred: numpy type(batch_size,k) \n",
    "        y_truth: list type (batch_size,groudtruth_num)\n",
    "    \"\"\"\n",
    "\n",
    "    hit_num = 0\n",
    "    for i in range(len(y_truth)):\n",
    "        for value in y_truth[i]:\n",
    "            hit_num += np.sum(pred[i]==value)\n",
    "    return hit_num\n",
    "\n",
    "def get_rr(pred,y_truth):\n",
    "    rr=0.\n",
    "    for i in range(len(y_truth)):\n",
    "        for value in y_truth[i]:\n",
    "            hit_indexes = np.where(pred[i]==value)[0]\n",
    "            for hit_index in hit_indexes:\n",
    "                rr += 1/(hit_index+1)\n",
    "    return rr\n",
    "\n",
    "def get_dcg(pred,y_truth):\n",
    "    y_pred_score = np.zeros_like(pred)\n",
    "\n",
    "    for i in range(len(y_truth)):\n",
    "\n",
    "        for j,y_pred in enumerate(pred[i]):\n",
    "            if y_pred == y_truth[i][0]:\n",
    "                y_pred_score[i][j]=1\n",
    "    gain = 2 ** y_pred_score - 1\n",
    "    discounts = np.tile(np.log2(np.arange(pred.shape[1]) + 2),(len(y_truth),1))\n",
    "    dcg = np.sum(gain / discounts,axis=1)\n",
    "    return dcg\n",
    "\n",
    "def get_ndcg(pred,y_truth):\n",
    "    dcg = get_dcg(pred, y_truth)\n",
    "    idcg = get_dcg(np.concatenate((y_truth,np.zeros_like(pred)[:,:-1]-1),axis=1), y_truth)\n",
    "    ndcg = np.sum(dcg / idcg)\n",
    "\n",
    "    return ndcg\n",
    "\n",
    "def dcg_score(y_pre, y_true, k):\n",
    "    y_pre_score = np.zeros(k)\n",
    "    if len(y_pre) > k:\n",
    "        y_pre = y_pre[:k]\n",
    "    for i in range(len(y_pre)):\n",
    "        pre_tag = y_pre[i]\n",
    "        if pre_tag in y_true:\n",
    "            y_pre_score[i] = 1\n",
    "    gain = 2 ** y_pre_score - 1\n",
    "    discounts = np.log2(np.arange(k) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_pre, y_true, k=5):\n",
    "    dcg = dcg_score(y_pre, y_true, k)\n",
    "    idcg = dcg_score(y_true, y_true, k)\n",
    "    return dcg / idcg\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-26T11:48:48.099Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "QdNvTTApbr_g"
   },
   "outputs": [],
   "source": [
    "# SelfAttention Layer\n",
    "class SelfAttention(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size,activate=\"selu\",dropout=0):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.config = list()\n",
    "        # 使用的Attention方法\n",
    "        self.method = method\n",
    "        # 隐藏层大小\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method not in ['dot', 'general']:\n",
    "            raise ValueError(self.method, \"Attention method do not exists.\")\n",
    "\n",
    "        if self.method == \"dot\":\n",
    "            self.query = torch.nn.Linear(self.hidden_size *2, self.hidden_size*2)\n",
    "            self.key = torch.nn.Linear(self.hidden_size*2, self.hidden_size*2)\n",
    "            torch.nn.init.constant_(self.query.bias,0)\n",
    "            torch.nn.init.constant_(self.key.bias,0)\n",
    "\n",
    "        if self.method == \"general\":\n",
    "            self.attention = torch.nn.Linear(self.hidden_size*2, self.hidden_size*2)\n",
    "            torch.nn.init.constant_(self.attention.bias,0)\n",
    "        \n",
    "        if activate == \"relu\":\n",
    "            self.activate = torch.relu\n",
    "        elif activate == \"tanh\":\n",
    "            self.activate = torch.tanh\n",
    "        elif activate == \"elu\":\n",
    "            self.activate = torch.nn.ELU()\n",
    "        elif activate == \"selu\":\n",
    "            self.activate = torch.selu\n",
    "        else:\n",
    "            self.activate = torch.sigmoid\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        torch.nn.utils.clip_grad_norm_(self.parameters(),max_norm=110)\n",
    "\n",
    "    def dot_score(self, encoder_output,is_train=True,weights=None):\n",
    "\n",
    "        if weights is None:\n",
    "            if is_train:\n",
    "                query = self.dropout(self.activate(self.query(encoder_output)))\n",
    "                key = self.dropout(self.activate(self.key(encoder_output)))\n",
    "            else:\n",
    "                query = self.activate(self.query(encoder_output))\n",
    "                key = self.activate(self.key(encoder_output))\n",
    "        else:\n",
    "            query = self.activate(torch.matmul(encoder_output,weights[0].t())+weights[1])\n",
    "            key = self.activate(torch.matmul(encoder_output,weights[2].t())+weights[3])\n",
    "        dot = query.bmm(key.permute(0, 2, 1))\n",
    "        return dot\n",
    "\n",
    "    def general_score(self, encoder_output,is_train=True,weights=None):\n",
    "        if weights is None:\n",
    "            if is_train:\n",
    "                energy = self.dropout(self.activate(self.attention(encoder_output)))\n",
    "            else:\n",
    "                energy = self.activate(self.attention(encoder_output))\n",
    "        else:\n",
    "            energy = self.activate(torch.matmul(encoder_output,weights[0].t())+weights[1])\n",
    "        return encoder_output.bmm(energy.permute(0, 2, 1))\n",
    "\n",
    "    def forward(self, encoder_outputs, mask=None,is_train=True):\n",
    "        # (batch_size,length,dim)\n",
    "        if self.method == \"general\":\n",
    "            attention_energies = self.general_score(encoder_outputs,is_train=is_train)\n",
    "        elif self.method == \"dot\":\n",
    "            attention_energies = self.dot_score(encoder_outputs,is_train=is_train)\n",
    "\n",
    "        #  (batch_size,length,length)\n",
    "        attention_energies.div_(torch.sqrt(torch.tensor(self.hidden_size, dtype=torch.float)))\n",
    "        if mask is not None:\n",
    "            new_mask = (1 - (1 - mask.float()).unsqueeze(1).permute(0, 2, 1).bmm(\n",
    "                (1 - mask.float()).unsqueeze(1)))\n",
    "\n",
    "            attention_energies = attention_energies - new_mask*1e12\n",
    "            weights = F.softmax(attention_energies, dim=2)\n",
    "            weights = weights*(1-new_mask)\n",
    "            # batch_size,length,length)*(batch_size,length,dim)->(batch_size,length,dim)->(batch_size,1,dim)->(batch_size,dim)\n",
    "            outputs = weights.bmm(encoder_outputs)\n",
    "            outputs.div_(mask.shape[1]-torch.sum(mask,dim=1).unsqueeze(1).unsqueeze(2).repeat((1,mask.shape[1],outputs.shape[2])).float())\n",
    "            outputs = outputs.sum(dim=1).squeeze(1)\n",
    "        else:\n",
    "            weights = F.softmax(attention_energies, dim=2)\n",
    "            # (batch_size,length,length)*(batch_size,length,dim)->(batch_size,length,dim)->(batch_size,1,dim)->(batch_size,dim)\n",
    "            outputs = (weights.bmm(encoder_outputs).sum(dim=1) / encoder_outputs.shape[1]).squeeze(1)\n",
    "        sa_weights = weights.sum(dim=1).squeeze(1)\n",
    "        return outputs, sa_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-26T11:48:48.100Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aVIrdlmKbtUq"
   },
   "outputs": [],
   "source": [
    "class POEM(torch.nn.Module):\n",
    "    def __init__(self, hidden_size=64, itemNum=0, posNum=0, padding_idx=0, dropout=0.5,attention_method=\"dot\",head_num=4,\n",
    "                 activate=\"selu\",session_length=20,delta=16.0):\n",
    "        super(POEM, self).__init__()\n",
    "        self.padding_idx = padding_idx\n",
    "        self.hidden_size = hidden_size\n",
    "        self.head_num = head_num\n",
    "        self.delta = delta\n",
    "        self.session_length = session_length\n",
    "        if activate == \"sigmoid\":\n",
    "            self.activate = torch.sigmoid\n",
    "        elif activate == \"tanh\":\n",
    "            self.activate = torch.tanh\n",
    "        elif activate == \"relu\":\n",
    "            self.activate = torch.relu\n",
    "        elif activate == \"elu\":\n",
    "            self.activate = torch.nn.ELU()\n",
    "        else:\n",
    "            self.activate = torch.selu\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.item_embedding = torch.nn.Embedding(itemNum, hidden_size, padding_idx=self.padding_idx,max_norm=1.5)\n",
    "        \n",
    "        self.position_embedding = torch.nn.Embedding(posNum,hidden_size,padding_idx=self.padding_idx,max_norm=1.5)\n",
    "    \n",
    "        self.position_weights = torch.nn.Embedding(posNum,1,padding_idx=self.padding_idx)\n",
    "        \n",
    "        self.self_attention = SelfAttention(attention_method, hidden_size,activate=activate,dropout=dropout).to(device)\n",
    "        torch.nn.init.constant_(self.item_embedding.weight[0],0)\n",
    "        torch.nn.init.constant_(self.position_embedding.weight[0],0)\n",
    "        torch.nn.init.constant_(self.position_weights.weight,1)\n",
    "        torch.nn.init.constant_(self.position_weights.weight[0],0)\n",
    "        \n",
    "        self.gen_mlp = torch.nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.cur_mlp = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.deep_mlp = torch.nn.Linear(hidden_size*3, hidden_size,bias=False)\n",
    "        \n",
    "    def forward(self, session,item=None,bpr_loss=False,neg_num=50):\n",
    "\n",
    "        mask = (session!=0).float()\n",
    "        length = torch.sum(mask,1).unsqueeze(1).repeat((1,self.hidden_size))\n",
    "        mask = mask.unsqueeze(2).repeat((1,1,self.hidden_size))\n",
    "        session_item_embeddings = F.normalize(self.item_embedding(session),dim=-1)* mask\n",
    "        positions = session.shape[1] - torch.arange(0,session.shape[1]).unsqueeze(0).repeat((session.shape[0],1)).to(device)\n",
    "        session_position_embeddings = self.dropout(self.position_embedding(positions))*mask\n",
    "        session_item_vecs = torch.cat((session_item_embeddings,session_position_embeddings), dim=2)\n",
    "        attention_mask = (session == self.padding_idx)\n",
    "        sa_output, sa_weights = self.self_attention(session_item_vecs, attention_mask)\n",
    "        session_position_weights = self.dropout(self.position_weights(positions))*mask\n",
    "        sa_weights = sa_weights.unsqueeze(2).repeat((1,1,self.hidden_size))\n",
    "        session_item_vecs2 = session_item_embeddings * session_position_weights * sa_weights\n",
    "        psa_output = torch.sum(session_item_vecs2, dim=1)/length\n",
    "        gen_output = self.dropout(self.activate(self.gen_mlp(sa_output)))\n",
    "        cur_output = self.dropout(self.activate(self.cur_mlp(session_item_embeddings[:,-1])))\n",
    "        deep_output = self.dropout(self.activate(self.deep_mlp(torch.cat((sa_output,session_item_embeddings[:,-1]),1))))\n",
    "        session_output =  F.normalize(gen_output * cur_output + deep_output + psa_output,dim=-1)\n",
    "        session_output = session_output*self.delta\n",
    "        item_embedding_weight = F.normalize(self.item_embedding.weight[1:],dim=-1)\n",
    "        result = torch.matmul(session_output,item_embedding_weight.t())\n",
    "        return result\n",
    "    \n",
    "    def predict_top_k(self, session, k=20):\n",
    "        mask = (session!=0).float()\n",
    "        length = torch.sum(mask,1).unsqueeze(1).repeat((1,self.hidden_size))\n",
    "        mask = mask.unsqueeze(2).repeat((1,1,self.hidden_size))\n",
    "        session_item_embeddings = F.normalize(self.item_embedding(session),dim=-1)* mask\n",
    "        positions = session.shape[1] - torch.arange(0,session.shape[1]).unsqueeze(0).repeat((session.shape[0],1)).to(device)\n",
    "        session_position_embeddings = self.position_embedding(positions)*mask\n",
    "        session_item_vecs = torch.cat((session_item_embeddings,session_position_embeddings), dim=2)\n",
    "        attention_mask = (session == self.padding_idx)\n",
    "        sa_output, sa_weights = self.self_attention(session_item_vecs, attention_mask,is_train=False)\n",
    "        session_position_weights = self.position_weights(positions)*mask\n",
    "        sa_weights = sa_weights.unsqueeze(2).repeat((1,1,self.hidden_size))\n",
    "        session_item_vecs2 = session_item_embeddings * session_position_weights * sa_weights\n",
    "        psa_output = torch.sum(session_item_vecs2, dim=1)/length\n",
    "        gen_output =self.activate(self.gen_mlp(sa_output))\n",
    "\n",
    "        cur_output = self.activate(self.cur_mlp(session_item_embeddings[:,-1]))\n",
    "        deep_output = self.activate(self.deep_mlp(torch.cat((sa_output,session_item_embeddings[:,-1]),1)))\n",
    "        session_output =  F.normalize(gen_output * cur_output + deep_output + psa_output,dim=-1)\n",
    "        session_output = session_output * self.delta\n",
    "        item_embedding_weight = F.normalize(self.item_embedding.weight[1:],dim=-1)\n",
    "        result = torch.matmul(session_output,item_embedding_weight.t())\n",
    "        result = torch.topk(result,k,dim=1)[1]\n",
    "        \n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-26T11:48:48.102Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Jhrg56xebung"
   },
   "outputs": [],
   "source": [
    "epochs=50\n",
    "def train(args):\n",
    "    hidden_size = args[\"hidden_size\"] if \"hidden_size\" in args.keys() else 100\n",
    "    dropout = args[\"dropout\"] if \"dropout\" in args.keys()  else 0.5\n",
    "    attention_method = args[\"method\"] if \"method\" in args.keys()  else \"general\"\n",
    "    lr = args[\"lr\"] if \"lr\" in args.keys()  else 5e-4\n",
    "    weight_decay = args[\"weight_decay\"] if \"weight_decay\" in args.keys()  else 1e-5\n",
    "    amsgrad = args[\"amsgrad\"] if \"amsgrad\" in args.keys() else True\n",
    "    session_length = args[\"session_length\"] if \"session_length\" in args.keys() else 20\n",
    "    delta = args[\"delta\"] if \"delta\" in args.keys() else 20\n",
    "    model = POEM(hidden_size=hidden_size, itemNum=dataset.index_count+1, posNum=session_length+1, padding_idx=0, dropout=dropout,\n",
    "                 activate=\"selu\",attention_method=attention_method,delta=delta).to(device)\n",
    "    opti = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay,amsgrad=amsgrad)\n",
    "    patience = args[\"patience\"] if \"patience\" in args.keys() else 5\n",
    "    best_model_hr = 0.0\n",
    "    best_model_mrr = 0.0\n",
    "    best_r1m = 0.0\n",
    "    best_model = None\n",
    "    predict_nums = [1,5,10,20]\n",
    "    no_improvement_epoch = 0\n",
    "    for epoch in range(epochs):\n",
    "        batch_losses = []\n",
    "        epoch_losses = []\n",
    "        for i,batch_data in enumerate(dataset.get_batch(batch_size,session_length,phase=\"train\")):\n",
    "            sessions = torch.tensor(batch_data[0]).to(device)\n",
    "            target_items = torch.tensor(batch_data[1]).squeeze().to(device)-1\n",
    "            result_pos = model(sessions)\n",
    "            loss = loss_function(result_pos,target_items)\n",
    "            opti.zero_grad()\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "            batch_losses.append(loss.cpu().detach().numpy())\n",
    "            epoch_losses.append(loss.cpu().detach().numpy())\n",
    "            if i % plot_num == 0:\n",
    "                time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                print(\"[%s] [%d/%d] %d mean_batch_loss : %0.6f\" % (time, epoch+1, epochs, i, np.mean(batch_losses)))\n",
    "                batch_losses = []\n",
    "        with torch.no_grad():\n",
    "            start_test_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(\"Start predicting\",start_test_time)\n",
    "            rrs = [0 for _ in range(len(predict_nums))]\n",
    "            hit_nums = [0 for _ in range(len(predict_nums))]\n",
    "            ndcgs = [0 for _ in range(len(predict_nums))]\n",
    "            for i,batch_data in enumerate(dataset.get_batch(batch_size,session_length,phase=\"test\")):\n",
    "                \n",
    "                sessions = torch.tensor(batch_data[0]).to(device)\n",
    "                target_items = np.array(batch_data[1])-1\n",
    "                y_pred = model.predict_top_k(sessions,20).cpu().numpy()\n",
    "                \n",
    "                for j,predict_num in enumerate(predict_nums):\n",
    "                    hit_nums[j]+=get_hit_num(y_pred[:,:predict_num],target_items)\n",
    "                    rrs[j]+=get_rr(y_pred[:,:predict_num],target_items)\n",
    "                    ndcgs[j]+=get_ndcg(y_pred[:,:predict_num],target_items)\n",
    "                    \n",
    "            end_test_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            hrs = [hit_num/len(dataset.all_testing_data) for hit_num in hit_nums]\n",
    "            mrrs = [rr/len(dataset.all_testing_data) for rr in rrs]\n",
    "            mndcgs = [ndcg/len(dataset.all_testing_data) for ndcg in ndcgs]\n",
    "            if hrs[-1] + mrrs[-1] > best_r1m:\n",
    "                print(\"change best\")\n",
    "                best_model = deepcopy(model)\n",
    "                best_model_hr = hrs[-1]\n",
    "                best_model_mrr = mrrs[-1]\n",
    "                best_r1m = hrs[-1] + mrrs[-1]\n",
    "                no_improvement_epoch = 0\n",
    "            else:\n",
    "                no_improvement_epoch +=1\n",
    "            print(\"testing finish [%s] \"%end_test_time)\n",
    "            for k,predict_num in enumerate(predict_nums):\n",
    "                print(\"\\tHR@%d=%.5f  MRR@%d=%.5f  NDCG@%d=%.5f\"%(predict_num,hrs[k],predict_num,mrrs[k],predict_num,mndcgs[k]))\n",
    "        if no_improvement_epoch>=patience:\n",
    "            print(\"early stopping\")\n",
    "            break\n",
    "    return best_model,best_model_hr,best_model_mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2H2SFJ7F77Z0"
   },
   "source": [
    "# CIKM-Session >= 2\n",
    "    HR@20=0.66609  MRR@20=0.32079, hyper-parameters: session_length-20, hidden_size-100, lr-0.0010,delta=16.0, amsgrad-True, method-general, dropout-0.5, weight_decay-0.000000.\n",
    "        HR@1=0.20653  MRR@1=0.20653  NDCG@1=0.20653\n",
    "        HR@5=0.45729  MRR@5=0.29951  NDCG@5=0.33882\n",
    "        HR@10=0.56267  MRR@10=0.31356  NDCG@10=0.37289\n",
    "        HR@20=0.66609  MRR@20=0.32079  NDCG@20=0.39909\n",
    "# RR-Session >= 2\n",
    "    HR@20=0.63097  MRR@20=0.36671, hyper-parameters: session_length-20, hidden_size-100, lr-0.0005,delta=16.0, amsgrad-True, method-general, dropout-0.5, weight_decay-0.000000. \n",
    "        HR@1=0.27421  MRR@1=0.27421  NDCG@1=0.27421\n",
    "        HR@5=0.48163  MRR@5=0.35128  NDCG@5=0.38378\n",
    "        HR@10=0.55950  MRR@10=0.36171  NDCG@10=0.40899\n",
    "        HR@20=0.63097  MRR@20=0.36671  NDCG@20=0.42711\n",
    "# RSC64-Session >= 2\n",
    "    HR@20=0.71958  MRR@20=0.31782, hyper-parameters: session_length-20, hidden_size-100, lr-0.0005,delta=16.0, amsgrad-True, method-general, dropout-0.5, weight_decay-0.000000. \n",
    "        HR@1=0.18518  MRR@1=0.18518  NDCG@1=0.18518\n",
    "        HR@5=0.48449  MRR@5=0.29292  NDCG@5=0.34050\n",
    "        HR@10=0.61466  MRR@10=0.31042  NDCG@10=0.38272\n",
    "        HR@20=0.71958  MRR@20=0.31782  NDCG@20=0.40940\n",
    "# RSC4-Session >= 2\n",
    "    HR@20=0.72436  MRR@20=0.32078, hyper-parameters: session_length-20, hidden_size-100, lr-0.0003,delta=16.0, amsgrad-True, method-general, dropout-0.3, weight_decay-0.000000. \n",
    "        HR@1=0.18877  MRR@1=0.18877  NDCG@1=0.18877\n",
    "        HR@5=0.48742  MRR@5=0.29579  NDCG@5=0.34335\n",
    "        HR@10=0.61732  MRR@10=0.31321  NDCG@10=0.38544\n",
    "        HR@20=0.72436  MRR@20=0.32078  NDCG@20=0.41267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-26T11:48:48.212Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "S8pn0Z7bbv4t",
    "outputId": "c1aa9692-56a0-40d2-d99b-e75b4f1e537e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0005,delta=16.0, amsgrad=True, method=general, dropout=0.3, weight_decay=0.000000. \n",
      "\n",
      "Start building the all training dataset\n",
      "The total number of training samples is： (5917745, 21)\n",
      "[2019-12-26 19:49:20] [1/50] 0 mean_batch_loss : 10.341468\n",
      "Start predicting 2019-12-26 19:51:07\n",
      "The total number of testing samples is： (55898, 21)\n",
      "change best\n",
      "testing finish [2019-12-26 19:51:11] \n",
      "\tHR@1=0.17419  MRR@1=0.17419  NDCG@1=0.17419\n",
      "\tHR@5=0.46238  MRR@5=0.27797  NDCG@5=0.32376\n",
      "\tHR@10=0.59308  MRR@10=0.29547  NDCG@10=0.36608\n",
      "\tHR@20=0.69902  MRR@20=0.30295  NDCG@20=0.39303\n",
      "[2019-12-26 19:51:11] [2/50] 0 mean_batch_loss : 4.155847\n",
      "Start predicting 2019-12-26 19:52:59\n",
      "change best\n",
      "testing finish [2019-12-26 19:53:03] \n",
      "\tHR@1=0.18181  MRR@1=0.18181  NDCG@1=0.18181\n",
      "\tHR@5=0.47284  MRR@5=0.28680  NDCG@5=0.33302\n",
      "\tHR@10=0.60208  MRR@10=0.30412  NDCG@10=0.37488\n",
      "\tHR@20=0.71099  MRR@20=0.31184  NDCG@20=0.40262\n",
      "[2019-12-26 19:53:03] [3/50] 0 mean_batch_loss : 3.983668\n",
      "Start predicting 2019-12-26 19:54:51\n",
      "change best\n",
      "testing finish [2019-12-26 19:54:55] \n",
      "\tHR@1=0.18289  MRR@1=0.18289  NDCG@1=0.18289\n",
      "\tHR@5=0.47689  MRR@5=0.28896  NDCG@5=0.33563\n",
      "\tHR@10=0.60730  MRR@10=0.30648  NDCG@10=0.37792\n",
      "\tHR@20=0.71444  MRR@20=0.31403  NDCG@20=0.40516\n",
      "[2019-12-26 19:54:55] [4/50] 0 mean_batch_loss : 3.974511\n",
      "Start predicting 2019-12-26 19:56:49\n",
      "change best\n",
      "testing finish [2019-12-26 19:56:53] \n",
      "\tHR@1=0.18489  MRR@1=0.18489  NDCG@1=0.18489\n",
      "\tHR@5=0.47873  MRR@5=0.29047  NDCG@5=0.33721\n",
      "\tHR@10=0.60906  MRR@10=0.30799  NDCG@10=0.37948\n",
      "\tHR@20=0.71690  MRR@20=0.31562  NDCG@20=0.40693\n",
      "[2019-12-26 19:56:54] [5/50] 0 mean_batch_loss : 4.173106\n",
      "Start predicting 2019-12-26 19:59:56\n",
      "change best\n",
      "testing finish [2019-12-26 20:00:00] \n",
      "\tHR@1=0.18530  MRR@1=0.18530  NDCG@1=0.18530\n",
      "\tHR@5=0.48109  MRR@5=0.29160  NDCG@5=0.33864\n",
      "\tHR@10=0.61253  MRR@10=0.30922  NDCG@10=0.38123\n",
      "\tHR@20=0.71929  MRR@20=0.31676  NDCG@20=0.40838\n",
      "[2019-12-26 20:00:00] [6/50] 0 mean_batch_loss : 3.884326\n",
      "Start predicting 2019-12-26 20:03:55\n",
      "testing finish [2019-12-26 20:03:59] \n",
      "\tHR@1=0.18346  MRR@1=0.18346  NDCG@1=0.18346\n",
      "\tHR@5=0.48023  MRR@5=0.29052  NDCG@5=0.33764\n",
      "\tHR@10=0.61369  MRR@10=0.30843  NDCG@10=0.38090\n",
      "\tHR@20=0.72003  MRR@20=0.31593  NDCG@20=0.40794\n",
      "[2019-12-26 20:03:59] [7/50] 0 mean_batch_loss : 3.741303\n",
      "Start predicting 2019-12-26 20:07:32\n",
      "change best\n",
      "testing finish [2019-12-26 20:07:37] \n",
      "\tHR@1=0.18559  MRR@1=0.18559  NDCG@1=0.18559\n",
      "\tHR@5=0.48190  MRR@5=0.29212  NDCG@5=0.33924\n",
      "\tHR@10=0.61299  MRR@10=0.30978  NDCG@10=0.38180\n",
      "\tHR@20=0.72020  MRR@20=0.31737  NDCG@20=0.40909\n",
      "[2019-12-26 20:07:37] [8/50] 0 mean_batch_loss : 3.916356\n",
      "Start predicting 2019-12-26 20:10:34\n",
      "change best\n",
      "testing finish [2019-12-26 20:10:38] \n",
      "\tHR@1=0.18716  MRR@1=0.18716  NDCG@1=0.18716\n",
      "\tHR@5=0.48139  MRR@5=0.29276  NDCG@5=0.33958\n",
      "\tHR@10=0.61333  MRR@10=0.31052  NDCG@10=0.38239\n",
      "\tHR@20=0.72060  MRR@20=0.31809  NDCG@20=0.40967\n",
      "[2019-12-26 20:10:38] [9/50] 0 mean_batch_loss : 3.924184\n",
      "Start predicting 2019-12-26 20:13:54\n",
      "change best\n",
      "testing finish [2019-12-26 20:13:58] \n",
      "\tHR@1=0.18654  MRR@1=0.18654  NDCG@1=0.18654\n",
      "\tHR@5=0.48161  MRR@5=0.29234  NDCG@5=0.33932\n",
      "\tHR@10=0.61623  MRR@10=0.31047  NDCG@10=0.38301\n",
      "\tHR@20=0.72190  MRR@20=0.31788  NDCG@20=0.40983\n",
      "[2019-12-26 20:13:59] [10/50] 0 mean_batch_loss : 3.880198\n",
      "Start predicting 2019-12-26 20:16:58\n",
      "change best\n",
      "testing finish [2019-12-26 20:17:02] \n",
      "\tHR@1=0.18705  MRR@1=0.18705  NDCG@1=0.18705\n",
      "\tHR@5=0.48247  MRR@5=0.29369  NDCG@5=0.34059\n",
      "\tHR@10=0.61525  MRR@10=0.31157  NDCG@10=0.38369\n",
      "\tHR@20=0.72160  MRR@20=0.31909  NDCG@20=0.41075\n",
      "[2019-12-26 20:17:03] [11/50] 0 mean_batch_loss : 3.952329\n",
      "Start predicting 2019-12-26 20:18:51\n",
      "testing finish [2019-12-26 20:18:55] \n",
      "\tHR@1=0.18629  MRR@1=0.18629  NDCG@1=0.18629\n",
      "\tHR@5=0.48300  MRR@5=0.29310  NDCG@5=0.34025\n",
      "\tHR@10=0.61652  MRR@10=0.31107  NDCG@10=0.38357\n",
      "\tHR@20=0.72217  MRR@20=0.31846  NDCG@20=0.41036\n",
      "[2019-12-26 20:18:55] [12/50] 0 mean_batch_loss : 4.096994\n",
      "Start predicting 2019-12-26 20:20:43\n",
      "testing finish [2019-12-26 20:20:47] \n",
      "\tHR@1=0.18618  MRR@1=0.18618  NDCG@1=0.18618\n",
      "\tHR@5=0.48342  MRR@5=0.29321  NDCG@5=0.34044\n",
      "\tHR@10=0.61485  MRR@10=0.31090  NDCG@10=0.38310\n",
      "\tHR@20=0.72215  MRR@20=0.31848  NDCG@20=0.41039\n",
      "[2019-12-26 20:20:48] [13/50] 0 mean_batch_loss : 3.795645\n",
      "Start predicting 2019-12-26 20:22:36\n",
      "change best\n",
      "testing finish [2019-12-26 20:22:40] \n",
      "\tHR@1=0.18739  MRR@1=0.18739  NDCG@1=0.18739\n",
      "\tHR@5=0.48442  MRR@5=0.29412  NDCG@5=0.34136\n",
      "\tHR@10=0.61625  MRR@10=0.31187  NDCG@10=0.38414\n",
      "\tHR@20=0.72368  MRR@20=0.31943  NDCG@20=0.41144\n",
      "[2019-12-26 20:22:40] [14/50] 0 mean_batch_loss : 4.006237\n",
      "Start predicting 2019-12-26 20:24:50\n",
      "testing finish [2019-12-26 20:24:54] \n",
      "\tHR@1=0.18548  MRR@1=0.18548  NDCG@1=0.18548\n",
      "\tHR@5=0.48302  MRR@5=0.29275  NDCG@5=0.34000\n",
      "\tHR@10=0.61684  MRR@10=0.31075  NDCG@10=0.38342\n",
      "\tHR@20=0.72253  MRR@20=0.31820  NDCG@20=0.41029\n",
      "[2019-12-26 20:24:55] [15/50] 0 mean_batch_loss : 3.860820\n",
      "Start predicting 2019-12-26 20:28:09\n",
      "testing finish [2019-12-26 20:28:13] \n",
      "\tHR@1=0.18920  MRR@1=0.18920  NDCG@1=0.18920\n",
      "\tHR@5=0.48479  MRR@5=0.29530  NDCG@5=0.34233\n",
      "\tHR@10=0.61600  MRR@10=0.31291  NDCG@10=0.38486\n",
      "\tHR@20=0.72237  MRR@20=0.32040  NDCG@20=0.41189\n",
      "[2019-12-26 20:28:14] [16/50] 0 mean_batch_loss : 3.946540\n",
      "Start predicting 2019-12-26 20:30:40\n",
      "testing finish [2019-12-26 20:30:43] \n",
      "\tHR@1=0.18729  MRR@1=0.18729  NDCG@1=0.18729\n",
      "\tHR@5=0.48467  MRR@5=0.29420  NDCG@5=0.34150\n",
      "\tHR@10=0.61632  MRR@10=0.31190  NDCG@10=0.38420\n",
      "\tHR@20=0.72210  MRR@20=0.31936  NDCG@20=0.41109\n",
      "[2019-12-26 20:30:44] [17/50] 0 mean_batch_loss : 3.971563\n",
      "Start predicting 2019-12-26 20:32:32\n",
      "testing finish [2019-12-26 20:32:36] \n",
      "\tHR@1=0.18788  MRR@1=0.18788  NDCG@1=0.18788\n",
      "\tHR@5=0.48427  MRR@5=0.29432  NDCG@5=0.34147\n",
      "\tHR@10=0.61571  MRR@10=0.31202  NDCG@10=0.38413\n",
      "\tHR@20=0.72328  MRR@20=0.31962  NDCG@20=0.41150\n",
      "[2019-12-26 20:32:37] [18/50] 0 mean_batch_loss : 3.737828\n",
      "Start predicting 2019-12-26 20:34:33\n",
      "testing finish [2019-12-26 20:34:37] \n",
      "\tHR@1=0.18807  MRR@1=0.18807  NDCG@1=0.18807\n",
      "\tHR@5=0.48368  MRR@5=0.29444  NDCG@5=0.34142\n",
      "\tHR@10=0.61591  MRR@10=0.31225  NDCG@10=0.38435\n",
      "\tHR@20=0.72274  MRR@20=0.31979  NDCG@20=0.41152\n",
      "[2019-12-26 20:34:38] [19/50] 0 mean_batch_loss : 3.971844\n",
      "Start predicting 2019-12-26 20:37:50\n",
      "testing finish [2019-12-26 20:37:54] \n",
      "\tHR@1=0.18845  MRR@1=0.18845  NDCG@1=0.18845\n",
      "\tHR@5=0.48376  MRR@5=0.29453  NDCG@5=0.34152\n",
      "\tHR@10=0.61639  MRR@10=0.31239  NDCG@10=0.38457\n",
      "\tHR@20=0.72185  MRR@20=0.31986  NDCG@20=0.41143\n",
      "[2019-12-26 20:37:55] [20/50] 0 mean_batch_loss : 3.867819\n",
      "Start predicting 2019-12-26 20:40:16\n",
      "testing finish [2019-12-26 20:40:20] \n",
      "\tHR@1=0.18800  MRR@1=0.18800  NDCG@1=0.18800\n",
      "\tHR@5=0.48440  MRR@5=0.29471  NDCG@5=0.34181\n",
      "\tHR@10=0.61580  MRR@10=0.31239  NDCG@10=0.38445\n",
      "\tHR@20=0.72244  MRR@20=0.31991  NDCG@20=0.41156\n",
      "[2019-12-26 20:40:21] [21/50] 0 mean_batch_loss : 3.995771\n",
      "Start predicting 2019-12-26 20:42:08\n",
      "testing finish [2019-12-26 20:42:12] \n",
      "\tHR@1=0.18745  MRR@1=0.18745  NDCG@1=0.18745\n",
      "\tHR@5=0.48331  MRR@5=0.29388  NDCG@5=0.34092\n",
      "\tHR@10=0.61480  MRR@10=0.31162  NDCG@10=0.38363\n",
      "\tHR@20=0.72173  MRR@20=0.31915  NDCG@20=0.41080\n",
      "[2019-12-26 20:42:13] [22/50] 0 mean_batch_loss : 3.755747\n",
      "Start predicting 2019-12-26 20:44:00\n",
      "testing finish [2019-12-26 20:44:04] \n",
      "\tHR@1=0.18679  MRR@1=0.18679  NDCG@1=0.18679\n",
      "\tHR@5=0.48492  MRR@5=0.29371  NDCG@5=0.34117\n",
      "\tHR@10=0.61587  MRR@10=0.31137  NDCG@10=0.38369\n",
      "\tHR@20=0.72233  MRR@20=0.31888  NDCG@20=0.41077\n",
      "[2019-12-26 20:44:05] [23/50] 0 mean_batch_loss : 3.972832\n",
      "Start predicting 2019-12-26 20:45:52\n",
      "testing finish [2019-12-26 20:45:56] \n",
      "\tHR@1=0.18638  MRR@1=0.18638  NDCG@1=0.18638\n",
      "\tHR@5=0.48352  MRR@5=0.29355  NDCG@5=0.34073\n",
      "\tHR@10=0.61596  MRR@10=0.31137  NDCG@10=0.38371\n",
      "\tHR@20=0.72296  MRR@20=0.31892  NDCG@20=0.41092\n",
      "early stopping\n",
      "best model change\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0005,delta=16.0, amsgrad=True, method=general, dropout=0.3, weight_decay=0.000000. \n",
      "\n",
      "current model HR@20=0.72368  MRR@20=0.31943.\n",
      "the best result so far. HR@20=0.72368  MRR@20=0.31943， hyper-parameters: session_length-20, hidden_size-100, lr-0.0005,delta=16.0, amsgrad-True, method-general, dropout-0.3, weight_decay-0.000000. \n",
      "\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0003,delta=16.0, amsgrad=True, method=general, dropout=0.3, weight_decay=0.000000. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-12-26 20:45:57] [1/50] 0 mean_batch_loss : 10.453060\n",
      "Start predicting 2019-12-26 20:47:44\n",
      "change best\n",
      "testing finish [2019-12-26 20:47:48] \n",
      "\tHR@1=0.16795  MRR@1=0.16795  NDCG@1=0.16795\n",
      "\tHR@5=0.45046  MRR@5=0.27033  NDCG@5=0.31509\n",
      "\tHR@10=0.57539  MRR@10=0.28709  NDCG@10=0.35558\n",
      "\tHR@20=0.67892  MRR@20=0.29436  NDCG@20=0.38185\n",
      "[2019-12-26 20:47:49] [2/50] 0 mean_batch_loss : 4.510535\n",
      "Start predicting 2019-12-26 20:49:36\n",
      "change best\n",
      "testing finish [2019-12-26 20:49:40] \n",
      "\tHR@1=0.17684  MRR@1=0.17684  NDCG@1=0.17684\n",
      "\tHR@5=0.46608  MRR@5=0.28082  NDCG@5=0.32682\n",
      "\tHR@10=0.59700  MRR@10=0.29840  NDCG@10=0.36927\n",
      "\tHR@20=0.70294  MRR@20=0.30588  NDCG@20=0.39622\n",
      "[2019-12-26 20:49:40] [3/50] 0 mean_batch_loss : 3.975014\n",
      "Start predicting 2019-12-26 20:51:28\n",
      "change best\n",
      "testing finish [2019-12-26 20:51:32] \n",
      "\tHR@1=0.18121  MRR@1=0.18121  NDCG@1=0.18121\n",
      "\tHR@5=0.47163  MRR@5=0.28596  NDCG@5=0.33208\n",
      "\tHR@10=0.60211  MRR@10=0.30350  NDCG@10=0.37440\n",
      "\tHR@20=0.70910  MRR@20=0.31108  NDCG@20=0.40164\n",
      "[2019-12-26 20:51:32] [4/50] 0 mean_batch_loss : 4.239701\n",
      "Start predicting 2019-12-26 20:53:20\n",
      "change best\n",
      "testing finish [2019-12-26 20:53:24] \n",
      "\tHR@1=0.18299  MRR@1=0.18299  NDCG@1=0.18299\n",
      "\tHR@5=0.47637  MRR@5=0.28854  NDCG@5=0.33517\n",
      "\tHR@10=0.60768  MRR@10=0.30618  NDCG@10=0.37774\n",
      "\tHR@20=0.71344  MRR@20=0.31365  NDCG@20=0.40465\n",
      "[2019-12-26 20:53:24] [5/50] 0 mean_batch_loss : 4.022605\n",
      "Start predicting 2019-12-26 20:55:12\n",
      "change best\n",
      "testing finish [2019-12-26 20:55:15] \n",
      "\tHR@1=0.18248  MRR@1=0.18248  NDCG@1=0.18248\n",
      "\tHR@5=0.47696  MRR@5=0.28842  NDCG@5=0.33523\n",
      "\tHR@10=0.60993  MRR@10=0.30640  NDCG@10=0.37847\n",
      "\tHR@20=0.71643  MRR@20=0.31393  NDCG@20=0.40556\n",
      "[2019-12-26 20:55:16] [6/50] 0 mean_batch_loss : 4.074892\n",
      "Start predicting 2019-12-26 20:57:03\n",
      "change best\n",
      "testing finish [2019-12-26 20:57:07] \n",
      "\tHR@1=0.18349  MRR@1=0.18349  NDCG@1=0.18349\n",
      "\tHR@5=0.48041  MRR@5=0.29018  NDCG@5=0.33741\n",
      "\tHR@10=0.61237  MRR@10=0.30792  NDCG@10=0.38021\n",
      "\tHR@20=0.71788  MRR@20=0.31538  NDCG@20=0.40706\n",
      "[2019-12-26 20:57:08] [7/50] 0 mean_batch_loss : 4.029492\n",
      "Start predicting 2019-12-26 20:58:56\n",
      "change best\n",
      "testing finish [2019-12-26 20:58:59] \n",
      "\tHR@1=0.18763  MRR@1=0.18763  NDCG@1=0.18763\n",
      "\tHR@5=0.48172  MRR@5=0.29335  NDCG@5=0.34011\n",
      "\tHR@10=0.61426  MRR@10=0.31118  NDCG@10=0.38312\n",
      "\tHR@20=0.71886  MRR@20=0.31854  NDCG@20=0.40969\n",
      "[2019-12-26 20:59:00] [8/50] 0 mean_batch_loss : 4.041587\n",
      "Start predicting 2019-12-26 21:00:48\n",
      "testing finish [2019-12-26 21:00:52] \n",
      "\tHR@1=0.18459  MRR@1=0.18459  NDCG@1=0.18459\n",
      "\tHR@5=0.48302  MRR@5=0.29184  NDCG@5=0.33930\n",
      "\tHR@10=0.61478  MRR@10=0.30954  NDCG@10=0.38202\n",
      "\tHR@20=0.72026  MRR@20=0.31698  NDCG@20=0.40885\n",
      "[2019-12-26 21:00:53] [9/50] 0 mean_batch_loss : 3.980108\n",
      "Start predicting 2019-12-26 21:02:40\n",
      "change best\n",
      "testing finish [2019-12-26 21:02:44] \n",
      "\tHR@1=0.18566  MRR@1=0.18566  NDCG@1=0.18566\n",
      "\tHR@5=0.48258  MRR@5=0.29249  NDCG@5=0.33969\n",
      "\tHR@10=0.61412  MRR@10=0.31018  NDCG@10=0.38236\n",
      "\tHR@20=0.72013  MRR@20=0.31768  NDCG@20=0.40935\n",
      "[2019-12-26 21:02:45] [10/50] 0 mean_batch_loss : 4.115561\n",
      "Start predicting 2019-12-26 21:04:32\n",
      "change best\n",
      "testing finish [2019-12-26 21:04:36] \n",
      "\tHR@1=0.18668  MRR@1=0.18668  NDCG@1=0.18668\n",
      "\tHR@5=0.48460  MRR@5=0.29384  NDCG@5=0.34121\n",
      "\tHR@10=0.61440  MRR@10=0.31125  NDCG@10=0.38327\n",
      "\tHR@20=0.72101  MRR@20=0.31879  NDCG@20=0.41040\n",
      "[2019-12-26 21:04:37] [11/50] 0 mean_batch_loss : 4.035393\n",
      "Start predicting 2019-12-26 21:06:24\n",
      "testing finish [2019-12-26 21:06:28] \n",
      "\tHR@1=0.18543  MRR@1=0.18543  NDCG@1=0.18543\n",
      "\tHR@5=0.48415  MRR@5=0.29261  NDCG@5=0.34015\n",
      "\tHR@10=0.61516  MRR@10=0.31021  NDCG@10=0.38263\n",
      "\tHR@20=0.72128  MRR@20=0.31770  NDCG@20=0.40962\n",
      "[2019-12-26 21:06:28] [12/50] 0 mean_batch_loss : 3.778718\n",
      "Start predicting 2019-12-26 21:08:16\n",
      "change best\n",
      "testing finish [2019-12-26 21:08:20] \n",
      "\tHR@1=0.18709  MRR@1=0.18709  NDCG@1=0.18709\n",
      "\tHR@5=0.48510  MRR@5=0.29404  NDCG@5=0.34146\n",
      "\tHR@10=0.61662  MRR@10=0.31164  NDCG@10=0.38405\n",
      "\tHR@20=0.72137  MRR@20=0.31901  NDCG@20=0.41065\n",
      "[2019-12-26 21:08:20] [13/50] 0 mean_batch_loss : 4.016307\n",
      "Start predicting 2019-12-26 21:10:08\n",
      "change best\n",
      "testing finish [2019-12-26 21:10:12] \n",
      "\tHR@1=0.18698  MRR@1=0.18698  NDCG@1=0.18698\n",
      "\tHR@5=0.48465  MRR@5=0.29405  NDCG@5=0.34137\n",
      "\tHR@10=0.61584  MRR@10=0.31172  NDCG@10=0.38396\n",
      "\tHR@20=0.72334  MRR@20=0.31930  NDCG@20=0.41130\n",
      "[2019-12-26 21:10:12] [14/50] 0 mean_batch_loss : 3.845253\n",
      "Start predicting 2019-12-26 21:12:00\n",
      "testing finish [2019-12-26 21:12:03] \n",
      "\tHR@1=0.18720  MRR@1=0.18720  NDCG@1=0.18720\n",
      "\tHR@5=0.48442  MRR@5=0.29421  NDCG@5=0.34145\n",
      "\tHR@10=0.61612  MRR@10=0.31194  NDCG@10=0.38419\n",
      "\tHR@20=0.72210  MRR@20=0.31941  NDCG@20=0.41113\n",
      "[2019-12-26 21:12:04] [15/50] 0 mean_batch_loss : 4.127995\n",
      "Start predicting 2019-12-26 21:13:52\n",
      "testing finish [2019-12-26 21:13:55] \n",
      "\tHR@1=0.18775  MRR@1=0.18775  NDCG@1=0.18775\n",
      "\tHR@5=0.48521  MRR@5=0.29490  NDCG@5=0.34216\n",
      "\tHR@10=0.61675  MRR@10=0.31259  NDCG@10=0.38483\n",
      "\tHR@20=0.72144  MRR@20=0.31999  NDCG@20=0.41148\n",
      "[2019-12-26 21:13:56] [16/50] 0 mean_batch_loss : 4.030267\n",
      "Start predicting 2019-12-26 21:15:43\n",
      "testing finish [2019-12-26 21:15:47] \n",
      "\tHR@1=0.18707  MRR@1=0.18707  NDCG@1=0.18707\n",
      "\tHR@5=0.48506  MRR@5=0.29427  NDCG@5=0.34164\n",
      "\tHR@10=0.61580  MRR@10=0.31182  NDCG@10=0.38402\n",
      "\tHR@20=0.72291  MRR@20=0.31939  NDCG@20=0.41128\n",
      "[2019-12-26 21:15:48] [17/50] 0 mean_batch_loss : 3.842794\n"
     ]
    }
   ],
   "source": [
    "hidden_sizes = [100]\n",
    "dropouts = [0.3,0.5]\n",
    "attention_methods = [\"general\"]\n",
    "lrs = [5e-4,3e-4]\n",
    "session_lengths = [20]\n",
    "weight_decays = [0]\n",
    "patience = 10\n",
    "deltas = [16.0]\n",
    "amsgrads = [True]\n",
    "best_params = \"\"\n",
    "best_all_model = 0.0\n",
    "best_all_hr = 0.0\n",
    "best_all_mrr = 0.0\n",
    "best_all_r1m = 0.0\n",
    "for session_length in session_lengths:\n",
    "    for hidden_size in hidden_sizes:\n",
    "        for amsgrad in amsgrads:\n",
    "            for attention_method in attention_methods:\n",
    "                for dropout in dropouts:\n",
    "                    for weight_decay in weight_decays:\n",
    "                        for lr in lrs:\n",
    "                            for delta in deltas:\n",
    "                                args = {}\n",
    "                                print(\"current model hyper-parameters: session_length=%d, hidden_size=%d, lr=%.4f,delta=%.1f, amsgrad=%s, method=%s, dropout=%.1f, weight_decay=%.6f. \\n\" % (session_length,hidden_size,lr,delta,str(amsgrad),attention_method,dropout,weight_decay))\n",
    "                                args[\"session_length\"] = session_length\n",
    "                                args[\"hidden_size\"] = hidden_size\n",
    "                                args[\"amsgrad\"] = amsgrad\n",
    "                                args[\"method\"] = attention_method\n",
    "                                args[\"dropout\"] = dropout\n",
    "                                args[\"weight_decay\"] = weight_decay\n",
    "                                args[\"lr\"] = lr\n",
    "                                args[\"delta\"] = delta\n",
    "                                args[\"patience\"] = patience\n",
    "                                best_model,best_model_hr,best_model_mrr = train(args)\n",
    "                                if best_model_hr + best_model_mrr > best_all_r1m:\n",
    "                                    print(\"best model change\")\n",
    "                                    best_all_r1m = best_model_hr + best_model_mrr\n",
    "                                    best_all_hr = best_model_hr\n",
    "                                    best_all_mrr = best_model_mrr\n",
    "                                    best_all_model = best_model\n",
    "                                    best_params = \"session_length-%d, hidden_size-%d, lr-%.4f,delta=%.1f, amsgrad-%s, method-%s, dropout-%.1f, weight_decay-%.6f\"%(session_length,hidden_size,lr,delta,str(amsgrad),attention_method,dropout,weight_decay)\n",
    "                                best_model = None\n",
    "                                print(\"current model hyper-parameters: session_length=%d, hidden_size=%d, lr=%.4f,delta=%.1f, amsgrad=%s, method=%s, dropout=%.1f, weight_decay=%.6f. \\n\" % (session_length,hidden_size,lr,delta,str(amsgrad),attention_method,dropout,weight_decay))\n",
    "                                print(\"current model HR@20=%.5f  MRR@20=%.5f.\"%(best_model_hr,best_model_mrr))\n",
    "                                print(\"the best result so far. HR@20=%.5f  MRR@20=%.5f， hyper-parameters: %s. \\n\"%(best_all_hr,best_all_mrr,best_params))\n",
    "print(\"The best result HR@20=%.5f  MRR@20=%.5f, hyper-parameters: %s. \"%(best_all_hr,best_all_mrr,best_params))\n",
    "print(\"over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-26T11:48:48.214Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "O8eiYy5UbyFR"
   },
   "outputs": [],
   "source": [
    "best_all_model.position_weights.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-26T11:48:48.215Z"
    }
   },
   "outputs": [],
   "source": [
    "# best_all_model.gate_weights.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "WDP-CE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "smy",
   "language": "python",
   "name": "smy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
