{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T07:04:23.355342Z",
     "start_time": "2020-03-02T07:04:22.869924Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T07:04:23.358736Z",
     "start_time": "2020-03-02T07:04:23.356469Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T07:04:23.367671Z",
     "start_time": "2020-03-02T07:04:23.359765Z"
    }
   },
   "outputs": [],
   "source": [
    "session_length = 19\n",
    "batch_size = 512\n",
    "plot_num = 50000\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T07:04:23.413935Z",
     "start_time": "2020-03-02T07:04:23.368867Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class SessionData(object):\n",
    "    def __init__(self,session_index,session_id,items_indexes):\n",
    "        self.session_index = session_index\n",
    "        self.session_id = session_id\n",
    "        self.item_list = items_indexes\n",
    "\n",
    "    def generate_seq_datas(self,session_length,padding_idx=0,predict_length=1):\n",
    "        sessions = []\n",
    "        if len(self.item_list)<2:\n",
    "            self.item_list.append[self.item_list[0]]\n",
    "        if predict_length==1:\n",
    "            # when session length>=3\n",
    "            for i in range(1,len(self.item_list)-1):\n",
    "#             # when session length >=2\n",
    "#             for i in range(len(self.item_list)-1):\n",
    "                if i <session_length:\n",
    "                    train_data = [0 for _ in range(session_length-i-1)]\n",
    "                    train_data.extend(self.item_list[:i+1])\n",
    "                    train_data.append(self.item_list[i+1])\n",
    "                else:\n",
    "                    train_data = self.item_list[i+1-session_length:i+1]\n",
    "                    train_data.append(self.item_list[i+1])\n",
    "                sessions.append(train_data)\n",
    "        else:\n",
    "\n",
    "            pass\n",
    "        return self.session_index,sessions\n",
    "    def __str__(self):\n",
    "        info = \" session index = {}\\n session id = {} \\n the length of item list= {} \\n the fisrt item index in item list is {}\".format(self.session_index,self.session_id,len(self.item_list),self.item_list[0])\n",
    "        return info\n",
    "class SessionDataSet(object):\n",
    "    def __init__(self,train_file,test_file,padding_idx=0):\n",
    "        super(SessionDataSet,self).__init__()\n",
    "        self.index_count = 0\n",
    "        self.session_count = 0\n",
    "        self.train_count = 0\n",
    "        self.test_count = 0\n",
    "        self.max_session_length = 0\n",
    "\n",
    "        self.padding_idx = padding_idx\n",
    "        self.item2index = dict()\n",
    "        self.index2item = dict()\n",
    "        self.session2index = dict()\n",
    "        self.index2session = dict()\n",
    "        self.item_total_num = dict()\n",
    "        self.item2index[\"<pad>\"] = padding_idx\n",
    "        self.index2item[padding_idx] = \"<pad>\"\n",
    "        self.train_data = self.load_data(train_file)\n",
    "        print(\"training set is loaded, # index: \",len(self.item2index.keys()))\n",
    "        self.train_count = self.session_count\n",
    "        print(\"train_session_num\",self.train_count)\n",
    "        self.test_data = self.load_data(test_file)\n",
    "        print(\"testing set is loaded, # index: \",len(self.index2item.keys()))\n",
    "        print(\"# item\",self.index_count)\n",
    "        self.test_count = self.session_count-self.train_count\n",
    "        print(\"# test session:\",self.test_count)\n",
    "        self.all_training_data = []\n",
    "        self.all_testing_data = []\n",
    "        self.all_meta_training_data = []\n",
    "        self.all_meta_testing_data = []\n",
    "        self.train_session_length = 0\n",
    "        self.test_session_length = 0\n",
    "    \n",
    "    def load_data(self,file_path):\n",
    "        data =  pickle.load(open(file_path, 'rb'))\n",
    "        session_ids = data[0]\n",
    "        session_data = data[1]\n",
    "        session_label = data[2]\n",
    "\n",
    "        result_data = []\n",
    "        lenth = len(session_ids)\n",
    "        print(\"# session\",lenth)\n",
    "\n",
    "        last_session_id = session_ids[0]\n",
    "        \n",
    "        session_item_indexes = []\n",
    "\n",
    "        for item_id in session_data[0]:\n",
    "            if item_id not in self.item2index.keys():\n",
    "                self.index_count+=1\n",
    "                self.item2index[item_id] = self.index_count\n",
    "                self.index2item[self.index_count] = item_id\n",
    "                self.item_total_num[self.index_count] = 0\n",
    "            session_item_indexes.append(self.item2index[item_id])\n",
    "            self.item_total_num[self.item2index[item_id]] += 1\n",
    "        target_item = session_label[0]\n",
    "        if target_item not in self.item2index.keys():\n",
    "            self.index_count+=1\n",
    "            self.item2index[target_item] = self.index_count\n",
    "            self.index2item[self.index_count] = target_item\n",
    "            self.item_total_num[self.index_count] = 0\n",
    "        session_item_indexes.append(self.item2index[target_item])\n",
    "        self.item_total_num[self.item2index[target_item]] += 1\n",
    "\n",
    "        for session_id,items,target_item in zip(session_ids,session_data,session_label):\n",
    "            if session_id!=last_session_id:\n",
    "\n",
    "                self.session_count+=1\n",
    "                self.session2index[last_session_id] = self.session_count\n",
    "                self.index2session[self.session_count] = last_session_id\n",
    "                last_session_id = session_id\n",
    "                if len(session_item_indexes)>self.max_session_length:\n",
    "                    self.max_session_length = len(session_item_indexes)\n",
    "                new_session = SessionData(self.session_count,last_session_id,session_item_indexes)\n",
    "                result_data.append(new_session)\n",
    "                session_item_indexes = []\n",
    "                for item_id in items:\n",
    "                    if item_id not in self.item2index.keys():\n",
    "                        self.index_count+=1\n",
    "                        self.item2index[item_id] = self.index_count\n",
    "                        self.index2item[self.index_count] = item_id\n",
    "                        self.item_total_num[self.index_count] = 0\n",
    "                    session_item_indexes.append(self.item2index[item_id])\n",
    "                    self.item_total_num[self.item2index[item_id]] += 1\n",
    "                if target_item not in self.item2index.keys():\n",
    "                    self.index_count+=1\n",
    "                    self.item2index[target_item] = self.index_count\n",
    "                    self.index2item[self.index_count] = target_item\n",
    "                    self.item_total_num[self.index_count] = 0\n",
    "                session_item_indexes.append(self.item2index[target_item])\n",
    "                self.item_total_num[self.item2index[target_item]] += 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        self.session_count+=1\n",
    "        self.session2index[last_session_id] = self.session_count\n",
    "        new_session = SessionData(self.session_count,last_session_id,session_item_indexes)\n",
    "        result_data.append(new_session)\n",
    "        print(\"loaded\")\n",
    "        print(new_session)\n",
    "        \n",
    "        return result_data\n",
    "    \n",
    "\n",
    "    def get_batch(self,batch_size,session_length=10,predict_length=1,all_data=None,phase=\"train\",neg_num=1,sampling_mathod=\"random\"):\n",
    "\n",
    "        if phase == \"train\":\n",
    "            if all_data is None:\n",
    "                all_data = self.get_all_training_data(session_length)\n",
    "            indexes = np.random.permutation(all_data.shape[0])\n",
    "            all_data = all_data[indexes]\n",
    "        else:\n",
    "            if all_data is None:\n",
    "                all_data = self.get_all_testing_data(session_length)\n",
    "        \n",
    "        sindex = 0\n",
    "        eindex = batch_size\n",
    "        while eindex < all_data.shape[0]:\n",
    "            batch = all_data[sindex: eindex]\n",
    "\n",
    "            temp = eindex\n",
    "            eindex = eindex + batch_size\n",
    "            sindex = temp\n",
    "            if phase ==\"train\":\n",
    "                batch = self.divid_and_extend_negative_samples(batch,session_length=session_length,predict_length=predict_length,neg_num=neg_num,method=sampling_mathod)\n",
    "            else:\n",
    "                batch = [batch[:,:session_length],batch[:,session_length:]]\n",
    "            yield batch\n",
    "\n",
    "        if eindex >= all_data.shape[0]:\n",
    "            batch = all_data[sindex:]\n",
    "            if phase ==\"train\":\n",
    "                batch = self.divid_and_extend_negative_samples(batch,session_length=session_length,predict_length=predict_length,neg_num=neg_num,method=sampling_mathod)\n",
    "            else:\n",
    "                batch = [batch[:,:session_length],batch[:,session_length:]]\n",
    "            yield batch\n",
    "    \n",
    "    def divid_and_extend_negative_samples(self,batch_data,session_length,predict_length=1,neg_num=1,method=\"random\"):\n",
    "        \"\"\"\n",
    "        divid and extend negative samples\n",
    "        \"\"\"\n",
    "        neg_items = []\n",
    "        if method == \"random\":\n",
    "            for session_and_target in batch_data:\n",
    "                neg_item = []\n",
    "                for i in range(neg_num):\n",
    "                    rand_item = random.randint(1,self.index_count)\n",
    "                    while rand_item in session_and_target or rand_item in neg_item:\n",
    "                        rand_item = random.randint(1,self.index_count)\n",
    "                    neg_item.append(rand_item)\n",
    "                neg_items.append(neg_item)\n",
    "        else:\n",
    "\n",
    "            total_list = set()\n",
    "            for session in batch_data:\n",
    "                for i in session:\n",
    "                    total_list.add(i) \n",
    "            total_list = list(total_list)\n",
    "            total_list =  sorted(total_list, key=lambda item: self.item_total_num[item],reverse=True)\n",
    "            for i,session in enumerate(batch_data):\n",
    "                np.random.choice(total_list)\n",
    "        session_items = batch_data[:,:session_length]\n",
    "        target_item = batch_data[:,session_length:]\n",
    "        neg_items = np.array(neg_items)\n",
    "        return [session_items,target_item,neg_items]\n",
    "    \n",
    "    def get_all_training_data(self,session_length,predict_length=1):\n",
    "        if len(self.all_training_data)!=0 and self.train_session_length==session_length:\n",
    "#             print(\"The build is complete and there is no need to repeat the build\")\n",
    "            return self.all_training_data\n",
    "        print(\"Start building the all training dataset\")\n",
    "        all_sessions = []\n",
    "        for session_data in self.train_data:\n",
    "            session_index,sessions = session_data.generate_seq_datas(session_length,padding_idx=self.padding_idx)\n",
    "            if sessions is not None:\n",
    "                all_sessions.extend(sessions)\n",
    "        all_sessions = np.array(all_sessions)\n",
    "        self.all_training_data = all_sessions\n",
    "        self.train_session_length=session_length\n",
    "        print(\"The total number of training samples is：\",all_sessions.shape)\n",
    "        return all_sessions\n",
    "    \n",
    "    def get_all_testing_data(self,session_length,predict_length=1):\n",
    "        if len(self.all_testing_data)!=0 and self.test_session_length==session_length:\n",
    "            return self.all_testing_data\n",
    "        all_sessions = []\n",
    "        for session_data in self.test_data:\n",
    "            session_index,sessions = session_data.generate_seq_datas(session_length,padding_idx=self.padding_idx)\n",
    "            if sessions is not None:\n",
    "                all_sessions.extend(sessions)\n",
    "        all_sessions = np.array(all_sessions)\n",
    "        self.all_testing_data = all_sessions\n",
    "        self.test_session_length=session_length\n",
    "        print(\"The total number of testing samples is：\",all_sessions.shape)\n",
    "        return all_sessions\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T07:04:24.628534Z",
     "start_time": "2020-03-02T07:04:23.428579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# session 526135\n",
      "loaded\n",
      " session index = 132501\n",
      " session id = 598664 \n",
      " the length of item list= 5 \n",
      " the fisrt item index in item list is 15612\n",
      "training set is loaded, # index:  40841\n",
      "train_session_num 132501\n",
      "# session 44279\n",
      "loaded\n",
      " session index = 143847\n",
      " session id = 600240 \n",
      " the length of item list= 4 \n",
      " the fisrt item index in item list is 2093\n",
      "testing set is loaded, # index:  40841\n",
      "# item 40840\n",
      "# test session: 11346\n"
     ]
    }
   ],
   "source": [
    "# dataset = SessionDataSet(train_file=\"../../data/retailrocket_gcsan_my/train.txt\",test_file=\"../../data/retailrocket_gcsan_my/test.txt\")\n",
    "dataset = SessionDataSet(train_file=\"../../data/diginetica_gcsan_my/train.txt\",test_file=\"../../data/diginetica_gcsan_my/test.txt\")\n",
    "# dataset = SessionDataSet(train_file=\"../../data/yoochoose1_4_gcsan_my/train.txt\",test_file=\"../../data/yoochoose1_4_gcsan_my/test.txt\")\n",
    "# dataset = SessionDataSet(train_file=\"../../data/yoochoose1_64_gcsan_my/train.txt\",test_file=\"../../data/yoochoose1_64_gcsan_my/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T07:04:24.636963Z",
     "start_time": "2020-03-02T07:04:24.629424Z"
    }
   },
   "outputs": [],
   "source": [
    "def bpr_loss(r):\n",
    "    return torch.sum(-torch.log(torch.sigmoid(r)))\n",
    "def get_hit_num(pred,y_truth):\n",
    "    \"\"\"\n",
    "        pred: numpy type(batch_size,k) \n",
    "        y_truth: list type (batch_size,groudtruth_num)\n",
    "    \"\"\"\n",
    "\n",
    "    hit_num = 0\n",
    "    for i in range(len(y_truth)):\n",
    "        for value in y_truth[i]:\n",
    "            hit_num += np.sum(pred[i]==value)\n",
    "    return hit_num\n",
    "\n",
    "def get_rr(pred,y_truth):\n",
    "    rr=0.\n",
    "    for i in range(len(y_truth)):\n",
    "        for value in y_truth[i]:\n",
    "            hit_indexes = np.where(pred[i]==value)[0]\n",
    "            for hit_index in hit_indexes:\n",
    "                rr += 1/(hit_index+1)\n",
    "    return rr\n",
    "\n",
    "def get_dcg(pred,y_truth):\n",
    "    y_pred_score = np.zeros_like(pred)\n",
    "\n",
    "    for i in range(len(y_truth)):\n",
    "\n",
    "        for j,y_pred in enumerate(pred[i]):\n",
    "            if y_pred == y_truth[i][0]:\n",
    "                y_pred_score[i][j]=1\n",
    "    gain = 2 ** y_pred_score - 1\n",
    "    discounts = np.tile(np.log2(np.arange(pred.shape[1]) + 2),(len(y_truth),1))\n",
    "    dcg = np.sum(gain / discounts,axis=1)\n",
    "    return dcg\n",
    "\n",
    "def get_ndcg(pred,y_truth):\n",
    "    dcg = get_dcg(pred, y_truth)\n",
    "    idcg = get_dcg(np.concatenate((y_truth,np.zeros_like(pred)[:,:-1]-1),axis=1), y_truth)\n",
    "    ndcg = np.sum(dcg / idcg)\n",
    "\n",
    "    return ndcg\n",
    "\n",
    "def dcg_score(y_pre, y_true, k):\n",
    "    y_pre_score = np.zeros(k)\n",
    "    if len(y_pre) > k:\n",
    "        y_pre = y_pre[:k]\n",
    "    for i in range(len(y_pre)):\n",
    "        pre_tag = y_pre[i]\n",
    "        if pre_tag in y_true:\n",
    "            y_pre_score[i] = 1\n",
    "    gain = 2 ** y_pre_score - 1\n",
    "    discounts = np.log2(np.arange(k) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_pre, y_true, k=5):\n",
    "    dcg = dcg_score(y_pre, y_true, k)\n",
    "    idcg = dcg_score(y_true, y_true, k)\n",
    "    return dcg / idcg\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T07:04:24.660077Z",
     "start_time": "2020-03-02T07:04:24.637925Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class NARM(torch.nn.Module):\n",
    "    def __init__(self, itemNum, hidden_size, embedding_dim, batch_size, layerNum = 1,padding_idx=0,posNum=11, dropout=0.5,embedding_dropout=0.25,activate=\"tanh\"):\n",
    "        super(NARM, self).__init__()\n",
    "        self.itemNum = itemNum\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.layerNum = layerNum\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.item_embedding = torch.nn.Embedding(itemNum, self.embedding_dim, padding_idx=padding_idx)\n",
    "        torch.nn.init.constant_(self.item_embedding.weight[0],0)\n",
    "        self.embedding_dropout = torch.nn.Dropout(embedding_dropout)\n",
    "        self.gru = torch.nn.GRU(self.embedding_dim, self.hidden_size, self.layerNum)\n",
    "        self.a_1 = torch.nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.a_2 = torch.nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.v_t = torch.nn.Linear(self.hidden_size, 1, bias=False)\n",
    "        self.ct_dropout = torch.nn.Dropout(dropout)\n",
    "        self.b = torch.nn.Linear(self.embedding_dim, 2 * self.hidden_size, bias=False)\n",
    "        #self.sf = torch.nn.Softmax()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def forward(self, seq, lengths):\n",
    "        seq = seq.t()\n",
    "        hidden = self.init_hidden(seq.size(1))\n",
    "        embs = self.embedding_dropout(self.item_embedding(seq))\n",
    "#         print(\"before\",embs.shape)\n",
    "        embs = pack_padded_sequence(embs, lengths)\n",
    "#         print(\"after\",embs.shape)\n",
    "        gru_out, hidden = self.gru(embs, hidden)\n",
    "\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)\n",
    "#         print(\"after aa\",gru_out,lengths)\n",
    "        # fetch the last hidden state of last timestamp\n",
    "        ht = hidden[-1]\n",
    "        gru_out = gru_out.permute(1, 0, 2)\n",
    "\n",
    "        c_global = ht\n",
    "        q1 = self.a_1(gru_out.contiguous().view(-1, self.hidden_size)).view(gru_out.size())  \n",
    "        q2 = self.a_2(ht)\n",
    "\n",
    "        mask = torch.where(seq.permute(1, 0) > 0, torch.tensor([1.], device = self.device), torch.tensor([0.], device = self.device))\n",
    "        q2_expand = q2.unsqueeze(1).expand_as(q1)\n",
    "        q2_masked = mask.unsqueeze(2).expand_as(q1) * q2_expand\n",
    "\n",
    "        alpha = self.v_t(torch.sigmoid(q1 + q2_masked).view(-1, self.hidden_size)).view(mask.size())\n",
    "        c_local = torch.sum(alpha.unsqueeze(2).expand_as(gru_out) * gru_out, 1)\n",
    "\n",
    "        c_t = torch.cat([c_local, c_global], 1)\n",
    "        c_t = self.ct_dropout(c_t)\n",
    "        \n",
    "        item_embs = self.item_embedding.weight[1:]\n",
    "        scores = torch.matmul(c_t, self.b(item_embs).permute(1, 0))\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros((self.layerNum, batch_size, self.hidden_size), requires_grad=True).to(self.device)\n",
    "    \n",
    "    def predict_top_k(self,seq, lengths, k=20):\n",
    "        seq = seq.t()\n",
    "        hidden = self.init_hidden(seq.size(1))\n",
    "        embs = self.item_embedding(seq)\n",
    "#         print(\"embs.shape\",embs.shape)\n",
    "        embs = pack_padded_sequence(embs, lengths)\n",
    "        gru_out, hidden = self.gru(embs, hidden)\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)\n",
    "\n",
    "        # fetch the last hidden state of last timestamp\n",
    "        ht = hidden[-1]\n",
    "        gru_out = gru_out.permute(1, 0, 2)\n",
    "\n",
    "        c_global = ht\n",
    "        q1 = self.a_1(gru_out.contiguous().view(-1, self.hidden_size)).view(gru_out.size())  \n",
    "        q2 = self.a_2(ht)\n",
    "\n",
    "        mask = torch.where(seq.permute(1, 0) > 0, torch.tensor([1.], device = self.device), torch.tensor([0.], device = self.device))\n",
    "        q2_expand = q2.unsqueeze(1).expand_as(q1)\n",
    "        q2_masked = mask.unsqueeze(2).expand_as(q1) * q2_expand\n",
    "\n",
    "        alpha = self.v_t(torch.sigmoid(q1 + q2_masked).view(-1, self.hidden_size)).view(mask.size())\n",
    "        c_local = torch.sum(alpha.unsqueeze(2).expand_as(gru_out) * gru_out, 1)\n",
    "\n",
    "        c_t = torch.cat([c_local, c_global], 1)\n",
    "#         c_t = self.ct_dropout(c_t)\n",
    "        \n",
    "        item_embs = self.item_embedding.weight[1:]\n",
    "        scores = torch.matmul(c_t, self.b(item_embs).permute(1, 0))\n",
    "        result = torch.topk(scores,k,dim=-1)[1]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIKM S >= 3   Total 867.4‬s Avg 17.35s\n",
    "    HR@20=0.64258  MRR@20=0.29960, hyper-parameters: current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
    "        HR@1=0.18919  MRR@1=0.18919  NDCG@1=0.18919\n",
    "        HR@5=0.43032  MRR@5=0.27794  NDCG@5=0.31586\n",
    "        HR@10=0.53732  MRR@10=0.29225  NDCG@10=0.35049\n",
    "        HR@20=0.64258  MRR@20=0.29960  NDCG@20=0.37716\n",
    "# RR S >= 3   Total 522.1s Avg 11.60s\n",
    "    HR@20=0.53992  MRR@20=0.28436, hyper-parameters: current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
    "        HR@1=0.19898  MRR@1=0.19898  NDCG@1=0.19898\n",
    "        HR@5=0.38931  MRR@5=0.26896  NDCG@5=0.29891\n",
    "        HR@10=0.46643  MRR@10=0.27927  NDCG@10=0.32387\n",
    "        HR@20=0.53992  MRR@20=0.28436  NDCG@20=0.34243\n",
    "        \n",
    "# RSC64 S >= 3   Total 205.6s Avg 7.34s\n",
    "    HR@20=0.69375  MRR@20=0.27877, hyper-parameters: current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
    "        HR@1=0.14854  MRR@1=0.14854  NDCG@1=0.14854\n",
    "        HR@5=0.43585  MRR@5=0.25130  NDCG@5=0.29709\n",
    "        HR@10=0.58163  MRR@10=0.27086  NDCG@10=0.34434\n",
    "        HR@20=0.69375  MRR@20=0.27877  NDCG@20=0.37284\n",
    "# RSC4 S >= 3   Total 2,672.2‬s Avg 92.14s\n",
    "    HR@20=0.71441  MRR@20=0.28263，session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
    "        HR@1=0.14575  MRR@1=0.14575  NDCG@1=0.14575\n",
    "        HR@5=0.45036  MRR@5=0.25469  NDCG@5=0.30324\n",
    "        HR@10=0.59594  MRR@10=0.27422  NDCG@10=0.35042\n",
    "        HR@20=0.71441  MRR@20=0.28263  NDCG@20=0.38060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T07:04:24.674643Z",
     "start_time": "2020-03-02T07:04:24.661356Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs=50\n",
    "def train(args):\n",
    "    hidden_size = args[\"hidden_size\"] if \"hidden_size\" in args.keys() else 100\n",
    "    embedding_dim = args[\"embedding_dim\"] if \"hidden_size\" in args.keys() else 100\n",
    "    dropout = args[\"dropout\"] if \"dropout\" in args.keys()  else 0.5\n",
    "    embedding_dropout = args[\"embedding_dropout\"] if \"dropout\" in args.keys()  else 0.5\n",
    "    lr = args[\"lr\"] if \"lr\" in args.keys()  else 1e-3\n",
    "    session_length = args[\"session_length\"] if \"session_length\" in args.keys() else 20\n",
    "    patience = args[\"patience\"] if \"patience\" in args.keys() else 5\n",
    "    model = NARM(hidden_size=hidden_size, embedding_dim=embedding_dim,itemNum=dataset.index_count+1, batch_size=batch_size,posNum=session_length+1, padding_idx=0, dropout=dropout,embedding_dropout=embedding_dropout).to(device)\n",
    "    opti = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    best_model_hr = 0.0\n",
    "    best_model_mrr = 0.0\n",
    "    best_r1m = 0.0\n",
    "    best_model = None\n",
    "    first_loss = 0.0\n",
    "    predict_nums = [1,5,10,20]\n",
    "    no_improvement_epoch = 0\n",
    "    start_train_time = datetime.datetime.now()\n",
    "    for epoch in range(epochs):\n",
    "        batch_losses = []\n",
    "        epoch_losses = []\n",
    "        for i,batch_data in enumerate(dataset.get_batch(batch_size,session_length,phase=\"train\")):\n",
    "            sessions = torch.tensor(batch_data[0]).to(device)\n",
    "            target_items = torch.tensor(batch_data[1]).squeeze().to(device)-1\n",
    "            result_pos = model(sessions,torch.tensor(session_length).unsqueeze(0).repeat(target_items.shape[0]))\n",
    "            loss = loss_function(result_pos,target_items)\n",
    "            opti.zero_grad()\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "            batch_losses.append(loss.cpu().detach().numpy())\n",
    "            epoch_losses.append(loss.cpu().detach().numpy())\n",
    "            if i % plot_num == 0:\n",
    "                time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                print(\"[%s] [%d/%d] %d mean_batch_loss : %0.6f\" % (time, epoch+1, epochs, i, np.mean(batch_losses)))\n",
    "                batch_losses = []\n",
    "        with torch.no_grad():\n",
    "            start_test_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(\"Start predicting\",start_test_time)\n",
    "            rrs = [0 for _ in range(len(predict_nums))]\n",
    "            hit_nums = [0 for _ in range(len(predict_nums))]\n",
    "            ndcgs = [0 for _ in range(len(predict_nums))]\n",
    "            for i,batch_data in enumerate(dataset.get_batch(batch_size,session_length,phase=\"test\")):\n",
    "                sessions = torch.tensor(batch_data[0]).to(device)\n",
    "                target_items = np.array(batch_data[1])-1\n",
    "                y_pred = model.predict_top_k(sessions,torch.tensor(session_length).unsqueeze(0).repeat(target_items.shape[0]),20).cpu().numpy()\n",
    "#                 print(y_pred[:2],target_items[:2])\n",
    "                \n",
    "                for j,predict_num in enumerate(predict_nums):\n",
    "                    hit_nums[j]+=get_hit_num(y_pred[:,:predict_num],target_items)\n",
    "                    rrs[j]+=get_rr(y_pred[:,:predict_num],target_items)\n",
    "                    ndcgs[j]+=get_ndcg(y_pred[:,:predict_num],target_items)\n",
    "                    \n",
    "            end_test_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            hrs = [hit_num/len(dataset.all_testing_data) for hit_num in hit_nums]\n",
    "            mrrs = [rr/len(dataset.all_testing_data) for rr in rrs]\n",
    "            mndcgs = [ndcg/len(dataset.all_testing_data) for ndcg in ndcgs]\n",
    "            if hrs[-1] + mrrs[-1] > best_r1m:\n",
    "                print(\"change best\")\n",
    "                best_model = deepcopy(model)\n",
    "                best_model_hr = hrs[-1]\n",
    "                best_model_mrr = mrrs[-1]\n",
    "                best_r1m = hrs[-1] + mrrs[-1]\n",
    "                no_improvement_epoch = 0\n",
    "            else:\n",
    "                no_improvement_epoch +=1\n",
    "            print(\"testing finish [%s] \"%end_test_time)\n",
    "            for k,predict_num in enumerate(predict_nums):\n",
    "                print(\"\\tHR@%d=%.5f  MRR@%d=%.5f  NDCG@%d=%.5f\"%(predict_num,hrs[k],predict_num,mrrs[k],predict_num,mndcgs[k]))\n",
    "        if no_improvement_epoch>=patience:\n",
    "            print(\"early stopping\")\n",
    "            break\n",
    "    end_train_time = datetime.datetime.now()\n",
    "    print(\"training and testting over, Total time\",end_train_time-start_train_time)\n",
    "    return best_model,best_model_hr,best_model_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T08:42:36.671113Z",
     "start_time": "2020-03-02T07:04:24.675646Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model hyper-parameters: session_length=20, hidden_size=10, lr=0.0030, embedding_dim=10, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "Start building the all training dataset\n",
      "The total number of training samples is： (526135, 21)\n",
      "[2020-03-02 15:04:29] [1/50] 0 mean_batch_loss : 13.777618\n",
      "Start predicting 2020-03-02 15:04:41\n",
      "The total number of testing samples is： (44279, 21)\n",
      "change best\n",
      "testing finish [2020-03-02 15:04:44] \n",
      "\tHR@1=0.00346  MRR@1=0.00346  NDCG@1=0.00346\n",
      "\tHR@5=0.00976  MRR@5=0.00565  NDCG@5=0.00667\n",
      "\tHR@10=0.01482  MRR@10=0.00632  NDCG@10=0.00829\n",
      "\tHR@20=0.02279  MRR@20=0.00687  NDCG@20=0.01031\n",
      "[2020-03-02 15:04:44] [2/50] 0 mean_batch_loss : 10.182892\n",
      "Start predicting 2020-03-02 15:04:56\n",
      "change best\n",
      "testing finish [2020-03-02 15:04:59] \n",
      "\tHR@1=0.00813  MRR@1=0.00813  NDCG@1=0.00813\n",
      "\tHR@5=0.02080  MRR@5=0.01244  NDCG@5=0.01450\n",
      "\tHR@10=0.03105  MRR@10=0.01378  NDCG@10=0.01778\n",
      "\tHR@20=0.04569  MRR@20=0.01478  NDCG@20=0.02147\n",
      "[2020-03-02 15:04:59] [3/50] 0 mean_batch_loss : 9.727792\n",
      "Start predicting 2020-03-02 15:05:10\n",
      "change best\n",
      "testing finish [2020-03-02 15:05:13] \n",
      "\tHR@1=0.01131  MRR@1=0.01131  NDCG@1=0.01131\n",
      "\tHR@5=0.02963  MRR@5=0.01737  NDCG@5=0.02038\n",
      "\tHR@10=0.04381  MRR@10=0.01921  NDCG@10=0.02492\n",
      "\tHR@20=0.06283  MRR@20=0.02054  NDCG@20=0.02974\n",
      "[2020-03-02 15:05:13] [4/50] 0 mean_batch_loss : 9.725247\n",
      "Start predicting 2020-03-02 15:05:25\n",
      "change best\n",
      "testing finish [2020-03-02 15:05:28] \n",
      "\tHR@1=0.01599  MRR@1=0.01599  NDCG@1=0.01599\n",
      "\tHR@5=0.04124  MRR@5=0.02466  NDCG@5=0.02875\n",
      "\tHR@10=0.06109  MRR@10=0.02726  NDCG@10=0.03512\n",
      "\tHR@20=0.08704  MRR@20=0.02905  NDCG@20=0.04166\n",
      "[2020-03-02 15:05:28] [5/50] 0 mean_batch_loss : 9.320013\n",
      "Start predicting 2020-03-02 15:05:40\n",
      "change best\n",
      "testing finish [2020-03-02 15:05:43] \n",
      "\tHR@1=0.01987  MRR@1=0.01987  NDCG@1=0.01987\n",
      "\tHR@5=0.05791  MRR@5=0.03288  NDCG@5=0.03905\n",
      "\tHR@10=0.08584  MRR@10=0.03652  NDCG@10=0.04800\n",
      "\tHR@20=0.11680  MRR@20=0.03864  NDCG@20=0.05578\n",
      "[2020-03-02 15:05:43] [6/50] 0 mean_batch_loss : 9.159239\n",
      "Start predicting 2020-03-02 15:05:54\n",
      "change best\n",
      "testing finish [2020-03-02 15:05:58] \n",
      "\tHR@1=0.02638  MRR@1=0.02638  NDCG@1=0.02638\n",
      "\tHR@5=0.07557  MRR@5=0.04377  NDCG@5=0.05164\n",
      "\tHR@10=0.10804  MRR@10=0.04807  NDCG@10=0.06211\n",
      "\tHR@20=0.14930  MRR@20=0.05091  NDCG@20=0.07252\n",
      "[2020-03-02 15:05:58] [7/50] 0 mean_batch_loss : 8.880388\n",
      "Start predicting 2020-03-02 15:06:09\n",
      "change best\n",
      "testing finish [2020-03-02 15:06:12] \n",
      "\tHR@1=0.02945  MRR@1=0.02945  NDCG@1=0.02945\n",
      "\tHR@5=0.08677  MRR@5=0.04910  NDCG@5=0.05840\n",
      "\tHR@10=0.12877  MRR@10=0.05462  NDCG@10=0.07190\n",
      "\tHR@20=0.17995  MRR@20=0.05812  NDCG@20=0.08478\n",
      "[2020-03-02 15:06:12] [8/50] 0 mean_batch_loss : 8.574312\n",
      "Start predicting 2020-03-02 15:06:24\n",
      "change best\n",
      "testing finish [2020-03-02 15:06:27] \n",
      "\tHR@1=0.03485  MRR@1=0.03485  NDCG@1=0.03485\n",
      "\tHR@5=0.10739  MRR@5=0.05981  NDCG@5=0.07156\n",
      "\tHR@10=0.15673  MRR@10=0.06629  NDCG@10=0.08740\n",
      "\tHR@20=0.21577  MRR@20=0.07038  NDCG@20=0.10233\n",
      "[2020-03-02 15:06:27] [9/50] 0 mean_batch_loss : 8.477037\n",
      "Start predicting 2020-03-02 15:06:39\n",
      "change best\n",
      "testing finish [2020-03-02 15:06:42] \n",
      "\tHR@1=0.03954  MRR@1=0.03954  NDCG@1=0.03954\n",
      "\tHR@5=0.11818  MRR@5=0.06660  NDCG@5=0.07933\n",
      "\tHR@10=0.17331  MRR@10=0.07387  NDCG@10=0.09707\n",
      "\tHR@20=0.24203  MRR@20=0.07859  NDCG@20=0.11439\n",
      "[2020-03-02 15:06:42] [10/50] 0 mean_batch_loss : 7.972018\n",
      "Start predicting 2020-03-02 15:06:54\n",
      "change best\n",
      "testing finish [2020-03-02 15:06:57] \n",
      "\tHR@1=0.03878  MRR@1=0.03878  NDCG@1=0.03878\n",
      "\tHR@5=0.12518  MRR@5=0.06873  NDCG@5=0.08267\n",
      "\tHR@10=0.18756  MRR@10=0.07697  NDCG@10=0.10276\n",
      "\tHR@20=0.26324  MRR@20=0.08214  NDCG@20=0.12180\n",
      "[2020-03-02 15:06:57] [11/50] 0 mean_batch_loss : 7.964718\n",
      "Start predicting 2020-03-02 15:07:08\n",
      "change best\n",
      "testing finish [2020-03-02 15:07:11] \n",
      "\tHR@1=0.04085  MRR@1=0.04085  NDCG@1=0.04085\n",
      "\tHR@5=0.13456  MRR@5=0.07234  NDCG@5=0.08766\n",
      "\tHR@10=0.20093  MRR@10=0.08111  NDCG@10=0.10904\n",
      "\tHR@20=0.27869  MRR@20=0.08643  NDCG@20=0.12860\n",
      "[2020-03-02 15:07:11] [12/50] 0 mean_batch_loss : 7.770333\n",
      "Start predicting 2020-03-02 15:07:23\n",
      "change best\n",
      "testing finish [2020-03-02 15:07:26] \n",
      "\tHR@1=0.04187  MRR@1=0.04187  NDCG@1=0.04187\n",
      "\tHR@5=0.13860  MRR@5=0.07522  NDCG@5=0.09088\n",
      "\tHR@10=0.21021  MRR@10=0.08467  NDCG@10=0.11392\n",
      "\tHR@20=0.29547  MRR@20=0.09055  NDCG@20=0.13544\n",
      "[2020-03-02 15:07:26] [13/50] 0 mean_batch_loss : 7.476127\n",
      "Start predicting 2020-03-02 15:07:37\n",
      "change best\n",
      "testing finish [2020-03-02 15:07:40] \n",
      "\tHR@1=0.04171  MRR@1=0.04171  NDCG@1=0.04171\n",
      "\tHR@5=0.14192  MRR@5=0.07581  NDCG@5=0.09210\n",
      "\tHR@10=0.21882  MRR@10=0.08597  NDCG@10=0.11687\n",
      "\tHR@20=0.30805  MRR@20=0.09208  NDCG@20=0.13933\n",
      "[2020-03-02 15:07:40] [14/50] 0 mean_batch_loss : 7.472281\n",
      "Start predicting 2020-03-02 15:07:52\n",
      "change best\n",
      "testing finish [2020-03-02 15:07:55] \n",
      "\tHR@1=0.04273  MRR@1=0.04273  NDCG@1=0.04273\n",
      "\tHR@5=0.14632  MRR@5=0.07821  NDCG@5=0.09501\n",
      "\tHR@10=0.22440  MRR@10=0.08856  NDCG@10=0.12019\n",
      "\tHR@20=0.31774  MRR@20=0.09497  NDCG@20=0.14370\n",
      "[2020-03-02 15:07:55] [15/50] 0 mean_batch_loss : 7.382797\n",
      "Start predicting 2020-03-02 15:08:07\n",
      "change best\n",
      "testing finish [2020-03-02 15:08:10] \n",
      "\tHR@1=0.04675  MRR@1=0.04675  NDCG@1=0.04675\n",
      "\tHR@5=0.15145  MRR@5=0.08251  NDCG@5=0.09952\n",
      "\tHR@10=0.22762  MRR@10=0.09262  NDCG@10=0.12409\n",
      "\tHR@20=0.32587  MRR@20=0.09935  NDCG@20=0.14882\n",
      "[2020-03-02 15:08:10] [16/50] 0 mean_batch_loss : 7.359639\n",
      "Start predicting 2020-03-02 15:08:22\n",
      "change best\n",
      "testing finish [2020-03-02 15:08:25] \n",
      "\tHR@1=0.04632  MRR@1=0.04632  NDCG@1=0.04632\n",
      "\tHR@5=0.15125  MRR@5=0.08221  NDCG@5=0.09924\n",
      "\tHR@10=0.23185  MRR@10=0.09277  NDCG@10=0.12511\n",
      "\tHR@20=0.33056  MRR@20=0.09956  NDCG@20=0.14998\n",
      "[2020-03-02 15:08:25] [17/50] 0 mean_batch_loss : 7.342922\n",
      "Start predicting 2020-03-02 15:08:37\n",
      "change best\n",
      "testing finish [2020-03-02 15:08:40] \n",
      "\tHR@1=0.04368  MRR@1=0.04368  NDCG@1=0.04368\n",
      "\tHR@5=0.15149  MRR@5=0.08065  NDCG@5=0.09812\n",
      "\tHR@10=0.23467  MRR@10=0.09166  NDCG@10=0.12494\n",
      "\tHR@20=0.33576  MRR@20=0.09865  NDCG@20=0.15046\n",
      "[2020-03-02 15:08:40] [18/50] 0 mean_batch_loss : 7.258411\n",
      "Start predicting 2020-03-02 15:08:51\n",
      "change best\n",
      "testing finish [2020-03-02 15:08:55] \n",
      "\tHR@1=0.04431  MRR@1=0.04431  NDCG@1=0.04431\n",
      "\tHR@5=0.15267  MRR@5=0.08121  NDCG@5=0.09883\n",
      "\tHR@10=0.23686  MRR@10=0.09232  NDCG@10=0.12593\n",
      "\tHR@20=0.34036  MRR@20=0.09944  NDCG@20=0.15202\n",
      "[2020-03-02 15:08:55] [19/50] 0 mean_batch_loss : 7.189783\n",
      "Start predicting 2020-03-02 15:09:06\n",
      "testing finish [2020-03-02 15:09:10] \n",
      "\tHR@1=0.04413  MRR@1=0.04413  NDCG@1=0.04413\n",
      "\tHR@5=0.15493  MRR@5=0.08227  NDCG@5=0.10020\n",
      "\tHR@10=0.23758  MRR@10=0.09316  NDCG@10=0.12679\n",
      "\tHR@20=0.33914  MRR@20=0.10017  NDCG@20=0.15241\n",
      "[2020-03-02 15:09:10] [20/50] 0 mean_batch_loss : 7.355118\n",
      "Start predicting 2020-03-02 15:09:21\n",
      "change best\n",
      "testing finish [2020-03-02 15:09:24] \n",
      "\tHR@1=0.04449  MRR@1=0.04449  NDCG@1=0.04449\n",
      "\tHR@5=0.15527  MRR@5=0.08233  NDCG@5=0.10032\n",
      "\tHR@10=0.23962  MRR@10=0.09347  NDCG@10=0.12748\n",
      "\tHR@20=0.34626  MRR@20=0.10079  NDCG@20=0.15434\n",
      "[2020-03-02 15:09:24] [21/50] 0 mean_batch_loss : 7.009295\n",
      "Start predicting 2020-03-02 15:09:36\n",
      "testing finish [2020-03-02 15:09:39] \n",
      "\tHR@1=0.04393  MRR@1=0.04393  NDCG@1=0.04393\n",
      "\tHR@5=0.15488  MRR@5=0.08198  NDCG@5=0.09996\n",
      "\tHR@10=0.23783  MRR@10=0.09284  NDCG@10=0.12657\n",
      "\tHR@20=0.34615  MRR@20=0.10034  NDCG@20=0.15394\n",
      "[2020-03-02 15:09:39] [22/50] 0 mean_batch_loss : 7.291643\n",
      "Start predicting 2020-03-02 15:09:51\n",
      "change best\n",
      "testing finish [2020-03-02 15:09:54] \n",
      "\tHR@1=0.04318  MRR@1=0.04318  NDCG@1=0.04318\n",
      "\tHR@5=0.15569  MRR@5=0.08149  NDCG@5=0.09978\n",
      "\tHR@10=0.23987  MRR@10=0.09259  NDCG@10=0.12687\n",
      "\tHR@20=0.34825  MRR@20=0.10004  NDCG@20=0.15418\n",
      "[2020-03-02 15:09:54] [23/50] 0 mean_batch_loss : 6.947301\n",
      "Start predicting 2020-03-02 15:10:06\n",
      "change best\n",
      "testing finish [2020-03-02 15:10:09] \n",
      "\tHR@1=0.04530  MRR@1=0.04530  NDCG@1=0.04530\n",
      "\tHR@5=0.15831  MRR@5=0.08364  NDCG@5=0.10204\n",
      "\tHR@10=0.24133  MRR@10=0.09448  NDCG@10=0.12865\n",
      "\tHR@20=0.35089  MRR@20=0.10203  NDCG@20=0.15628\n",
      "[2020-03-02 15:10:09] [24/50] 0 mean_batch_loss : 7.079316\n",
      "Start predicting 2020-03-02 15:10:20\n",
      "testing finish [2020-03-02 15:10:23] \n",
      "\tHR@1=0.04546  MRR@1=0.04546  NDCG@1=0.04546\n",
      "\tHR@5=0.15472  MRR@5=0.08285  NDCG@5=0.10057\n",
      "\tHR@10=0.24197  MRR@10=0.09434  NDCG@10=0.12863\n",
      "\tHR@20=0.35012  MRR@20=0.10174  NDCG@20=0.15584\n",
      "[2020-03-02 15:10:23] [25/50] 0 mean_batch_loss : 6.942869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2020-03-02 15:10:35\n",
      "testing finish [2020-03-02 15:10:38] \n",
      "\tHR@1=0.04819  MRR@1=0.04819  NDCG@1=0.04819\n",
      "\tHR@5=0.15594  MRR@5=0.08469  NDCG@5=0.10225\n",
      "\tHR@10=0.24156  MRR@10=0.09594  NDCG@10=0.12975\n",
      "\tHR@20=0.34951  MRR@20=0.10333  NDCG@20=0.15693\n",
      "[2020-03-02 15:10:38] [26/50] 0 mean_batch_loss : 7.160785\n",
      "Start predicting 2020-03-02 15:10:50\n",
      "change best\n",
      "testing finish [2020-03-02 15:10:53] \n",
      "\tHR@1=0.04578  MRR@1=0.04578  NDCG@1=0.04578\n",
      "\tHR@5=0.15822  MRR@5=0.08360  NDCG@5=0.10197\n",
      "\tHR@10=0.24361  MRR@10=0.09488  NDCG@10=0.12946\n",
      "\tHR@20=0.35369  MRR@20=0.10247  NDCG@20=0.15723\n",
      "[2020-03-02 15:10:53] [27/50] 0 mean_batch_loss : 7.068726\n",
      "Start predicting 2020-03-02 15:11:05\n",
      "testing finish [2020-03-02 15:11:08] \n",
      "\tHR@1=0.04573  MRR@1=0.04573  NDCG@1=0.04573\n",
      "\tHR@5=0.15775  MRR@5=0.08358  NDCG@5=0.10185\n",
      "\tHR@10=0.24513  MRR@10=0.09515  NDCG@10=0.13002\n",
      "\tHR@20=0.35279  MRR@20=0.10256  NDCG@20=0.15715\n",
      "[2020-03-02 15:11:08] [28/50] 0 mean_batch_loss : 6.811332\n",
      "Start predicting 2020-03-02 15:11:20\n",
      "testing finish [2020-03-02 15:11:23] \n",
      "\tHR@1=0.04463  MRR@1=0.04463  NDCG@1=0.04463\n",
      "\tHR@5=0.15671  MRR@5=0.08276  NDCG@5=0.10098\n",
      "\tHR@10=0.24328  MRR@10=0.09420  NDCG@10=0.12887\n",
      "\tHR@20=0.35136  MRR@20=0.10161  NDCG@20=0.15608\n",
      "[2020-03-02 15:11:23] [29/50] 0 mean_batch_loss : 7.144918\n",
      "Start predicting 2020-03-02 15:11:35\n",
      "testing finish [2020-03-02 15:11:38] \n",
      "\tHR@1=0.04250  MRR@1=0.04250  NDCG@1=0.04250\n",
      "\tHR@5=0.15689  MRR@5=0.08134  NDCG@5=0.09996\n",
      "\tHR@10=0.24361  MRR@10=0.09281  NDCG@10=0.12790\n",
      "\tHR@20=0.35559  MRR@20=0.10055  NDCG@20=0.15617\n",
      "[2020-03-02 15:11:38] [30/50] 0 mean_batch_loss : 7.213503\n",
      "Start predicting 2020-03-02 15:11:50\n",
      "change best\n",
      "testing finish [2020-03-02 15:11:53] \n",
      "\tHR@1=0.04553  MRR@1=0.04553  NDCG@1=0.04553\n",
      "\tHR@5=0.15807  MRR@5=0.08383  NDCG@5=0.10213\n",
      "\tHR@10=0.24626  MRR@10=0.09542  NDCG@10=0.13047\n",
      "\tHR@20=0.35739  MRR@20=0.10303  NDCG@20=0.15845\n",
      "[2020-03-02 15:11:53] [31/50] 0 mean_batch_loss : 6.939764\n",
      "Start predicting 2020-03-02 15:12:05\n",
      "testing finish [2020-03-02 15:12:08] \n",
      "\tHR@1=0.04395  MRR@1=0.04395  NDCG@1=0.04395\n",
      "\tHR@5=0.15687  MRR@5=0.08185  NDCG@5=0.10032\n",
      "\tHR@10=0.24165  MRR@10=0.09306  NDCG@10=0.12763\n",
      "\tHR@20=0.35663  MRR@20=0.10090  NDCG@20=0.15652\n",
      "[2020-03-02 15:12:08] [32/50] 0 mean_batch_loss : 6.901330\n",
      "Start predicting 2020-03-02 15:12:20\n",
      "testing finish [2020-03-02 15:12:23] \n",
      "\tHR@1=0.04571  MRR@1=0.04571  NDCG@1=0.04571\n",
      "\tHR@5=0.15734  MRR@5=0.08363  NDCG@5=0.10180\n",
      "\tHR@10=0.24337  MRR@10=0.09495  NDCG@10=0.12947\n",
      "\tHR@20=0.35306  MRR@20=0.10252  NDCG@20=0.15714\n",
      "[2020-03-02 15:12:23] [33/50] 0 mean_batch_loss : 6.778872\n",
      "Start predicting 2020-03-02 15:12:35\n",
      "testing finish [2020-03-02 15:12:38] \n",
      "\tHR@1=0.04734  MRR@1=0.04734  NDCG@1=0.04734\n",
      "\tHR@5=0.15486  MRR@5=0.08388  NDCG@5=0.10138\n",
      "\tHR@10=0.23964  MRR@10=0.09501  NDCG@10=0.12860\n",
      "\tHR@20=0.35279  MRR@20=0.10281  NDCG@20=0.15715\n",
      "[2020-03-02 15:12:38] [34/50] 0 mean_batch_loss : 7.068860\n",
      "Start predicting 2020-03-02 15:12:50\n",
      "testing finish [2020-03-02 15:12:53] \n",
      "\tHR@1=0.04600  MRR@1=0.04600  NDCG@1=0.04600\n",
      "\tHR@5=0.15746  MRR@5=0.08338  NDCG@5=0.10161\n",
      "\tHR@10=0.24456  MRR@10=0.09476  NDCG@10=0.12952\n",
      "\tHR@20=0.35683  MRR@20=0.10252  NDCG@20=0.15788\n",
      "[2020-03-02 15:12:53] [35/50] 0 mean_batch_loss : 6.961690\n",
      "Start predicting 2020-03-02 15:13:05\n",
      "testing finish [2020-03-02 15:13:08] \n",
      "\tHR@1=0.04576  MRR@1=0.04576  NDCG@1=0.04576\n",
      "\tHR@5=0.15719  MRR@5=0.08413  NDCG@5=0.10217\n",
      "\tHR@10=0.24479  MRR@10=0.09568  NDCG@10=0.13036\n",
      "\tHR@20=0.35633  MRR@20=0.10333  NDCG@20=0.15845\n",
      "early stopping\n",
      "training and testting over, Total time 0:08:40.054713\n",
      "best model change\n",
      "current model hyper-parameters: session_length=20, hidden_size=10, lr=0.0030, embedding_dim=10, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "current model HR@20=0.35739  MRR@20=0.10303\n",
      "the best result so far. HR@20=0.35739  MRR@20=0.10303, current model hyper-parameters: session_length=20, hidden_size=10, lr=0.0030, embedding_dim=10, embedding_dropout=0.25, dropout=0.50\n",
      " \n",
      "\n",
      "current model hyper-parameters: session_length=20, hidden_size=20, lr=0.0030, embedding_dim=20, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "[2020-03-02 15:13:08] [1/50] 0 mean_batch_loss : 12.398650\n",
      "Start predicting 2020-03-02 15:13:20\n",
      "change best\n",
      "testing finish [2020-03-02 15:13:23] \n",
      "\tHR@1=0.03004  MRR@1=0.03004  NDCG@1=0.03004\n",
      "\tHR@5=0.06118  MRR@5=0.04123  NDCG@5=0.04618\n",
      "\tHR@10=0.07995  MRR@10=0.04370  NDCG@10=0.05221\n",
      "\tHR@20=0.10346  MRR@20=0.04532  NDCG@20=0.05814\n",
      "[2020-03-02 15:13:23] [2/50] 0 mean_batch_loss : 9.924412\n",
      "Start predicting 2020-03-02 15:13:35\n",
      "change best\n",
      "testing finish [2020-03-02 15:13:38] \n",
      "\tHR@1=0.04896  MRR@1=0.04896  NDCG@1=0.04896\n",
      "\tHR@5=0.08921  MRR@5=0.06358  NDCG@5=0.06995\n",
      "\tHR@10=0.11233  MRR@10=0.06665  NDCG@10=0.07741\n",
      "\tHR@20=0.13995  MRR@20=0.06857  NDCG@20=0.08440\n",
      "[2020-03-02 15:13:38] [3/50] 0 mean_batch_loss : 9.357822\n",
      "Start predicting 2020-03-02 15:13:50\n",
      "change best\n",
      "testing finish [2020-03-02 15:13:53] \n",
      "\tHR@1=0.06597  MRR@1=0.06597  NDCG@1=0.06597\n",
      "\tHR@5=0.12690  MRR@5=0.08802  NDCG@5=0.09767\n",
      "\tHR@10=0.15886  MRR@10=0.09227  NDCG@10=0.10800\n",
      "\tHR@20=0.19352  MRR@20=0.09466  NDCG@20=0.11674\n",
      "[2020-03-02 15:13:54] [4/50] 0 mean_batch_loss : 9.089150\n",
      "Start predicting 2020-03-02 15:14:06\n",
      "change best\n",
      "testing finish [2020-03-02 15:14:09] \n",
      "\tHR@1=0.07164  MRR@1=0.07164  NDCG@1=0.07164\n",
      "\tHR@5=0.14960  MRR@5=0.09968  NDCG@5=0.11206\n",
      "\tHR@10=0.19235  MRR@10=0.10535  NDCG@10=0.12586\n",
      "\tHR@20=0.23695  MRR@20=0.10842  NDCG@20=0.13710\n",
      "[2020-03-02 15:14:09] [5/50] 0 mean_batch_loss : 8.397649\n",
      "Start predicting 2020-03-02 15:14:21\n",
      "change best\n",
      "testing finish [2020-03-02 15:14:24] \n",
      "\tHR@1=0.07511  MRR@1=0.07511  NDCG@1=0.07511\n",
      "\tHR@5=0.17026  MRR@5=0.10936  NDCG@5=0.12447\n",
      "\tHR@10=0.22329  MRR@10=0.11643  NDCG@10=0.14162\n",
      "\tHR@20=0.28354  MRR@20=0.12060  NDCG@20=0.15683\n",
      "[2020-03-02 15:14:24] [6/50] 0 mean_batch_loss : 8.159271\n",
      "Start predicting 2020-03-02 15:14:36\n",
      "change best\n",
      "testing finish [2020-03-02 15:14:39] \n",
      "\tHR@1=0.08083  MRR@1=0.08083  NDCG@1=0.08083\n",
      "\tHR@5=0.19402  MRR@5=0.12138  NDCG@5=0.13940\n",
      "\tHR@10=0.26114  MRR@10=0.13027  NDCG@10=0.16103\n",
      "\tHR@20=0.33298  MRR@20=0.13525  NDCG@20=0.17919\n",
      "[2020-03-02 15:14:39] [7/50] 0 mean_batch_loss : 7.681224\n",
      "Start predicting 2020-03-02 15:14:51\n",
      "change best\n",
      "testing finish [2020-03-02 15:14:54] \n",
      "\tHR@1=0.08365  MRR@1=0.08365  NDCG@1=0.08365\n",
      "\tHR@5=0.21290  MRR@5=0.12926  NDCG@5=0.14998\n",
      "\tHR@10=0.28779  MRR@10=0.13919  NDCG@10=0.17413\n",
      "\tHR@20=0.37029  MRR@20=0.14492  NDCG@20=0.19500\n",
      "[2020-03-02 15:14:54] [8/50] 0 mean_batch_loss : 7.015753\n",
      "Start predicting 2020-03-02 15:15:06\n",
      "change best\n",
      "testing finish [2020-03-02 15:15:09] \n",
      "\tHR@1=0.08510  MRR@1=0.08510  NDCG@1=0.08510\n",
      "\tHR@5=0.22631  MRR@5=0.13493  NDCG@5=0.15755\n",
      "\tHR@10=0.30852  MRR@10=0.14581  NDCG@10=0.18404\n",
      "\tHR@20=0.40005  MRR@20=0.15218  NDCG@20=0.20720\n",
      "[2020-03-02 15:15:09] [9/50] 0 mean_batch_loss : 6.839465\n",
      "Start predicting 2020-03-02 15:15:21\n",
      "change best\n",
      "testing finish [2020-03-02 15:15:24] \n",
      "\tHR@1=0.08385  MRR@1=0.08385  NDCG@1=0.08385\n",
      "\tHR@5=0.23126  MRR@5=0.13588  NDCG@5=0.15950\n",
      "\tHR@10=0.32189  MRR@10=0.14796  NDCG@10=0.18879\n",
      "\tHR@20=0.42088  MRR@20=0.15483  NDCG@20=0.21382\n",
      "[2020-03-02 15:15:24] [10/50] 0 mean_batch_loss : 6.543923\n",
      "Start predicting 2020-03-02 15:15:36\n",
      "change best\n",
      "testing finish [2020-03-02 15:15:39] \n",
      "\tHR@1=0.08717  MRR@1=0.08717  NDCG@1=0.08717\n",
      "\tHR@5=0.24014  MRR@5=0.14067  NDCG@5=0.16527\n",
      "\tHR@10=0.33339  MRR@10=0.15308  NDCG@10=0.19539\n",
      "\tHR@20=0.43748  MRR@20=0.16028  NDCG@20=0.22169\n",
      "[2020-03-02 15:15:39] [11/50] 0 mean_batch_loss : 6.554244\n",
      "Start predicting 2020-03-02 15:15:51\n",
      "change best\n",
      "testing finish [2020-03-02 15:15:54] \n",
      "\tHR@1=0.08839  MRR@1=0.08839  NDCG@1=0.08839\n",
      "\tHR@5=0.24596  MRR@5=0.14347  NDCG@5=0.16882\n",
      "\tHR@10=0.34443  MRR@10=0.15647  NDCG@10=0.20052\n",
      "\tHR@20=0.45044  MRR@20=0.16380  NDCG@20=0.22729\n",
      "[2020-03-02 15:15:55] [12/50] 0 mean_batch_loss : 6.421515\n",
      "Start predicting 2020-03-02 15:16:07\n",
      "change best\n",
      "testing finish [2020-03-02 15:16:10] \n",
      "\tHR@1=0.08731  MRR@1=0.08731  NDCG@1=0.08731\n",
      "\tHR@5=0.24994  MRR@5=0.14461  NDCG@5=0.17069\n",
      "\tHR@10=0.34965  MRR@10=0.15789  NDCG@10=0.20290\n",
      "\tHR@20=0.46126  MRR@20=0.16558  NDCG@20=0.23105\n",
      "[2020-03-02 15:16:10] [13/50] 0 mean_batch_loss : 6.296283\n",
      "Start predicting 2020-03-02 15:16:21\n",
      "change best\n",
      "testing finish [2020-03-02 15:16:25] \n",
      "\tHR@1=0.08864  MRR@1=0.08864  NDCG@1=0.08864\n",
      "\tHR@5=0.25190  MRR@5=0.14579  NDCG@5=0.17204\n",
      "\tHR@10=0.35369  MRR@10=0.15935  NDCG@10=0.20493\n",
      "\tHR@20=0.46593  MRR@20=0.16717  NDCG@20=0.23334\n",
      "[2020-03-02 15:16:25] [14/50] 0 mean_batch_loss : 6.200770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2020-03-02 15:16:37\n",
      "change best\n",
      "testing finish [2020-03-02 15:16:40] \n",
      "\tHR@1=0.09049  MRR@1=0.09049  NDCG@1=0.09049\n",
      "\tHR@5=0.25854  MRR@5=0.14926  NDCG@5=0.17630\n",
      "\tHR@10=0.36026  MRR@10=0.16271  NDCG@10=0.20906\n",
      "\tHR@20=0.47332  MRR@20=0.17054  NDCG@20=0.23762\n",
      "[2020-03-02 15:16:40] [15/50] 0 mean_batch_loss : 6.030202\n",
      "Start predicting 2020-03-02 15:16:52\n",
      "change best\n",
      "testing finish [2020-03-02 15:16:55] \n",
      "\tHR@1=0.09054  MRR@1=0.09054  NDCG@1=0.09054\n",
      "\tHR@5=0.26344  MRR@5=0.15078  NDCG@5=0.17864\n",
      "\tHR@10=0.36774  MRR@10=0.16461  NDCG@10=0.21227\n",
      "\tHR@20=0.48334  MRR@20=0.17257  NDCG@20=0.24143\n",
      "[2020-03-02 15:16:55] [16/50] 0 mean_batch_loss : 6.019308\n",
      "Start predicting 2020-03-02 15:17:07\n",
      "change best\n",
      "testing finish [2020-03-02 15:17:10] \n",
      "\tHR@1=0.08973  MRR@1=0.08973  NDCG@1=0.08973\n",
      "\tHR@5=0.26326  MRR@5=0.15065  NDCG@5=0.17852\n",
      "\tHR@10=0.36796  MRR@10=0.16457  NDCG@10=0.21232\n",
      "\tHR@20=0.48483  MRR@20=0.17263  NDCG@20=0.24181\n",
      "[2020-03-02 15:17:10] [17/50] 0 mean_batch_loss : 6.136656\n",
      "Start predicting 2020-03-02 15:17:22\n",
      "change best\n",
      "testing finish [2020-03-02 15:17:26] \n",
      "\tHR@1=0.09257  MRR@1=0.09257  NDCG@1=0.09257\n",
      "\tHR@5=0.27013  MRR@5=0.15487  NDCG@5=0.18340\n",
      "\tHR@10=0.37505  MRR@10=0.16877  NDCG@10=0.21723\n",
      "\tHR@20=0.49507  MRR@20=0.17704  NDCG@20=0.24749\n",
      "[2020-03-02 15:17:26] [18/50] 0 mean_batch_loss : 5.867286\n",
      "Start predicting 2020-03-02 15:17:38\n",
      "change best\n",
      "testing finish [2020-03-02 15:17:41] \n",
      "\tHR@1=0.09122  MRR@1=0.09122  NDCG@1=0.09122\n",
      "\tHR@5=0.26954  MRR@5=0.15398  NDCG@5=0.18259\n",
      "\tHR@10=0.37765  MRR@10=0.16832  NDCG@10=0.21746\n",
      "\tHR@20=0.49737  MRR@20=0.17663  NDCG@20=0.24774\n",
      "[2020-03-02 15:17:41] [19/50] 0 mean_batch_loss : 5.722460\n",
      "Start predicting 2020-03-02 15:17:53\n",
      "change best\n",
      "testing finish [2020-03-02 15:17:56] \n",
      "\tHR@1=0.09596  MRR@1=0.09596  NDCG@1=0.09596\n",
      "\tHR@5=0.27503  MRR@5=0.15860  NDCG@5=0.18740\n",
      "\tHR@10=0.38567  MRR@10=0.17325  NDCG@10=0.22306\n",
      "\tHR@20=0.50347  MRR@20=0.18138  NDCG@20=0.25279\n",
      "[2020-03-02 15:17:56] [20/50] 0 mean_batch_loss : 5.920028\n",
      "Start predicting 2020-03-02 15:18:08\n",
      "change best\n",
      "testing finish [2020-03-02 15:18:11] \n",
      "\tHR@1=0.09497  MRR@1=0.09497  NDCG@1=0.09497\n",
      "\tHR@5=0.27363  MRR@5=0.15761  NDCG@5=0.18631\n",
      "\tHR@10=0.38203  MRR@10=0.17202  NDCG@10=0.22131\n",
      "\tHR@20=0.50453  MRR@20=0.18049  NDCG@20=0.25224\n",
      "[2020-03-02 15:18:11] [21/50] 0 mean_batch_loss : 5.844900\n",
      "Start predicting 2020-03-02 15:18:23\n",
      "change best\n",
      "testing finish [2020-03-02 15:18:27] \n",
      "\tHR@1=0.09756  MRR@1=0.09756  NDCG@1=0.09756\n",
      "\tHR@5=0.27889  MRR@5=0.16074  NDCG@5=0.18996\n",
      "\tHR@10=0.39129  MRR@10=0.17574  NDCG@10=0.22630\n",
      "\tHR@20=0.51182  MRR@20=0.18409  NDCG@20=0.25675\n",
      "[2020-03-02 15:18:27] [22/50] 0 mean_batch_loss : 5.935389\n",
      "Start predicting 2020-03-02 15:18:39\n",
      "change best\n",
      "testing finish [2020-03-02 15:18:42] \n",
      "\tHR@1=0.09560  MRR@1=0.09560  NDCG@1=0.09560\n",
      "\tHR@5=0.28275  MRR@5=0.16073  NDCG@5=0.19090\n",
      "\tHR@10=0.39186  MRR@10=0.17515  NDCG@10=0.22604\n",
      "\tHR@20=0.51498  MRR@20=0.18371  NDCG@20=0.25718\n",
      "[2020-03-02 15:18:42] [23/50] 0 mean_batch_loss : 5.580629\n",
      "Start predicting 2020-03-02 15:18:54\n",
      "change best\n",
      "testing finish [2020-03-02 15:18:57] \n",
      "\tHR@1=0.09528  MRR@1=0.09528  NDCG@1=0.09528\n",
      "\tHR@5=0.28201  MRR@5=0.16063  NDCG@5=0.19066\n",
      "\tHR@10=0.39159  MRR@10=0.17523  NDCG@10=0.22607\n",
      "\tHR@20=0.51727  MRR@20=0.18394  NDCG@20=0.25783\n",
      "[2020-03-02 15:18:57] [24/50] 0 mean_batch_loss : 5.695034\n",
      "Start predicting 2020-03-02 15:19:09\n",
      "change best\n",
      "testing finish [2020-03-02 15:19:12] \n",
      "\tHR@1=0.09901  MRR@1=0.09901  NDCG@1=0.09901\n",
      "\tHR@5=0.28397  MRR@5=0.16334  NDCG@5=0.19316\n",
      "\tHR@10=0.39694  MRR@10=0.17840  NDCG@10=0.22968\n",
      "\tHR@20=0.52223  MRR@20=0.18705  NDCG@20=0.26130\n",
      "[2020-03-02 15:19:12] [25/50] 0 mean_batch_loss : 5.615204\n",
      "Start predicting 2020-03-02 15:19:24\n",
      "change best\n",
      "testing finish [2020-03-02 15:19:27] \n",
      "\tHR@1=0.09786  MRR@1=0.09786  NDCG@1=0.09786\n",
      "\tHR@5=0.28795  MRR@5=0.16441  NDCG@5=0.19497\n",
      "\tHR@10=0.39978  MRR@10=0.17924  NDCG@10=0.23104\n",
      "\tHR@20=0.52659  MRR@20=0.18803  NDCG@20=0.26308\n",
      "[2020-03-02 15:19:28] [26/50] 0 mean_batch_loss : 5.577728\n",
      "Start predicting 2020-03-02 15:19:40\n",
      "change best\n",
      "testing finish [2020-03-02 15:19:43] \n",
      "\tHR@1=0.09928  MRR@1=0.09928  NDCG@1=0.09928\n",
      "\tHR@5=0.28817  MRR@5=0.16573  NDCG@5=0.19603\n",
      "\tHR@10=0.40294  MRR@10=0.18101  NDCG@10=0.23311\n",
      "\tHR@20=0.52924  MRR@20=0.18973  NDCG@20=0.26500\n",
      "[2020-03-02 15:19:43] [27/50] 0 mean_batch_loss : 5.570182\n",
      "Start predicting 2020-03-02 15:19:55\n",
      "testing finish [2020-03-02 15:19:58] \n",
      "\tHR@1=0.09978  MRR@1=0.09978  NDCG@1=0.09978\n",
      "\tHR@5=0.28955  MRR@5=0.16608  NDCG@5=0.19662\n",
      "\tHR@10=0.40374  MRR@10=0.18123  NDCG@10=0.23345\n",
      "\tHR@20=0.52876  MRR@20=0.18988  NDCG@20=0.26503\n",
      "[2020-03-02 15:19:58] [28/50] 0 mean_batch_loss : 5.638495\n",
      "Start predicting 2020-03-02 15:20:10\n",
      "change best\n",
      "testing finish [2020-03-02 15:20:14] \n",
      "\tHR@1=0.09969  MRR@1=0.09969  NDCG@1=0.09969\n",
      "\tHR@5=0.29197  MRR@5=0.16672  NDCG@5=0.19768\n",
      "\tHR@10=0.40742  MRR@10=0.18212  NDCG@10=0.23502\n",
      "\tHR@20=0.53398  MRR@20=0.19089  NDCG@20=0.26700\n",
      "[2020-03-02 15:20:14] [29/50] 0 mean_batch_loss : 5.620504\n",
      "Start predicting 2020-03-02 15:20:26\n",
      "change best\n",
      "testing finish [2020-03-02 15:20:29] \n",
      "\tHR@1=0.10032  MRR@1=0.10032  NDCG@1=0.10032\n",
      "\tHR@5=0.29296  MRR@5=0.16791  NDCG@5=0.19886\n",
      "\tHR@10=0.40796  MRR@10=0.18319  NDCG@10=0.23598\n",
      "\tHR@20=0.53567  MRR@20=0.19205  NDCG@20=0.26827\n",
      "[2020-03-02 15:20:29] [30/50] 0 mean_batch_loss : 5.502896\n",
      "Start predicting 2020-03-02 15:20:41\n",
      "change best\n",
      "testing finish [2020-03-02 15:20:44] \n",
      "\tHR@1=0.10174  MRR@1=0.10174  NDCG@1=0.10174\n",
      "\tHR@5=0.29380  MRR@5=0.16892  NDCG@5=0.19982\n",
      "\tHR@10=0.41013  MRR@10=0.18433  NDCG@10=0.23732\n",
      "\tHR@20=0.53743  MRR@20=0.19314  NDCG@20=0.26947\n",
      "[2020-03-02 15:20:45] [31/50] 0 mean_batch_loss : 5.550848\n",
      "Start predicting 2020-03-02 15:20:57\n",
      "change best\n",
      "testing finish [2020-03-02 15:21:00] \n",
      "\tHR@1=0.10319  MRR@1=0.10319  NDCG@1=0.10319\n",
      "\tHR@5=0.29578  MRR@5=0.17039  NDCG@5=0.20141\n",
      "\tHR@10=0.41476  MRR@10=0.18618  NDCG@10=0.23979\n",
      "\tHR@20=0.54012  MRR@20=0.19486  NDCG@20=0.27147\n",
      "[2020-03-02 15:21:00] [32/50] 0 mean_batch_loss : 5.759753\n",
      "Start predicting 2020-03-02 15:21:12\n",
      "change best\n",
      "testing finish [2020-03-02 15:21:15] \n",
      "\tHR@1=0.10642  MRR@1=0.10642  NDCG@1=0.10642\n",
      "\tHR@5=0.30068  MRR@5=0.17417  NDCG@5=0.20545\n",
      "\tHR@10=0.41887  MRR@10=0.18988  NDCG@10=0.24361\n",
      "\tHR@20=0.54450  MRR@20=0.19858  NDCG@20=0.27535\n",
      "[2020-03-02 15:21:15] [33/50] 0 mean_batch_loss : 5.690309\n",
      "Start predicting 2020-03-02 15:21:27\n",
      "testing finish [2020-03-02 15:21:31] \n",
      "\tHR@1=0.10287  MRR@1=0.10287  NDCG@1=0.10287\n",
      "\tHR@5=0.30096  MRR@5=0.17220  NDCG@5=0.20405\n",
      "\tHR@10=0.41738  MRR@10=0.18771  NDCG@10=0.24167\n",
      "\tHR@20=0.54441  MRR@20=0.19651  NDCG@20=0.27378\n",
      "[2020-03-02 15:21:31] [34/50] 0 mean_batch_loss : 5.564920\n",
      "Start predicting 2020-03-02 15:21:43\n",
      "testing finish [2020-03-02 15:21:46] \n",
      "\tHR@1=0.10452  MRR@1=0.10452  NDCG@1=0.10452\n",
      "\tHR@5=0.29849  MRR@5=0.17289  NDCG@5=0.20399\n",
      "\tHR@10=0.41708  MRR@10=0.18867  NDCG@10=0.24228\n",
      "\tHR@20=0.54423  MRR@20=0.19747  NDCG@20=0.27440\n",
      "[2020-03-02 15:21:46] [35/50] 0 mean_batch_loss : 5.371070\n",
      "Start predicting 2020-03-02 15:21:58\n",
      "change best\n",
      "testing finish [2020-03-02 15:22:01] \n",
      "\tHR@1=0.10332  MRR@1=0.10332  NDCG@1=0.10332\n",
      "\tHR@5=0.30161  MRR@5=0.17255  NDCG@5=0.20447\n",
      "\tHR@10=0.41896  MRR@10=0.18813  NDCG@10=0.24234\n",
      "\tHR@20=0.54730  MRR@20=0.19698  NDCG@20=0.27471\n",
      "[2020-03-02 15:22:01] [36/50] 0 mean_batch_loss : 5.542442\n",
      "Start predicting 2020-03-02 15:22:13\n",
      "testing finish [2020-03-02 15:22:16] \n",
      "\tHR@1=0.10472  MRR@1=0.10472  NDCG@1=0.10472\n",
      "\tHR@5=0.30048  MRR@5=0.17343  NDCG@5=0.20487\n",
      "\tHR@10=0.41871  MRR@10=0.18921  NDCG@10=0.24311\n",
      "\tHR@20=0.54500  MRR@20=0.19799  NDCG@20=0.27505\n",
      "[2020-03-02 15:22:16] [37/50] 0 mean_batch_loss : 5.245435\n",
      "Start predicting 2020-03-02 15:22:28\n",
      "change best\n",
      "testing finish [2020-03-02 15:22:31] \n",
      "\tHR@1=0.10339  MRR@1=0.10339  NDCG@1=0.10339\n",
      "\tHR@5=0.30256  MRR@5=0.17338  NDCG@5=0.20535\n",
      "\tHR@10=0.42257  MRR@10=0.18946  NDCG@10=0.24422\n",
      "\tHR@20=0.55114  MRR@20=0.19835  NDCG@20=0.27669\n",
      "[2020-03-02 15:22:31] [38/50] 0 mean_batch_loss : 5.502166\n",
      "Start predicting 2020-03-02 15:22:44\n",
      "change best\n",
      "testing finish [2020-03-02 15:22:47] \n",
      "\tHR@1=0.10339  MRR@1=0.10339  NDCG@1=0.10339\n",
      "\tHR@5=0.30520  MRR@5=0.17428  NDCG@5=0.20667\n",
      "\tHR@10=0.42295  MRR@10=0.18994  NDCG@10=0.24469\n",
      "\tHR@20=0.55141  MRR@20=0.19886  NDCG@20=0.27718\n",
      "[2020-03-02 15:22:47] [39/50] 0 mean_batch_loss : 5.431009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2020-03-02 15:22:59\n",
      "testing finish [2020-03-02 15:23:02] \n",
      "\tHR@1=0.10409  MRR@1=0.10409  NDCG@1=0.10409\n",
      "\tHR@5=0.30516  MRR@5=0.17458  NDCG@5=0.20690\n",
      "\tHR@10=0.42253  MRR@10=0.19022  NDCG@10=0.24483\n",
      "\tHR@20=0.55094  MRR@20=0.19913  NDCG@20=0.27730\n",
      "[2020-03-02 15:23:02] [40/50] 0 mean_batch_loss : 5.447358\n",
      "Start predicting 2020-03-02 15:23:14\n",
      "change best\n",
      "testing finish [2020-03-02 15:23:17] \n",
      "\tHR@1=0.10477  MRR@1=0.10477  NDCG@1=0.10477\n",
      "\tHR@5=0.30635  MRR@5=0.17574  NDCG@5=0.20808\n",
      "\tHR@10=0.42492  MRR@10=0.19146  NDCG@10=0.24631\n",
      "\tHR@20=0.55354  MRR@20=0.20044  NDCG@20=0.27890\n",
      "[2020-03-02 15:23:17] [41/50] 0 mean_batch_loss : 5.206198\n",
      "Start predicting 2020-03-02 15:23:29\n",
      "change best\n",
      "testing finish [2020-03-02 15:23:32] \n",
      "\tHR@1=0.10450  MRR@1=0.10450  NDCG@1=0.10450\n",
      "\tHR@5=0.30879  MRR@5=0.17575  NDCG@5=0.20865\n",
      "\tHR@10=0.42962  MRR@10=0.19180  NDCG@10=0.24764\n",
      "\tHR@20=0.55735  MRR@20=0.20067  NDCG@20=0.27994\n",
      "[2020-03-02 15:23:33] [42/50] 0 mean_batch_loss : 5.334809\n",
      "Start predicting 2020-03-02 15:23:44\n",
      "change best\n",
      "testing finish [2020-03-02 15:23:48] \n",
      "\tHR@1=0.10678  MRR@1=0.10678  NDCG@1=0.10678\n",
      "\tHR@5=0.30839  MRR@5=0.17773  NDCG@5=0.21006\n",
      "\tHR@10=0.43054  MRR@10=0.19400  NDCG@10=0.24953\n",
      "\tHR@20=0.55744  MRR@20=0.20280  NDCG@20=0.28161\n",
      "[2020-03-02 15:23:48] [43/50] 0 mean_batch_loss : 5.425480\n",
      "Start predicting 2020-03-02 15:24:00\n",
      "testing finish [2020-03-02 15:24:03] \n",
      "\tHR@1=0.10357  MRR@1=0.10357  NDCG@1=0.10357\n",
      "\tHR@5=0.30741  MRR@5=0.17521  NDCG@5=0.20793\n",
      "\tHR@10=0.43045  MRR@10=0.19161  NDCG@10=0.24770\n",
      "\tHR@20=0.55783  MRR@20=0.20044  NDCG@20=0.27989\n",
      "[2020-03-02 15:24:03] [44/50] 0 mean_batch_loss : 5.644121\n",
      "Start predicting 2020-03-02 15:24:15\n",
      "change best\n",
      "testing finish [2020-03-02 15:24:18] \n",
      "\tHR@1=0.10827  MRR@1=0.10827  NDCG@1=0.10827\n",
      "\tHR@5=0.31125  MRR@5=0.17938  NDCG@5=0.21201\n",
      "\tHR@10=0.43151  MRR@10=0.19536  NDCG@10=0.25082\n",
      "\tHR@20=0.55891  MRR@20=0.20418  NDCG@20=0.28301\n",
      "[2020-03-02 15:24:18] [45/50] 0 mean_batch_loss : 5.559216\n",
      "Start predicting 2020-03-02 15:24:30\n",
      "change best\n",
      "testing finish [2020-03-02 15:24:33] \n",
      "\tHR@1=0.10892  MRR@1=0.10892  NDCG@1=0.10892\n",
      "\tHR@5=0.30972  MRR@5=0.17937  NDCG@5=0.21162\n",
      "\tHR@10=0.43278  MRR@10=0.19575  NDCG@10=0.25138\n",
      "\tHR@20=0.55923  MRR@20=0.20448  NDCG@20=0.28329\n",
      "[2020-03-02 15:24:33] [46/50] 0 mean_batch_loss : 5.633139\n",
      "Start predicting 2020-03-02 15:24:45\n",
      "change best\n",
      "testing finish [2020-03-02 15:24:48] \n",
      "\tHR@1=0.10698  MRR@1=0.10698  NDCG@1=0.10698\n",
      "\tHR@5=0.31304  MRR@5=0.17955  NDCG@5=0.21259\n",
      "\tHR@10=0.43190  MRR@10=0.19532  NDCG@10=0.25094\n",
      "\tHR@20=0.56203  MRR@20=0.20436  NDCG@20=0.28386\n",
      "[2020-03-02 15:24:49] [47/50] 0 mean_batch_loss : 5.403635\n",
      "Start predicting 2020-03-02 15:25:00\n",
      "change best\n",
      "testing finish [2020-03-02 15:25:03] \n",
      "\tHR@1=0.10617  MRR@1=0.10617  NDCG@1=0.10617\n",
      "\tHR@5=0.31189  MRR@5=0.17871  NDCG@5=0.21169\n",
      "\tHR@10=0.43650  MRR@10=0.19533  NDCG@10=0.25198\n",
      "\tHR@20=0.56325  MRR@20=0.20413  NDCG@20=0.28403\n",
      "[2020-03-02 15:25:04] [48/50] 0 mean_batch_loss : 5.638476\n",
      "Start predicting 2020-03-02 15:25:15\n",
      "change best\n",
      "testing finish [2020-03-02 15:25:18] \n",
      "\tHR@1=0.10987  MRR@1=0.10987  NDCG@1=0.10987\n",
      "\tHR@5=0.31252  MRR@5=0.18096  NDCG@5=0.21351\n",
      "\tHR@10=0.43355  MRR@10=0.19708  NDCG@10=0.25261\n",
      "\tHR@20=0.56232  MRR@20=0.20603  NDCG@20=0.28519\n",
      "[2020-03-02 15:25:18] [49/50] 0 mean_batch_loss : 5.341802\n",
      "Start predicting 2020-03-02 15:25:30\n",
      "change best\n",
      "testing finish [2020-03-02 15:25:33] \n",
      "\tHR@1=0.10538  MRR@1=0.10538  NDCG@1=0.10538\n",
      "\tHR@5=0.31690  MRR@5=0.18004  NDCG@5=0.21393\n",
      "\tHR@10=0.43517  MRR@10=0.19576  NDCG@10=0.25211\n",
      "\tHR@20=0.56399  MRR@20=0.20472  NDCG@20=0.28470\n",
      "[2020-03-02 15:25:33] [50/50] 0 mean_batch_loss : 5.304245\n",
      "Start predicting 2020-03-02 15:25:45\n",
      "testing finish [2020-03-02 15:25:48] \n",
      "\tHR@1=0.10685  MRR@1=0.10685  NDCG@1=0.10685\n",
      "\tHR@5=0.31347  MRR@5=0.17903  NDCG@5=0.21228\n",
      "\tHR@10=0.43605  MRR@10=0.19536  NDCG@10=0.25188\n",
      "\tHR@20=0.56388  MRR@20=0.20426  NDCG@20=0.28425\n",
      "training and testting over, Total time 0:12:40.132797\n",
      "best model change\n",
      "current model hyper-parameters: session_length=20, hidden_size=20, lr=0.0030, embedding_dim=20, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "current model HR@20=0.56399  MRR@20=0.20472\n",
      "the best result so far. HR@20=0.56399  MRR@20=0.20472, current model hyper-parameters: session_length=20, hidden_size=20, lr=0.0030, embedding_dim=20, embedding_dropout=0.25, dropout=0.50\n",
      " \n",
      "\n",
      "current model hyper-parameters: session_length=20, hidden_size=50, lr=0.0030, embedding_dim=50, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "[2020-03-02 15:25:48] [1/50] 0 mean_batch_loss : 12.987446\n",
      "Start predicting 2020-03-02 15:26:02\n",
      "change best\n",
      "testing finish [2020-03-02 15:26:05] \n",
      "\tHR@1=0.18117  MRR@1=0.18117  NDCG@1=0.18117\n",
      "\tHR@5=0.20958  MRR@5=0.19232  NDCG@5=0.19665\n",
      "\tHR@10=0.22031  MRR@10=0.19375  NDCG@10=0.20012\n",
      "\tHR@20=0.23113  MRR@20=0.19451  NDCG@20=0.20286\n",
      "[2020-03-02 15:26:06] [2/50] 0 mean_batch_loss : 9.610478\n",
      "Start predicting 2020-03-02 15:26:20\n",
      "change best\n",
      "testing finish [2020-03-02 15:26:23] \n",
      "\tHR@1=0.17523  MRR@1=0.17523  NDCG@1=0.17523\n",
      "\tHR@5=0.22909  MRR@5=0.19531  NDCG@5=0.20373\n",
      "\tHR@10=0.25211  MRR@10=0.19839  NDCG@10=0.21118\n",
      "\tHR@20=0.27663  MRR@20=0.20009  NDCG@20=0.21738\n",
      "[2020-03-02 15:26:23] [3/50] 0 mean_batch_loss : 8.606475\n",
      "Start predicting 2020-03-02 15:26:37\n",
      "change best\n",
      "testing finish [2020-03-02 15:26:40] \n",
      "\tHR@1=0.15012  MRR@1=0.15012  NDCG@1=0.15012\n",
      "\tHR@5=0.24120  MRR@5=0.18363  NDCG@5=0.19795\n",
      "\tHR@10=0.28469  MRR@10=0.18937  NDCG@10=0.21196\n",
      "\tHR@20=0.33022  MRR@20=0.19253  NDCG@20=0.22347\n",
      "[2020-03-02 15:26:40] [4/50] 0 mean_batch_loss : 7.806285\n",
      "Start predicting 2020-03-02 15:26:54\n",
      "change best\n",
      "testing finish [2020-03-02 15:26:57] \n",
      "\tHR@1=0.14183  MRR@1=0.14183  NDCG@1=0.14183\n",
      "\tHR@5=0.26290  MRR@5=0.18595  NDCG@5=0.20508\n",
      "\tHR@10=0.32573  MRR@10=0.19429  NDCG@10=0.22535\n",
      "\tHR@20=0.39030  MRR@20=0.19877  NDCG@20=0.24168\n",
      "[2020-03-02 15:26:57] [5/50] 0 mean_batch_loss : 7.016835\n",
      "Start predicting 2020-03-02 15:27:12\n",
      "change best\n",
      "testing finish [2020-03-02 15:27:15] \n",
      "\tHR@1=0.14544  MRR@1=0.14544  NDCG@1=0.14544\n",
      "\tHR@5=0.29140  MRR@5=0.19789  NDCG@5=0.22109\n",
      "\tHR@10=0.36672  MRR@10=0.20790  NDCG@10=0.24540\n",
      "\tHR@20=0.44789  MRR@20=0.21355  NDCG@20=0.26595\n",
      "[2020-03-02 15:27:15] [6/50] 0 mean_batch_loss : 6.277448\n",
      "Start predicting 2020-03-02 15:27:29\n",
      "change best\n",
      "testing finish [2020-03-02 15:27:32] \n",
      "\tHR@1=0.15759  MRR@1=0.15759  NDCG@1=0.15759\n",
      "\tHR@5=0.31900  MRR@5=0.21597  NDCG@5=0.24155\n",
      "\tHR@10=0.40584  MRR@10=0.22752  NDCG@10=0.26959\n",
      "\tHR@20=0.49317  MRR@20=0.23357  NDCG@20=0.29167\n",
      "[2020-03-02 15:27:32] [7/50] 0 mean_batch_loss : 5.703815\n",
      "Start predicting 2020-03-02 15:27:46\n",
      "change best\n",
      "testing finish [2020-03-02 15:27:49] \n",
      "\tHR@1=0.15016  MRR@1=0.15016  NDCG@1=0.15016\n",
      "\tHR@5=0.32729  MRR@5=0.21420  NDCG@5=0.24227\n",
      "\tHR@10=0.41963  MRR@10=0.22651  NDCG@10=0.27213\n",
      "\tHR@20=0.51760  MRR@20=0.23330  NDCG@20=0.29688\n",
      "[2020-03-02 15:27:49] [8/50] 0 mean_batch_loss : 5.665153\n",
      "Start predicting 2020-03-02 15:28:04\n",
      "change best\n",
      "testing finish [2020-03-02 15:28:07] \n",
      "\tHR@1=0.15583  MRR@1=0.15583  NDCG@1=0.15583\n",
      "\tHR@5=0.34115  MRR@5=0.22297  NDCG@5=0.25232\n",
      "\tHR@10=0.43863  MRR@10=0.23592  NDCG@10=0.28379\n",
      "\tHR@20=0.53750  MRR@20=0.24278  NDCG@20=0.30878\n",
      "[2020-03-02 15:28:07] [9/50] 0 mean_batch_loss : 5.498124\n",
      "Start predicting 2020-03-02 15:28:21\n",
      "change best\n",
      "testing finish [2020-03-02 15:28:24] \n",
      "\tHR@1=0.15807  MRR@1=0.15807  NDCG@1=0.15807\n",
      "\tHR@5=0.34768  MRR@5=0.22668  NDCG@5=0.25673\n",
      "\tHR@10=0.44624  MRR@10=0.23983  NDCG@10=0.28860\n",
      "\tHR@20=0.55031  MRR@20=0.24708  NDCG@20=0.31494\n",
      "[2020-03-02 15:28:24] [10/50] 0 mean_batch_loss : 5.062971\n",
      "Start predicting 2020-03-02 15:28:38\n",
      "change best\n",
      "testing finish [2020-03-02 15:28:41] \n",
      "\tHR@1=0.16175  MRR@1=0.16175  NDCG@1=0.16175\n",
      "\tHR@5=0.36026  MRR@5=0.23341  NDCG@5=0.26490\n",
      "\tHR@10=0.46117  MRR@10=0.24693  NDCG@10=0.29758\n",
      "\tHR@20=0.56691  MRR@20=0.25427  NDCG@20=0.32432\n",
      "[2020-03-02 15:28:41] [11/50] 0 mean_batch_loss : 4.988173\n",
      "Start predicting 2020-03-02 15:28:55\n",
      "change best\n",
      "testing finish [2020-03-02 15:28:59] \n",
      "\tHR@1=0.16050  MRR@1=0.16050  NDCG@1=0.16050\n",
      "\tHR@5=0.36521  MRR@5=0.23489  NDCG@5=0.26727\n",
      "\tHR@10=0.46763  MRR@10=0.24850  NDCG@10=0.30034\n",
      "\tHR@20=0.57587  MRR@20=0.25600  NDCG@20=0.32768\n",
      "[2020-03-02 15:28:59] [12/50] 0 mean_batch_loss : 5.159656\n",
      "Start predicting 2020-03-02 15:29:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change best\n",
      "testing finish [2020-03-02 15:29:16] \n",
      "\tHR@1=0.16312  MRR@1=0.16312  NDCG@1=0.16312\n",
      "\tHR@5=0.36439  MRR@5=0.23586  NDCG@5=0.26778\n",
      "\tHR@10=0.47009  MRR@10=0.24998  NDCG@10=0.30197\n",
      "\tHR@20=0.58070  MRR@20=0.25768  NDCG@20=0.32996\n",
      "[2020-03-02 15:29:16] [13/50] 0 mean_batch_loss : 4.769242\n",
      "Start predicting 2020-03-02 15:29:30\n",
      "change best\n",
      "testing finish [2020-03-02 15:29:33] \n",
      "\tHR@1=0.16511  MRR@1=0.16511  NDCG@1=0.16511\n",
      "\tHR@5=0.37415  MRR@5=0.24131  NDCG@5=0.27434\n",
      "\tHR@10=0.47926  MRR@10=0.25533  NDCG@10=0.30831\n",
      "\tHR@20=0.58746  MRR@20=0.26285  NDCG@20=0.33569\n",
      "[2020-03-02 15:29:33] [14/50] 0 mean_batch_loss : 4.924292\n",
      "Start predicting 2020-03-02 15:29:47\n",
      "change best\n",
      "testing finish [2020-03-02 15:29:50] \n",
      "\tHR@1=0.16373  MRR@1=0.16373  NDCG@1=0.16373\n",
      "\tHR@5=0.37736  MRR@5=0.24136  NDCG@5=0.27516\n",
      "\tHR@10=0.48513  MRR@10=0.25576  NDCG@10=0.31003\n",
      "\tHR@20=0.59471  MRR@20=0.26342  NDCG@20=0.33781\n",
      "[2020-03-02 15:29:50] [15/50] 0 mean_batch_loss : 4.821004\n",
      "Start predicting 2020-03-02 15:30:05\n",
      "change best\n",
      "testing finish [2020-03-02 15:30:08] \n",
      "\tHR@1=0.16622  MRR@1=0.16622  NDCG@1=0.16622\n",
      "\tHR@5=0.37982  MRR@5=0.24357  NDCG@5=0.27742\n",
      "\tHR@10=0.48922  MRR@10=0.25813  NDCG@10=0.31275\n",
      "\tHR@20=0.59778  MRR@20=0.26567  NDCG@20=0.34021\n",
      "[2020-03-02 15:30:08] [16/50] 0 mean_batch_loss : 4.373092\n",
      "Start predicting 2020-03-02 15:30:22\n",
      "change best\n",
      "testing finish [2020-03-02 15:30:25] \n",
      "\tHR@1=0.16615  MRR@1=0.16615  NDCG@1=0.16615\n",
      "\tHR@5=0.38431  MRR@5=0.24541  NDCG@5=0.27994\n",
      "\tHR@10=0.49089  MRR@10=0.25966  NDCG@10=0.31442\n",
      "\tHR@20=0.60281  MRR@20=0.26744  NDCG@20=0.34274\n",
      "[2020-03-02 15:30:25] [17/50] 0 mean_batch_loss : 4.658405\n",
      "Start predicting 2020-03-02 15:30:39\n",
      "change best\n",
      "testing finish [2020-03-02 15:30:42] \n",
      "\tHR@1=0.16730  MRR@1=0.16730  NDCG@1=0.16730\n",
      "\tHR@5=0.38779  MRR@5=0.24708  NDCG@5=0.28203\n",
      "\tHR@10=0.49617  MRR@10=0.26157  NDCG@10=0.31710\n",
      "\tHR@20=0.60620  MRR@20=0.26924  NDCG@20=0.34496\n",
      "[2020-03-02 15:30:42] [18/50] 0 mean_batch_loss : 4.655342\n",
      "Start predicting 2020-03-02 15:30:56\n",
      "change best\n",
      "testing finish [2020-03-02 15:31:00] \n",
      "\tHR@1=0.16631  MRR@1=0.16631  NDCG@1=0.16631\n",
      "\tHR@5=0.39170  MRR@5=0.24848  NDCG@5=0.28408\n",
      "\tHR@10=0.50123  MRR@10=0.26308  NDCG@10=0.31948\n",
      "\tHR@20=0.61081  MRR@20=0.27069  NDCG@20=0.34720\n",
      "[2020-03-02 15:31:00] [19/50] 0 mean_batch_loss : 4.481138\n",
      "Start predicting 2020-03-02 15:31:14\n",
      "change best\n",
      "testing finish [2020-03-02 15:31:17] \n",
      "\tHR@1=0.17096  MRR@1=0.17096  NDCG@1=0.17096\n",
      "\tHR@5=0.39574  MRR@5=0.25308  NDCG@5=0.28856\n",
      "\tHR@10=0.50509  MRR@10=0.26764  NDCG@10=0.32389\n",
      "\tHR@20=0.61661  MRR@20=0.27541  NDCG@20=0.35213\n",
      "[2020-03-02 15:31:17] [20/50] 0 mean_batch_loss : 4.373135\n",
      "Start predicting 2020-03-02 15:31:31\n",
      "testing finish [2020-03-02 15:31:34] \n",
      "\tHR@1=0.16945  MRR@1=0.16945  NDCG@1=0.16945\n",
      "\tHR@5=0.39673  MRR@5=0.25263  NDCG@5=0.28848\n",
      "\tHR@10=0.50844  MRR@10=0.26758  NDCG@10=0.32464\n",
      "\tHR@20=0.61655  MRR@20=0.27510  NDCG@20=0.35199\n",
      "[2020-03-02 15:31:34] [21/50] 0 mean_batch_loss : 4.587617\n",
      "Start predicting 2020-03-02 15:31:48\n",
      "change best\n",
      "testing finish [2020-03-02 15:31:52] \n",
      "\tHR@1=0.17116  MRR@1=0.17116  NDCG@1=0.17116\n",
      "\tHR@5=0.39651  MRR@5=0.25294  NDCG@5=0.28861\n",
      "\tHR@10=0.50895  MRR@10=0.26796  NDCG@10=0.32499\n",
      "\tHR@20=0.62041  MRR@20=0.27574  NDCG@20=0.35322\n",
      "[2020-03-02 15:31:52] [22/50] 0 mean_batch_loss : 4.431741\n",
      "Start predicting 2020-03-02 15:32:06\n",
      "change best\n",
      "testing finish [2020-03-02 15:32:09] \n",
      "\tHR@1=0.17288  MRR@1=0.17288  NDCG@1=0.17288\n",
      "\tHR@5=0.40213  MRR@5=0.25642  NDCG@5=0.29265\n",
      "\tHR@10=0.51297  MRR@10=0.27124  NDCG@10=0.32851\n",
      "\tHR@20=0.62117  MRR@20=0.27876  NDCG@20=0.35589\n",
      "[2020-03-02 15:32:09] [23/50] 0 mean_batch_loss : 4.628142\n",
      "Start predicting 2020-03-02 15:32:23\n",
      "testing finish [2020-03-02 15:32:26] \n",
      "\tHR@1=0.17128  MRR@1=0.17128  NDCG@1=0.17128\n",
      "\tHR@5=0.40042  MRR@5=0.25430  NDCG@5=0.29060\n",
      "\tHR@10=0.51130  MRR@10=0.26915  NDCG@10=0.32651\n",
      "\tHR@20=0.62212  MRR@20=0.27688  NDCG@20=0.35458\n",
      "[2020-03-02 15:32:26] [24/50] 0 mean_batch_loss : 4.437957\n",
      "Start predicting 2020-03-02 15:32:40\n",
      "change best\n",
      "testing finish [2020-03-02 15:32:43] \n",
      "\tHR@1=0.17634  MRR@1=0.17634  NDCG@1=0.17634\n",
      "\tHR@5=0.40428  MRR@5=0.25935  NDCG@5=0.29538\n",
      "\tHR@10=0.51672  MRR@10=0.27446  NDCG@10=0.33184\n",
      "\tHR@20=0.62691  MRR@20=0.28213  NDCG@20=0.35972\n",
      "[2020-03-02 15:32:43] [25/50] 0 mean_batch_loss : 4.327904\n",
      "Start predicting 2020-03-02 15:32:58\n",
      "testing finish [2020-03-02 15:33:01] \n",
      "\tHR@1=0.17266  MRR@1=0.17266  NDCG@1=0.17266\n",
      "\tHR@5=0.40340  MRR@5=0.25643  NDCG@5=0.29294\n",
      "\tHR@10=0.51670  MRR@10=0.27160  NDCG@10=0.32963\n",
      "\tHR@20=0.62630  MRR@20=0.27926  NDCG@20=0.35741\n",
      "[2020-03-02 15:33:01] [26/50] 0 mean_batch_loss : 4.329884\n",
      "Start predicting 2020-03-02 15:33:15\n",
      "change best\n",
      "testing finish [2020-03-02 15:33:18] \n",
      "\tHR@1=0.17304  MRR@1=0.17304  NDCG@1=0.17304\n",
      "\tHR@5=0.40590  MRR@5=0.25717  NDCG@5=0.29411\n",
      "\tHR@10=0.51733  MRR@10=0.27203  NDCG@10=0.33013\n",
      "\tHR@20=0.62955  MRR@20=0.27984  NDCG@20=0.35853\n",
      "[2020-03-02 15:33:18] [27/50] 0 mean_batch_loss : 4.420129\n",
      "Start predicting 2020-03-02 15:33:33\n",
      "change best\n",
      "testing finish [2020-03-02 15:33:36] \n",
      "\tHR@1=0.17288  MRR@1=0.17288  NDCG@1=0.17288\n",
      "\tHR@5=0.40785  MRR@5=0.25791  NDCG@5=0.29515\n",
      "\tHR@10=0.51923  MRR@10=0.27278  NDCG@10=0.33118\n",
      "\tHR@20=0.62940  MRR@20=0.28044  NDCG@20=0.35905\n",
      "[2020-03-02 15:33:36] [28/50] 0 mean_batch_loss : 4.290617\n",
      "Start predicting 2020-03-02 15:33:50\n",
      "change best\n",
      "testing finish [2020-03-02 15:33:53] \n",
      "\tHR@1=0.17491  MRR@1=0.17491  NDCG@1=0.17491\n",
      "\tHR@5=0.40764  MRR@5=0.25960  NDCG@5=0.29640\n",
      "\tHR@10=0.51916  MRR@10=0.27458  NDCG@10=0.33255\n",
      "\tHR@20=0.63098  MRR@20=0.28240  NDCG@20=0.36089\n",
      "[2020-03-02 15:33:53] [29/50] 0 mean_batch_loss : 4.224634\n",
      "Start predicting 2020-03-02 15:34:07\n",
      "change best\n",
      "testing finish [2020-03-02 15:34:10] \n",
      "\tHR@1=0.17514  MRR@1=0.17514  NDCG@1=0.17514\n",
      "\tHR@5=0.40922  MRR@5=0.26010  NDCG@5=0.29715\n",
      "\tHR@10=0.52223  MRR@10=0.27519  NDCG@10=0.33370\n",
      "\tHR@20=0.63111  MRR@20=0.28275  NDCG@20=0.36124\n",
      "[2020-03-02 15:34:10] [30/50] 0 mean_batch_loss : 4.199739\n",
      "Start predicting 2020-03-02 15:34:25\n",
      "change best\n",
      "testing finish [2020-03-02 15:34:28] \n",
      "\tHR@1=0.17369  MRR@1=0.17369  NDCG@1=0.17369\n",
      "\tHR@5=0.40936  MRR@5=0.25923  NDCG@5=0.29652\n",
      "\tHR@10=0.52126  MRR@10=0.27419  NDCG@10=0.33274\n",
      "\tHR@20=0.63267  MRR@20=0.28194  NDCG@20=0.36093\n",
      "[2020-03-02 15:34:28] [31/50] 0 mean_batch_loss : 4.299394\n",
      "Start predicting 2020-03-02 15:34:42\n",
      "change best\n",
      "testing finish [2020-03-02 15:34:45] \n",
      "\tHR@1=0.17471  MRR@1=0.17471  NDCG@1=0.17471\n",
      "\tHR@5=0.41313  MRR@5=0.26166  NDCG@5=0.29931\n",
      "\tHR@10=0.52483  MRR@10=0.27660  NDCG@10=0.33547\n",
      "\tHR@20=0.63536  MRR@20=0.28428  NDCG@20=0.36343\n",
      "[2020-03-02 15:34:45] [32/50] 0 mean_batch_loss : 4.204110\n",
      "Start predicting 2020-03-02 15:34:59\n",
      "testing finish [2020-03-02 15:35:02] \n",
      "\tHR@1=0.17530  MRR@1=0.17530  NDCG@1=0.17530\n",
      "\tHR@5=0.41216  MRR@5=0.26156  NDCG@5=0.29899\n",
      "\tHR@10=0.52526  MRR@10=0.27669  NDCG@10=0.33560\n",
      "\tHR@20=0.63515  MRR@20=0.28434  NDCG@20=0.36342\n",
      "[2020-03-02 15:35:02] [33/50] 0 mean_batch_loss : 4.217166\n",
      "Start predicting 2020-03-02 15:35:16\n",
      "testing finish [2020-03-02 15:35:19] \n",
      "\tHR@1=0.17290  MRR@1=0.17290  NDCG@1=0.17290\n",
      "\tHR@5=0.41198  MRR@5=0.26035  NDCG@5=0.29807\n",
      "\tHR@10=0.52429  MRR@10=0.27544  NDCG@10=0.33449\n",
      "\tHR@20=0.63470  MRR@20=0.28317  NDCG@20=0.36248\n",
      "[2020-03-02 15:35:19] [34/50] 0 mean_batch_loss : 4.313716\n",
      "Start predicting 2020-03-02 15:35:33\n",
      "change best\n",
      "testing finish [2020-03-02 15:35:37] \n",
      "\tHR@1=0.17573  MRR@1=0.17573  NDCG@1=0.17573\n",
      "\tHR@5=0.41528  MRR@5=0.26324  NDCG@5=0.30105\n",
      "\tHR@10=0.52908  MRR@10=0.27844  NDCG@10=0.33786\n",
      "\tHR@20=0.63865  MRR@20=0.28608  NDCG@20=0.36562\n",
      "[2020-03-02 15:35:37] [35/50] 0 mean_batch_loss : 4.252968\n",
      "Start predicting 2020-03-02 15:35:51\n",
      "testing finish [2020-03-02 15:35:54] \n",
      "\tHR@1=0.17464  MRR@1=0.17464  NDCG@1=0.17464\n",
      "\tHR@5=0.41543  MRR@5=0.26223  NDCG@5=0.30031\n",
      "\tHR@10=0.52585  MRR@10=0.27699  NDCG@10=0.33604\n",
      "\tHR@20=0.63719  MRR@20=0.28473  NDCG@20=0.36420\n",
      "[2020-03-02 15:35:54] [36/50] 0 mean_batch_loss : 4.320321\n",
      "Start predicting 2020-03-02 15:36:08\n",
      "testing finish [2020-03-02 15:36:11] \n",
      "\tHR@1=0.17378  MRR@1=0.17378  NDCG@1=0.17378\n",
      "\tHR@5=0.41618  MRR@5=0.26206  NDCG@5=0.30037\n",
      "\tHR@10=0.52989  MRR@10=0.27725  NDCG@10=0.33715\n",
      "\tHR@20=0.63924  MRR@20=0.28487  NDCG@20=0.36484\n",
      "[2020-03-02 15:36:11] [37/50] 0 mean_batch_loss : 4.300678\n",
      "Start predicting 2020-03-02 15:36:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing finish [2020-03-02 15:36:29] \n",
      "\tHR@1=0.17198  MRR@1=0.17198  NDCG@1=0.17198\n",
      "\tHR@5=0.41485  MRR@5=0.26064  NDCG@5=0.29898\n",
      "\tHR@10=0.52788  MRR@10=0.27569  NDCG@10=0.33550\n",
      "\tHR@20=0.63678  MRR@20=0.28327  NDCG@20=0.36305\n",
      "[2020-03-02 15:36:29] [38/50] 0 mean_batch_loss : 4.159074\n",
      "Start predicting 2020-03-02 15:36:43\n",
      "change best\n",
      "testing finish [2020-03-02 15:36:47] \n",
      "\tHR@1=0.17315  MRR@1=0.17315  NDCG@1=0.17315\n",
      "\tHR@5=0.41699  MRR@5=0.26202  NDCG@5=0.30056\n",
      "\tHR@10=0.53057  MRR@10=0.27721  NDCG@10=0.33731\n",
      "\tHR@20=0.64089  MRR@20=0.28491  NDCG@20=0.36526\n",
      "[2020-03-02 15:36:47] [39/50] 0 mean_batch_loss : 4.154287\n",
      "Start predicting 2020-03-02 15:37:01\n",
      "change best\n",
      "testing finish [2020-03-02 15:37:04] \n",
      "\tHR@1=0.17354  MRR@1=0.17354  NDCG@1=0.17354\n",
      "\tHR@5=0.41819  MRR@5=0.26281  NDCG@5=0.30144\n",
      "\tHR@10=0.53289  MRR@10=0.27823  NDCG@10=0.33864\n",
      "\tHR@20=0.64225  MRR@20=0.28582  NDCG@20=0.36629\n",
      "[2020-03-02 15:37:04] [40/50] 0 mean_batch_loss : 4.058253\n",
      "Start predicting 2020-03-02 15:37:18\n",
      "testing finish [2020-03-02 15:37:21] \n",
      "\tHR@1=0.17351  MRR@1=0.17351  NDCG@1=0.17351\n",
      "\tHR@5=0.42097  MRR@5=0.26313  NDCG@5=0.30233\n",
      "\tHR@10=0.53217  MRR@10=0.27796  NDCG@10=0.33829\n",
      "\tHR@20=0.64046  MRR@20=0.28549  NDCG@20=0.36568\n",
      "[2020-03-02 15:37:21] [41/50] 0 mean_batch_loss : 3.943128\n",
      "Start predicting 2020-03-02 15:37:33\n",
      "change best\n",
      "testing finish [2020-03-02 15:37:37] \n",
      "\tHR@1=0.17288  MRR@1=0.17288  NDCG@1=0.17288\n",
      "\tHR@5=0.41857  MRR@5=0.26231  NDCG@5=0.30116\n",
      "\tHR@10=0.53319  MRR@10=0.27764  NDCG@10=0.33825\n",
      "\tHR@20=0.64281  MRR@20=0.28527  NDCG@20=0.36599\n",
      "[2020-03-02 15:37:37] [42/50] 0 mean_batch_loss : 3.967245\n",
      "Start predicting 2020-03-02 15:37:49\n",
      "testing finish [2020-03-02 15:37:52] \n",
      "\tHR@1=0.17209  MRR@1=0.17209  NDCG@1=0.17209\n",
      "\tHR@5=0.42004  MRR@5=0.26252  NDCG@5=0.30169\n",
      "\tHR@10=0.53246  MRR@10=0.27760  NDCG@10=0.33812\n",
      "\tHR@20=0.64258  MRR@20=0.28530  NDCG@20=0.36603\n",
      "[2020-03-02 15:37:52] [43/50] 0 mean_batch_loss : 4.088388\n",
      "Start predicting 2020-03-02 15:38:06\n",
      "testing finish [2020-03-02 15:38:10] \n",
      "\tHR@1=0.17354  MRR@1=0.17354  NDCG@1=0.17354\n",
      "\tHR@5=0.41848  MRR@5=0.26256  NDCG@5=0.30131\n",
      "\tHR@10=0.53122  MRR@10=0.27768  NDCG@10=0.33784\n",
      "\tHR@20=0.64211  MRR@20=0.28539  NDCG@20=0.36589\n",
      "[2020-03-02 15:38:10] [44/50] 0 mean_batch_loss : 3.978843\n",
      "Start predicting 2020-03-02 15:38:24\n",
      "change best\n",
      "testing finish [2020-03-02 15:38:28] \n",
      "\tHR@1=0.17372  MRR@1=0.17372  NDCG@1=0.17372\n",
      "\tHR@5=0.41871  MRR@5=0.26332  NDCG@5=0.30196\n",
      "\tHR@10=0.53190  MRR@10=0.27848  NDCG@10=0.33862\n",
      "\tHR@20=0.64426  MRR@20=0.28632  NDCG@20=0.36709\n",
      "[2020-03-02 15:38:28] [45/50] 0 mean_batch_loss : 3.964081\n",
      "Start predicting 2020-03-02 15:38:42\n",
      "testing finish [2020-03-02 15:38:45] \n",
      "\tHR@1=0.17263  MRR@1=0.17263  NDCG@1=0.17263\n",
      "\tHR@5=0.42232  MRR@5=0.26332  NDCG@5=0.30284\n",
      "\tHR@10=0.53330  MRR@10=0.27816  NDCG@10=0.33875\n",
      "\tHR@20=0.64356  MRR@20=0.28587  NDCG@20=0.36670\n",
      "[2020-03-02 15:38:45] [46/50] 0 mean_batch_loss : 4.297004\n",
      "Start predicting 2020-03-02 15:38:59\n",
      "testing finish [2020-03-02 15:39:03] \n",
      "\tHR@1=0.17069  MRR@1=0.17069  NDCG@1=0.17069\n",
      "\tHR@5=0.42033  MRR@5=0.26185  NDCG@5=0.30125\n",
      "\tHR@10=0.53479  MRR@10=0.27717  NDCG@10=0.33832\n",
      "\tHR@20=0.64426  MRR@20=0.28480  NDCG@20=0.36603\n",
      "[2020-03-02 15:39:03] [47/50] 0 mean_batch_loss : 4.151927\n",
      "Start predicting 2020-03-02 15:39:17\n",
      "testing finish [2020-03-02 15:39:20] \n",
      "\tHR@1=0.17155  MRR@1=0.17155  NDCG@1=0.17155\n",
      "\tHR@5=0.41860  MRR@5=0.26129  NDCG@5=0.30038\n",
      "\tHR@10=0.53255  MRR@10=0.27649  NDCG@10=0.33722\n",
      "\tHR@20=0.64340  MRR@20=0.28420  NDCG@20=0.36527\n",
      "[2020-03-02 15:39:20] [48/50] 0 mean_batch_loss : 4.119339\n",
      "Start predicting 2020-03-02 15:39:35\n",
      "testing finish [2020-03-02 15:39:38] \n",
      "\tHR@1=0.17322  MRR@1=0.17322  NDCG@1=0.17322\n",
      "\tHR@5=0.41950  MRR@5=0.26284  NDCG@5=0.30178\n",
      "\tHR@10=0.53504  MRR@10=0.27828  NDCG@10=0.33916\n",
      "\tHR@20=0.64428  MRR@20=0.28590  NDCG@20=0.36683\n",
      "[2020-03-02 15:39:38] [49/50] 0 mean_batch_loss : 3.880431\n",
      "Start predicting 2020-03-02 15:39:53\n",
      "testing finish [2020-03-02 15:39:56] \n",
      "\tHR@1=0.17189  MRR@1=0.17189  NDCG@1=0.17189\n",
      "\tHR@5=0.41988  MRR@5=0.26247  NDCG@5=0.30162\n",
      "\tHR@10=0.53560  MRR@10=0.27794  NDCG@10=0.33906\n",
      "\tHR@20=0.64484  MRR@20=0.28557  NDCG@20=0.36674\n",
      "early stopping\n",
      "training and testting over, Total time 0:14:08.140774\n",
      "best model change\n",
      "current model hyper-parameters: session_length=20, hidden_size=50, lr=0.0030, embedding_dim=50, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "current model HR@20=0.64426  MRR@20=0.28632\n",
      "the best result so far. HR@20=0.64426  MRR@20=0.28632, current model hyper-parameters: session_length=20, hidden_size=50, lr=0.0030, embedding_dim=50, embedding_dropout=0.25, dropout=0.50\n",
      " \n",
      "\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0030, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "[2020-03-02 15:39:56] [1/50] 0 mean_batch_loss : 20.364264\n",
      "Start predicting 2020-03-02 15:40:14\n",
      "change best\n",
      "testing finish [2020-03-02 15:40:17] \n",
      "\tHR@1=0.20963  MRR@1=0.20963  NDCG@1=0.20963\n",
      "\tHR@5=0.23104  MRR@5=0.21755  NDCG@5=0.22091\n",
      "\tHR@10=0.23980  MRR@10=0.21874  NDCG@10=0.22376\n",
      "\tHR@20=0.25116  MRR@20=0.21952  NDCG@20=0.22662\n",
      "[2020-03-02 15:40:18] [2/50] 0 mean_batch_loss : 9.188643\n",
      "Start predicting 2020-03-02 15:40:35\n",
      "change best\n",
      "testing finish [2020-03-02 15:40:38] \n",
      "\tHR@1=0.19014  MRR@1=0.19014  NDCG@1=0.19014\n",
      "\tHR@5=0.25841  MRR@5=0.21515  NDCG@5=0.22591\n",
      "\tHR@10=0.29011  MRR@10=0.21940  NDCG@10=0.23619\n",
      "\tHR@20=0.32130  MRR@20=0.22158  NDCG@20=0.24408\n",
      "[2020-03-02 15:40:39] [3/50] 0 mean_batch_loss : 8.017248\n",
      "Start predicting 2020-03-02 15:40:56\n",
      "change best\n",
      "testing finish [2020-03-02 15:41:00] \n",
      "\tHR@1=0.17464  MRR@1=0.17464  NDCG@1=0.17464\n",
      "\tHR@5=0.28797  MRR@5=0.21600  NDCG@5=0.23389\n",
      "\tHR@10=0.34355  MRR@10=0.22339  NDCG@10=0.25184\n",
      "\tHR@20=0.40060  MRR@20=0.22737  NDCG@20=0.26629\n",
      "[2020-03-02 15:41:00] [4/50] 0 mean_batch_loss : 7.250297\n",
      "Start predicting 2020-03-02 15:41:17\n",
      "change best\n",
      "testing finish [2020-03-02 15:41:21] \n",
      "\tHR@1=0.17055  MRR@1=0.17055  NDCG@1=0.17055\n",
      "\tHR@5=0.31862  MRR@5=0.22461  NDCG@5=0.24799\n",
      "\tHR@10=0.39086  MRR@10=0.23420  NDCG@10=0.27130\n",
      "\tHR@20=0.46785  MRR@20=0.23950  NDCG@20=0.29072\n",
      "[2020-03-02 15:41:21] [5/50] 0 mean_batch_loss : 5.936842\n",
      "Start predicting 2020-03-02 15:41:39\n",
      "change best\n",
      "testing finish [2020-03-02 15:41:42] \n",
      "\tHR@1=0.16940  MRR@1=0.16940  NDCG@1=0.16940\n",
      "\tHR@5=0.33709  MRR@5=0.23018  NDCG@5=0.25674\n",
      "\tHR@10=0.42433  MRR@10=0.24185  NDCG@10=0.28498\n",
      "\tHR@20=0.51566  MRR@20=0.24821  NDCG@20=0.30809\n",
      "[2020-03-02 15:41:42] [6/50] 0 mean_batch_loss : 5.609313\n",
      "Start predicting 2020-03-02 15:42:00\n",
      "change best\n",
      "testing finish [2020-03-02 15:42:03] \n",
      "\tHR@1=0.17150  MRR@1=0.17150  NDCG@1=0.17150\n",
      "\tHR@5=0.35685  MRR@5=0.23901  NDCG@5=0.26830\n",
      "\tHR@10=0.45010  MRR@10=0.25142  NDCG@10=0.29842\n",
      "\tHR@20=0.54590  MRR@20=0.25809  NDCG@20=0.32267\n",
      "[2020-03-02 15:42:03] [7/50] 0 mean_batch_loss : 5.040868\n",
      "Start predicting 2020-03-02 15:42:21\n",
      "change best\n",
      "testing finish [2020-03-02 15:42:25] \n",
      "\tHR@1=0.17295  MRR@1=0.17295  NDCG@1=0.17295\n",
      "\tHR@5=0.36733  MRR@5=0.24365  NDCG@5=0.27439\n",
      "\tHR@10=0.46458  MRR@10=0.25663  NDCG@10=0.30583\n",
      "\tHR@20=0.56675  MRR@20=0.26371  NDCG@20=0.33166\n",
      "[2020-03-02 15:42:25] [8/50] 0 mean_batch_loss : 5.013662\n",
      "Start predicting 2020-03-02 15:42:43\n",
      "change best\n",
      "testing finish [2020-03-02 15:42:47] \n",
      "\tHR@1=0.17794  MRR@1=0.17794  NDCG@1=0.17794\n",
      "\tHR@5=0.37867  MRR@5=0.25098  NDCG@5=0.28272\n",
      "\tHR@10=0.47939  MRR@10=0.26442  NDCG@10=0.31529\n",
      "\tHR@20=0.58364  MRR@20=0.27162  NDCG@20=0.34161\n",
      "[2020-03-02 15:42:47] [9/50] 0 mean_batch_loss : 4.481553\n",
      "Start predicting 2020-03-02 15:43:06\n",
      "change best\n",
      "testing finish [2020-03-02 15:43:09] \n",
      "\tHR@1=0.17297  MRR@1=0.17297  NDCG@1=0.17297\n",
      "\tHR@5=0.38063  MRR@5=0.24892  NDCG@5=0.28167\n",
      "\tHR@10=0.48499  MRR@10=0.26292  NDCG@10=0.31549\n",
      "\tHR@20=0.59168  MRR@20=0.27033  NDCG@20=0.34248\n",
      "[2020-03-02 15:43:10] [10/50] 0 mean_batch_loss : 4.401372\n",
      "Start predicting 2020-03-02 15:43:28\n",
      "change best\n",
      "testing finish [2020-03-02 15:43:32] \n",
      "\tHR@1=0.17740  MRR@1=0.17740  NDCG@1=0.17740\n",
      "\tHR@5=0.39242  MRR@5=0.25594  NDCG@5=0.28988\n",
      "\tHR@10=0.49744  MRR@10=0.26990  NDCG@10=0.32378\n",
      "\tHR@20=0.60528  MRR@20=0.27740  NDCG@20=0.35106\n",
      "[2020-03-02 15:43:32] [11/50] 0 mean_batch_loss : 4.594790\n",
      "Start predicting 2020-03-02 15:43:50\n",
      "change best\n",
      "testing finish [2020-03-02 15:43:54] \n",
      "\tHR@1=0.17670  MRR@1=0.17670  NDCG@1=0.17670\n",
      "\tHR@5=0.39816  MRR@5=0.25741  NDCG@5=0.29239\n",
      "\tHR@10=0.50195  MRR@10=0.27126  NDCG@10=0.32596\n",
      "\tHR@20=0.60972  MRR@20=0.27877  NDCG@20=0.35324\n",
      "[2020-03-02 15:43:54] [12/50] 0 mean_batch_loss : 4.243264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2020-03-02 15:44:13\n",
      "change best\n",
      "testing finish [2020-03-02 15:44:16] \n",
      "\tHR@1=0.17855  MRR@1=0.17855  NDCG@1=0.17855\n",
      "\tHR@5=0.40078  MRR@5=0.25993  NDCG@5=0.29496\n",
      "\tHR@10=0.50688  MRR@10=0.27411  NDCG@10=0.32929\n",
      "\tHR@20=0.61472  MRR@20=0.28159  NDCG@20=0.35655\n",
      "[2020-03-02 15:44:16] [13/50] 0 mean_batch_loss : 4.254182\n",
      "Start predicting 2020-03-02 15:44:34\n",
      "change best\n",
      "testing finish [2020-03-02 15:44:38] \n",
      "\tHR@1=0.17864  MRR@1=0.17864  NDCG@1=0.17864\n",
      "\tHR@5=0.40642  MRR@5=0.26244  NDCG@5=0.29827\n",
      "\tHR@10=0.51345  MRR@10=0.27672  NDCG@10=0.33288\n",
      "\tHR@20=0.62036  MRR@20=0.28420  NDCG@20=0.35998\n",
      "[2020-03-02 15:44:38] [14/50] 0 mean_batch_loss : 3.933518\n",
      "Start predicting 2020-03-02 15:44:56\n",
      "change best\n",
      "testing finish [2020-03-02 15:44:59] \n",
      "\tHR@1=0.17776  MRR@1=0.17776  NDCG@1=0.17776\n",
      "\tHR@5=0.40929  MRR@5=0.26238  NDCG@5=0.29892\n",
      "\tHR@10=0.51557  MRR@10=0.27659  NDCG@10=0.33331\n",
      "\tHR@20=0.62224  MRR@20=0.28398  NDCG@20=0.36027\n",
      "[2020-03-02 15:44:59] [15/50] 0 mean_batch_loss : 3.877083\n",
      "Start predicting 2020-03-02 15:45:18\n",
      "change best\n",
      "testing finish [2020-03-02 15:45:22] \n",
      "\tHR@1=0.17891  MRR@1=0.17891  NDCG@1=0.17891\n",
      "\tHR@5=0.41155  MRR@5=0.26399  NDCG@5=0.30069\n",
      "\tHR@10=0.51950  MRR@10=0.27844  NDCG@10=0.33563\n",
      "\tHR@20=0.62906  MRR@20=0.28604  NDCG@20=0.36333\n",
      "[2020-03-02 15:45:22] [16/50] 0 mean_batch_loss : 4.176277\n",
      "Start predicting 2020-03-02 15:45:40\n",
      "change best\n",
      "testing finish [2020-03-02 15:45:44] \n",
      "\tHR@1=0.17945  MRR@1=0.17945  NDCG@1=0.17945\n",
      "\tHR@5=0.41358  MRR@5=0.26513  NDCG@5=0.30205\n",
      "\tHR@10=0.52239  MRR@10=0.27966  NDCG@10=0.33725\n",
      "\tHR@20=0.63055  MRR@20=0.28718  NDCG@20=0.36461\n",
      "[2020-03-02 15:45:44] [17/50] 0 mean_batch_loss : 4.044951\n",
      "Start predicting 2020-03-02 15:46:02\n",
      "change best\n",
      "testing finish [2020-03-02 15:46:06] \n",
      "\tHR@1=0.18130  MRR@1=0.18130  NDCG@1=0.18130\n",
      "\tHR@5=0.41625  MRR@5=0.26759  NDCG@5=0.30457\n",
      "\tHR@10=0.52582  MRR@10=0.28224  NDCG@10=0.34004\n",
      "\tHR@20=0.63251  MRR@20=0.28967  NDCG@20=0.36705\n",
      "[2020-03-02 15:46:06] [18/50] 0 mean_batch_loss : 3.894746\n",
      "Start predicting 2020-03-02 15:46:25\n",
      "change best\n",
      "testing finish [2020-03-02 15:46:28] \n",
      "\tHR@1=0.17990  MRR@1=0.17990  NDCG@1=0.17990\n",
      "\tHR@5=0.42043  MRR@5=0.26795  NDCG@5=0.30588\n",
      "\tHR@10=0.52912  MRR@10=0.28244  NDCG@10=0.34101\n",
      "\tHR@20=0.63608  MRR@20=0.28989  NDCG@20=0.36809\n",
      "[2020-03-02 15:46:28] [19/50] 0 mean_batch_loss : 4.134864\n",
      "Start predicting 2020-03-02 15:46:47\n",
      "change best\n",
      "testing finish [2020-03-02 15:46:50] \n",
      "\tHR@1=0.17984  MRR@1=0.17984  NDCG@1=0.17984\n",
      "\tHR@5=0.42128  MRR@5=0.26851  NDCG@5=0.30653\n",
      "\tHR@10=0.53054  MRR@10=0.28304  NDCG@10=0.34182\n",
      "\tHR@20=0.63859  MRR@20=0.29057  NDCG@20=0.36918\n",
      "[2020-03-02 15:46:50] [20/50] 0 mean_batch_loss : 3.879091\n",
      "Start predicting 2020-03-02 15:47:09\n",
      "change best\n",
      "testing finish [2020-03-02 15:47:12] \n",
      "\tHR@1=0.17984  MRR@1=0.17984  NDCG@1=0.17984\n",
      "\tHR@5=0.42255  MRR@5=0.26860  NDCG@5=0.30689\n",
      "\tHR@10=0.53292  MRR@10=0.28340  NDCG@10=0.34266\n",
      "\tHR@20=0.64071  MRR@20=0.29090  NDCG@20=0.36994\n",
      "[2020-03-02 15:47:12] [21/50] 0 mean_batch_loss : 3.826732\n",
      "Start predicting 2020-03-02 15:47:31\n",
      "change best\n",
      "testing finish [2020-03-02 15:47:34] \n",
      "\tHR@1=0.18038  MRR@1=0.18038  NDCG@1=0.18038\n",
      "\tHR@5=0.42460  MRR@5=0.27022  NDCG@5=0.30864\n",
      "\tHR@10=0.53531  MRR@10=0.28501  NDCG@10=0.34445\n",
      "\tHR@20=0.64015  MRR@20=0.29228  NDCG@20=0.37096\n",
      "[2020-03-02 15:47:34] [22/50] 0 mean_batch_loss : 3.914074\n",
      "Start predicting 2020-03-02 15:47:52\n",
      "testing finish [2020-03-02 15:47:56] \n",
      "\tHR@1=0.17932  MRR@1=0.17932  NDCG@1=0.17932\n",
      "\tHR@5=0.42241  MRR@5=0.26902  NDCG@5=0.30722\n",
      "\tHR@10=0.53262  MRR@10=0.28380  NDCG@10=0.34293\n",
      "\tHR@20=0.64094  MRR@20=0.29130  NDCG@20=0.37030\n",
      "[2020-03-02 15:47:56] [23/50] 0 mean_batch_loss : 3.860014\n",
      "Start predicting 2020-03-02 15:48:14\n",
      "testing finish [2020-03-02 15:48:18] \n",
      "\tHR@1=0.17604  MRR@1=0.17604  NDCG@1=0.17604\n",
      "\tHR@5=0.42528  MRR@5=0.26743  NDCG@5=0.30670\n",
      "\tHR@10=0.53676  MRR@10=0.28230  NDCG@10=0.34274\n",
      "\tHR@20=0.64270  MRR@20=0.28969  NDCG@20=0.36958\n",
      "[2020-03-02 15:48:18] [24/50] 0 mean_batch_loss : 3.901795\n",
      "Start predicting 2020-03-02 15:48:36\n",
      "change best\n",
      "testing finish [2020-03-02 15:48:39] \n",
      "\tHR@1=0.17627  MRR@1=0.17627  NDCG@1=0.17627\n",
      "\tHR@5=0.42546  MRR@5=0.26765  NDCG@5=0.30692\n",
      "\tHR@10=0.53529  MRR@10=0.28233  NDCG@10=0.34246\n",
      "\tHR@20=0.64378  MRR@20=0.28991  NDCG@20=0.36995\n",
      "[2020-03-02 15:48:40] [25/50] 0 mean_batch_loss : 3.665439\n",
      "Start predicting 2020-03-02 15:48:59\n",
      "change best\n",
      "testing finish [2020-03-02 15:49:02] \n",
      "\tHR@1=0.17810  MRR@1=0.17810  NDCG@1=0.17810\n",
      "\tHR@5=0.42948  MRR@5=0.27027  NDCG@5=0.30988\n",
      "\tHR@10=0.53788  MRR@10=0.28485  NDCG@10=0.34504\n",
      "\tHR@20=0.64464  MRR@20=0.29229  NDCG@20=0.37208\n",
      "[2020-03-02 15:49:02] [26/50] 0 mean_batch_loss : 3.694210\n",
      "Start predicting 2020-03-02 15:49:21\n",
      "testing finish [2020-03-02 15:49:24] \n",
      "\tHR@1=0.17817  MRR@1=0.17817  NDCG@1=0.17817\n",
      "\tHR@5=0.42682  MRR@5=0.26886  NDCG@5=0.30813\n",
      "\tHR@10=0.53739  MRR@10=0.28368  NDCG@10=0.34395\n",
      "\tHR@20=0.64545  MRR@20=0.29122  NDCG@20=0.37132\n",
      "[2020-03-02 15:49:24] [27/50] 0 mean_batch_loss : 3.882931\n",
      "Start predicting 2020-03-02 15:49:43\n",
      "testing finish [2020-03-02 15:49:46] \n",
      "\tHR@1=0.17769  MRR@1=0.17769  NDCG@1=0.17769\n",
      "\tHR@5=0.42691  MRR@5=0.26891  NDCG@5=0.30822\n",
      "\tHR@10=0.53874  MRR@10=0.28390  NDCG@10=0.34444\n",
      "\tHR@20=0.64405  MRR@20=0.29128  NDCG@20=0.37116\n",
      "[2020-03-02 15:49:46] [28/50] 0 mean_batch_loss : 3.688664\n",
      "Start predicting 2020-03-02 15:50:05\n",
      "change best\n",
      "testing finish [2020-03-02 15:50:08] \n",
      "\tHR@1=0.17733  MRR@1=0.17733  NDCG@1=0.17733\n",
      "\tHR@5=0.42822  MRR@5=0.26901  NDCG@5=0.30860\n",
      "\tHR@10=0.53928  MRR@10=0.28387  NDCG@10=0.34455\n",
      "\tHR@20=0.64674  MRR@20=0.29136  NDCG@20=0.37176\n",
      "[2020-03-02 15:50:08] [29/50] 0 mean_batch_loss : 3.647087\n",
      "Start predicting 2020-03-02 15:50:27\n",
      "testing finish [2020-03-02 15:50:30] \n",
      "\tHR@1=0.17663  MRR@1=0.17663  NDCG@1=0.17663\n",
      "\tHR@5=0.42788  MRR@5=0.26866  NDCG@5=0.30828\n",
      "\tHR@10=0.54053  MRR@10=0.28374  NDCG@10=0.34475\n",
      "\tHR@20=0.64511  MRR@20=0.29106  NDCG@20=0.37127\n",
      "[2020-03-02 15:50:30] [30/50] 0 mean_batch_loss : 3.461230\n",
      "Start predicting 2020-03-02 15:50:49\n",
      "testing finish [2020-03-02 15:50:53] \n",
      "\tHR@1=0.17654  MRR@1=0.17654  NDCG@1=0.17654\n",
      "\tHR@5=0.42795  MRR@5=0.26818  NDCG@5=0.30790\n",
      "\tHR@10=0.53985  MRR@10=0.28318  NDCG@10=0.34415\n",
      "\tHR@20=0.64613  MRR@20=0.29062  NDCG@20=0.37110\n",
      "[2020-03-02 15:50:53] [31/50] 0 mean_batch_loss : 3.511596\n",
      "Start predicting 2020-03-02 15:51:12\n",
      "testing finish [2020-03-02 15:51:15] \n",
      "\tHR@1=0.17360  MRR@1=0.17360  NDCG@1=0.17360\n",
      "\tHR@5=0.42887  MRR@5=0.26689  NDCG@5=0.30718\n",
      "\tHR@10=0.53976  MRR@10=0.28173  NDCG@10=0.34308\n",
      "\tHR@20=0.64789  MRR@20=0.28930  NDCG@20=0.37050\n",
      "[2020-03-02 15:51:15] [32/50] 0 mean_batch_loss : 3.574579\n",
      "Start predicting 2020-03-02 15:51:34\n",
      "testing finish [2020-03-02 15:51:37] \n",
      "\tHR@1=0.17369  MRR@1=0.17369  NDCG@1=0.17369\n",
      "\tHR@5=0.42903  MRR@5=0.26767  NDCG@5=0.30784\n",
      "\tHR@10=0.53992  MRR@10=0.28254  NDCG@10=0.34377\n",
      "\tHR@20=0.64618  MRR@20=0.28994  NDCG@20=0.37068\n",
      "[2020-03-02 15:51:37] [33/50] 0 mean_batch_loss : 3.439962\n",
      "Start predicting 2020-03-02 15:51:56\n",
      "testing finish [2020-03-02 15:51:59] \n",
      "\tHR@1=0.17372  MRR@1=0.17372  NDCG@1=0.17372\n",
      "\tHR@5=0.42537  MRR@5=0.26582  NDCG@5=0.30551\n",
      "\tHR@10=0.53782  MRR@10=0.28093  NDCG@10=0.34198\n",
      "\tHR@20=0.64669  MRR@20=0.28855  NDCG@20=0.36959\n",
      "early stopping\n",
      "training and testting over, Total time 0:12:03.196260\n",
      "best model change\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0030, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "current model HR@20=0.64674  MRR@20=0.29136\n",
      "the best result so far. HR@20=0.64674  MRR@20=0.29136, current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0030, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      " \n",
      "\n",
      "current model hyper-parameters: session_length=20, hidden_size=200, lr=0.0030, embedding_dim=200, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "[2020-03-02 15:52:00] [1/50] 0 mean_batch_loss : 17.867598\n",
      "Start predicting 2020-03-02 15:52:50\n",
      "change best\n",
      "testing finish [2020-03-02 15:52:56] \n",
      "\tHR@1=0.18219  MRR@1=0.18219  NDCG@1=0.18219\n",
      "\tHR@5=0.23246  MRR@5=0.20159  NDCG@5=0.20932\n",
      "\tHR@10=0.25062  MRR@10=0.20401  NDCG@10=0.21518\n",
      "\tHR@20=0.26977  MRR@20=0.20532  NDCG@20=0.22001\n",
      "[2020-03-02 15:52:57] [2/50] 0 mean_batch_loss : 8.998050\n",
      "Start predicting 2020-03-02 15:53:48\n",
      "change best\n",
      "testing finish [2020-03-02 15:53:54] \n",
      "\tHR@1=0.17324  MRR@1=0.17324  NDCG@1=0.17324\n",
      "\tHR@5=0.27196  MRR@5=0.20943  NDCG@5=0.22499\n",
      "\tHR@10=0.31667  MRR@10=0.21539  NDCG@10=0.23944\n",
      "\tHR@20=0.36209  MRR@20=0.21854  NDCG@20=0.25093\n",
      "[2020-03-02 15:53:54] [3/50] 0 mean_batch_loss : 7.805904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2020-03-02 15:54:44\n",
      "change best\n",
      "testing finish [2020-03-02 15:54:50] \n",
      "\tHR@1=0.16683  MRR@1=0.16683  NDCG@1=0.16683\n",
      "\tHR@5=0.30895  MRR@5=0.21846  NDCG@5=0.24095\n",
      "\tHR@10=0.37950  MRR@10=0.22778  NDCG@10=0.26367\n",
      "\tHR@20=0.45107  MRR@20=0.23277  NDCG@20=0.28178\n",
      "[2020-03-02 15:54:51] [4/50] 0 mean_batch_loss : 6.158460\n",
      "Start predicting 2020-03-02 15:55:42\n",
      "change best\n",
      "testing finish [2020-03-02 15:55:48] \n",
      "\tHR@1=0.16459  MRR@1=0.16459  NDCG@1=0.16459\n",
      "\tHR@5=0.33747  MRR@5=0.22758  NDCG@5=0.25490\n",
      "\tHR@10=0.42431  MRR@10=0.23915  NDCG@10=0.28296\n",
      "\tHR@20=0.51286  MRR@20=0.24528  NDCG@20=0.30533\n",
      "[2020-03-02 15:55:48] [5/50] 0 mean_batch_loss : 5.391572\n",
      "Start predicting 2020-03-02 15:56:40\n",
      "change best\n",
      "testing finish [2020-03-02 15:56:45] \n",
      "\tHR@1=0.15816  MRR@1=0.15816  NDCG@1=0.15816\n",
      "\tHR@5=0.35008  MRR@5=0.22777  NDCG@5=0.25815\n",
      "\tHR@10=0.44622  MRR@10=0.24053  NDCG@10=0.28917\n",
      "\tHR@20=0.54617  MRR@20=0.24749  NDCG@20=0.31448\n",
      "[2020-03-02 15:56:45] [6/50] 0 mean_batch_loss : 4.874934\n",
      "Start predicting 2020-03-02 15:57:35\n",
      "change best\n",
      "testing finish [2020-03-02 15:57:40] \n",
      "\tHR@1=0.16464  MRR@1=0.16464  NDCG@1=0.16464\n",
      "\tHR@5=0.36957  MRR@5=0.23925  NDCG@5=0.27164\n",
      "\tHR@10=0.46891  MRR@10=0.25255  NDCG@10=0.30381\n",
      "\tHR@20=0.57393  MRR@20=0.25985  NDCG@20=0.33038\n",
      "[2020-03-02 15:57:40] [7/50] 0 mean_batch_loss : 4.440334\n",
      "Start predicting 2020-03-02 15:58:28\n",
      "change best\n",
      "testing finish [2020-03-02 15:58:34] \n",
      "\tHR@1=0.16251  MRR@1=0.16251  NDCG@1=0.16251\n",
      "\tHR@5=0.37889  MRR@5=0.24166  NDCG@5=0.27579\n",
      "\tHR@10=0.48395  MRR@10=0.25571  NDCG@10=0.30980\n",
      "\tHR@20=0.59193  MRR@20=0.26320  NDCG@20=0.33709\n",
      "[2020-03-02 15:58:34] [8/50] 0 mean_batch_loss : 4.451871\n",
      "Start predicting 2020-03-02 15:59:25\n",
      "change best\n",
      "testing finish [2020-03-02 15:59:31] \n",
      "\tHR@1=0.16683  MRR@1=0.16683  NDCG@1=0.16683\n",
      "\tHR@5=0.38958  MRR@5=0.24786  NDCG@5=0.28309\n",
      "\tHR@10=0.49493  MRR@10=0.26196  NDCG@10=0.31720\n",
      "\tHR@20=0.60320  MRR@20=0.26953  NDCG@20=0.34464\n",
      "[2020-03-02 15:59:31] [9/50] 0 mean_batch_loss : 4.280958\n",
      "Start predicting 2020-03-02 16:00:23\n",
      "change best\n",
      "testing finish [2020-03-02 16:00:29] \n",
      "\tHR@1=0.17270  MRR@1=0.17270  NDCG@1=0.17270\n",
      "\tHR@5=0.39800  MRR@5=0.25474  NDCG@5=0.29034\n",
      "\tHR@10=0.50724  MRR@10=0.26931  NDCG@10=0.32566\n",
      "\tHR@20=0.61386  MRR@20=0.27675  NDCG@20=0.35267\n",
      "[2020-03-02 16:00:29] [10/50] 0 mean_batch_loss : 4.197788\n",
      "Start predicting 2020-03-02 16:01:20\n",
      "change best\n",
      "testing finish [2020-03-02 16:01:27] \n",
      "\tHR@1=0.17173  MRR@1=0.17173  NDCG@1=0.17173\n",
      "\tHR@5=0.40495  MRR@5=0.25606  NDCG@5=0.29303\n",
      "\tHR@10=0.51392  MRR@10=0.27065  NDCG@10=0.32833\n",
      "\tHR@20=0.62142  MRR@20=0.27812  NDCG@20=0.35552\n",
      "[2020-03-02 16:01:27] [11/50] 0 mean_batch_loss : 4.098632\n",
      "Start predicting 2020-03-02 16:02:17\n",
      "change best\n",
      "testing finish [2020-03-02 16:02:23] \n",
      "\tHR@1=0.16929  MRR@1=0.16929  NDCG@1=0.16929\n",
      "\tHR@5=0.40554  MRR@5=0.25555  NDCG@5=0.29285\n",
      "\tHR@10=0.51724  MRR@10=0.27050  NDCG@10=0.32901\n",
      "\tHR@20=0.62632  MRR@20=0.27808  NDCG@20=0.35661\n",
      "[2020-03-02 16:02:23] [12/50] 0 mean_batch_loss : 3.950698\n",
      "Start predicting 2020-03-02 16:03:14\n",
      "change best\n",
      "testing finish [2020-03-02 16:03:20] \n",
      "\tHR@1=0.16832  MRR@1=0.16832  NDCG@1=0.16832\n",
      "\tHR@5=0.40918  MRR@5=0.25655  NDCG@5=0.29452\n",
      "\tHR@10=0.52187  MRR@10=0.27164  NDCG@10=0.33101\n",
      "\tHR@20=0.62833  MRR@20=0.27909  NDCG@20=0.35801\n",
      "[2020-03-02 16:03:20] [13/50] 0 mean_batch_loss : 3.847634\n",
      "Start predicting 2020-03-02 16:04:10\n",
      "change best\n",
      "testing finish [2020-03-02 16:04:16] \n",
      "\tHR@1=0.17049  MRR@1=0.17049  NDCG@1=0.17049\n",
      "\tHR@5=0.41440  MRR@5=0.25939  NDCG@5=0.29793\n",
      "\tHR@10=0.52497  MRR@10=0.27412  NDCG@10=0.33366\n",
      "\tHR@20=0.63179  MRR@20=0.28157  NDCG@20=0.36072\n",
      "[2020-03-02 16:04:16] [14/50] 0 mean_batch_loss : 3.731028\n",
      "Start predicting 2020-03-02 16:05:07\n",
      "change best\n",
      "testing finish [2020-03-02 16:05:13] \n",
      "\tHR@1=0.16875  MRR@1=0.16875  NDCG@1=0.16875\n",
      "\tHR@5=0.41552  MRR@5=0.25907  NDCG@5=0.29799\n",
      "\tHR@10=0.52713  MRR@10=0.27403  NDCG@10=0.33414\n",
      "\tHR@20=0.63454  MRR@20=0.28154  NDCG@20=0.36137\n",
      "[2020-03-02 16:05:13] [15/50] 0 mean_batch_loss : 3.854550\n",
      "Start predicting 2020-03-02 16:06:03\n",
      "change best\n",
      "testing finish [2020-03-02 16:06:09] \n",
      "\tHR@1=0.17207  MRR@1=0.17207  NDCG@1=0.17207\n",
      "\tHR@5=0.41864  MRR@5=0.26218  NDCG@5=0.30109\n",
      "\tHR@10=0.52874  MRR@10=0.27690  NDCG@10=0.33672\n",
      "\tHR@20=0.63432  MRR@20=0.28425  NDCG@20=0.36345\n",
      "[2020-03-02 16:06:09] [16/50] 0 mean_batch_loss : 3.870238\n",
      "Start predicting 2020-03-02 16:07:00\n",
      "change best\n",
      "testing finish [2020-03-02 16:07:06] \n",
      "\tHR@1=0.16929  MRR@1=0.16929  NDCG@1=0.16929\n",
      "\tHR@5=0.42076  MRR@5=0.26096  NDCG@5=0.30070\n",
      "\tHR@10=0.53271  MRR@10=0.27592  NDCG@10=0.33692\n",
      "\tHR@20=0.63899  MRR@20=0.28335  NDCG@20=0.36386\n",
      "[2020-03-02 16:07:06] [17/50] 0 mean_batch_loss : 3.651067\n",
      "Start predicting 2020-03-02 16:07:57\n",
      "testing finish [2020-03-02 16:08:03] \n",
      "\tHR@1=0.16913  MRR@1=0.16913  NDCG@1=0.16913\n",
      "\tHR@5=0.42164  MRR@5=0.26082  NDCG@5=0.30078\n",
      "\tHR@10=0.53271  MRR@10=0.27570  NDCG@10=0.33676\n",
      "\tHR@20=0.63655  MRR@20=0.28297  NDCG@20=0.36308\n",
      "[2020-03-02 16:08:03] [18/50] 0 mean_batch_loss : 3.528023\n",
      "Start predicting 2020-03-02 16:08:53\n",
      "testing finish [2020-03-02 16:08:59] \n",
      "\tHR@1=0.16613  MRR@1=0.16613  NDCG@1=0.16613\n",
      "\tHR@5=0.41882  MRR@5=0.25827  NDCG@5=0.29819\n",
      "\tHR@10=0.53226  MRR@10=0.27342  NDCG@10=0.33489\n",
      "\tHR@20=0.63872  MRR@20=0.28084  NDCG@20=0.36185\n",
      "[2020-03-02 16:08:59] [19/50] 0 mean_batch_loss : 3.802584\n",
      "Start predicting 2020-03-02 16:09:48\n",
      "change best\n",
      "testing finish [2020-03-02 16:09:54] \n",
      "\tHR@1=0.16640  MRR@1=0.16640  NDCG@1=0.16640\n",
      "\tHR@5=0.42146  MRR@5=0.25961  NDCG@5=0.29987\n",
      "\tHR@10=0.53597  MRR@10=0.27487  NDCG@10=0.33687\n",
      "\tHR@20=0.64024  MRR@20=0.28213  NDCG@20=0.36326\n",
      "[2020-03-02 16:09:54] [20/50] 0 mean_batch_loss : 3.376227\n",
      "Start predicting 2020-03-02 16:10:38\n",
      "testing finish [2020-03-02 16:10:44] \n",
      "\tHR@1=0.16507  MRR@1=0.16507  NDCG@1=0.16507\n",
      "\tHR@5=0.41848  MRR@5=0.25700  NDCG@5=0.29714\n",
      "\tHR@10=0.53280  MRR@10=0.27230  NDCG@10=0.33415\n",
      "\tHR@20=0.63800  MRR@20=0.27967  NDCG@20=0.36083\n",
      "[2020-03-02 16:10:44] [21/50] 0 mean_batch_loss : 3.411822\n",
      "Start predicting 2020-03-02 16:11:28\n",
      "testing finish [2020-03-02 16:11:34] \n",
      "\tHR@1=0.16421  MRR@1=0.16421  NDCG@1=0.16421\n",
      "\tHR@5=0.41756  MRR@5=0.25591  NDCG@5=0.29607\n",
      "\tHR@10=0.53244  MRR@10=0.27133  NDCG@10=0.33330\n",
      "\tHR@20=0.63996  MRR@20=0.27884  NDCG@20=0.36055\n",
      "[2020-03-02 16:11:34] [22/50] 0 mean_batch_loss : 3.362402\n",
      "Start predicting 2020-03-02 16:12:18\n",
      "testing finish [2020-03-02 16:12:24] \n",
      "\tHR@1=0.16672  MRR@1=0.16672  NDCG@1=0.16672\n",
      "\tHR@5=0.41810  MRR@5=0.25810  NDCG@5=0.29787\n",
      "\tHR@10=0.53235  MRR@10=0.27340  NDCG@10=0.33487\n",
      "\tHR@20=0.63877  MRR@20=0.28083  NDCG@20=0.36183\n",
      "[2020-03-02 16:12:24] [23/50] 0 mean_batch_loss : 3.570542\n",
      "Start predicting 2020-03-02 16:13:06\n",
      "testing finish [2020-03-02 16:13:12] \n",
      "\tHR@1=0.16145  MRR@1=0.16145  NDCG@1=0.16145\n",
      "\tHR@5=0.41430  MRR@5=0.25342  NDCG@5=0.29341\n",
      "\tHR@10=0.53176  MRR@10=0.26918  NDCG@10=0.33149\n",
      "\tHR@20=0.63766  MRR@20=0.27660  NDCG@20=0.35834\n",
      "[2020-03-02 16:13:12] [24/50] 0 mean_batch_loss : 3.139707\n",
      "Start predicting 2020-03-02 16:13:57\n",
      "testing finish [2020-03-02 16:14:02] \n",
      "\tHR@1=0.15929  MRR@1=0.15929  NDCG@1=0.15929\n",
      "\tHR@5=0.41485  MRR@5=0.25148  NDCG@5=0.29205\n",
      "\tHR@10=0.52802  MRR@10=0.26667  NDCG@10=0.32873\n",
      "\tHR@20=0.63741  MRR@20=0.27429  NDCG@20=0.35643\n",
      "early stopping\n",
      "training and testting over, Total time 0:22:02.817554\n",
      "current model hyper-parameters: session_length=20, hidden_size=200, lr=0.0030, embedding_dim=200, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "current model HR@20=0.64024  MRR@20=0.28213\n",
      "the best result so far. HR@20=0.64024  MRR@20=0.29136, current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0030, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      " \n",
      "\n",
      "current model hyper-parameters: session_length=20, hidden_size=300, lr=0.0030, embedding_dim=300, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "[2020-03-02 16:14:03] [1/50] 0 mean_batch_loss : 39.441597\n",
      "Start predicting 2020-03-02 16:14:55\n",
      "change best\n",
      "testing finish [2020-03-02 16:15:00] \n",
      "\tHR@1=0.16507  MRR@1=0.16507  NDCG@1=0.16507\n",
      "\tHR@5=0.23939  MRR@5=0.19363  NDCG@5=0.20508\n",
      "\tHR@10=0.26735  MRR@10=0.19736  NDCG@10=0.21412\n",
      "\tHR@20=0.29450  MRR@20=0.19926  NDCG@20=0.22100\n",
      "[2020-03-02 16:15:00] [2/50] 0 mean_batch_loss : 9.127110\n",
      "Start predicting 2020-03-02 16:15:52\n",
      "testing finish [2020-03-02 16:15:58] \n",
      "\tHR@1=0.02920  MRR@1=0.02920  NDCG@1=0.02920\n",
      "\tHR@5=0.07796  MRR@5=0.04628  NDCG@5=0.05412\n",
      "\tHR@10=0.10890  MRR@10=0.05041  NDCG@10=0.06413\n",
      "\tHR@20=0.14402  MRR@20=0.05282  NDCG@20=0.07297\n",
      "[2020-03-02 16:15:59] [3/50] 0 mean_batch_loss : 9.378822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2020-03-02 16:16:50\n",
      "testing finish [2020-03-02 16:16:56] \n",
      "\tHR@1=0.06310  MRR@1=0.06310  NDCG@1=0.06310\n",
      "\tHR@5=0.16202  MRR@5=0.09863  NDCG@5=0.11435\n",
      "\tHR@10=0.21861  MRR@10=0.10618  NDCG@10=0.13265\n",
      "\tHR@20=0.27842  MRR@20=0.11032  NDCG@20=0.14776\n",
      "[2020-03-02 16:16:56] [4/50] 0 mean_batch_loss : 8.013636\n",
      "Start predicting 2020-03-02 16:17:48\n",
      "change best\n",
      "testing finish [2020-03-02 16:17:54] \n",
      "\tHR@1=0.09860  MRR@1=0.09860  NDCG@1=0.09860\n",
      "\tHR@5=0.23801  MRR@5=0.14864  NDCG@5=0.17082\n",
      "\tHR@10=0.31270  MRR@10=0.15857  NDCG@10=0.19493\n",
      "\tHR@20=0.39113  MRR@20=0.16402  NDCG@20=0.21477\n",
      "[2020-03-02 16:17:54] [5/50] 0 mean_batch_loss : 6.762211\n",
      "Start predicting 2020-03-02 16:18:46\n",
      "change best\n",
      "testing finish [2020-03-02 16:18:52] \n",
      "\tHR@1=0.12243  MRR@1=0.12243  NDCG@1=0.12243\n",
      "\tHR@5=0.28485  MRR@5=0.18081  NDCG@5=0.20663\n",
      "\tHR@10=0.37130  MRR@10=0.19242  NDCG@10=0.23466\n",
      "\tHR@20=0.46498  MRR@20=0.19893  NDCG@20=0.25836\n",
      "[2020-03-02 16:18:52] [6/50] 0 mean_batch_loss : 5.872862\n",
      "Start predicting 2020-03-02 16:19:45\n",
      "change best\n",
      "testing finish [2020-03-02 16:19:51] \n",
      "\tHR@1=0.13973  MRR@1=0.13973  NDCG@1=0.13973\n",
      "\tHR@5=0.32214  MRR@5=0.20523  NDCG@5=0.23425\n",
      "\tHR@10=0.41814  MRR@10=0.21800  NDCG@10=0.26524\n",
      "\tHR@20=0.51837  MRR@20=0.22493  NDCG@20=0.29056\n",
      "[2020-03-02 16:19:51] [7/50] 0 mean_batch_loss : 5.309218\n",
      "Start predicting 2020-03-02 16:20:44\n",
      "testing finish [2020-03-02 16:20:50] \n",
      "\tHR@1=0.12652  MRR@1=0.12652  NDCG@1=0.12652\n",
      "\tHR@5=0.31069  MRR@5=0.19202  NDCG@5=0.22143\n",
      "\tHR@10=0.41263  MRR@10=0.20562  NDCG@10=0.25439\n",
      "\tHR@20=0.52196  MRR@20=0.21319  NDCG@20=0.28202\n",
      "[2020-03-02 16:20:50] [8/50] 0 mean_batch_loss : 5.295527\n",
      "Start predicting 2020-03-02 16:21:42\n",
      "change best\n",
      "testing finish [2020-03-02 16:21:48] \n",
      "\tHR@1=0.14149  MRR@1=0.14149  NDCG@1=0.14149\n",
      "\tHR@5=0.33982  MRR@5=0.21319  NDCG@5=0.24465\n",
      "\tHR@10=0.44484  MRR@10=0.22724  NDCG@10=0.27864\n",
      "\tHR@20=0.55491  MRR@20=0.23485  NDCG@20=0.30644\n",
      "[2020-03-02 16:21:48] [9/50] 0 mean_batch_loss : 4.701313\n",
      "Start predicting 2020-03-02 16:22:40\n",
      "change best\n",
      "testing finish [2020-03-02 16:22:46] \n",
      "\tHR@1=0.14924  MRR@1=0.14924  NDCG@1=0.14924\n",
      "\tHR@5=0.35631  MRR@5=0.22400  NDCG@5=0.25685\n",
      "\tHR@10=0.46295  MRR@10=0.23822  NDCG@10=0.29132\n",
      "\tHR@20=0.57605  MRR@20=0.24605  NDCG@20=0.31990\n",
      "[2020-03-02 16:22:46] [10/50] 0 mean_batch_loss : 4.296626\n",
      "Start predicting 2020-03-02 16:23:39\n",
      "change best\n",
      "testing finish [2020-03-02 16:23:45] \n",
      "\tHR@1=0.15470  MRR@1=0.15470  NDCG@1=0.15470\n",
      "\tHR@5=0.36916  MRR@5=0.23240  NDCG@5=0.26637\n",
      "\tHR@10=0.47851  MRR@10=0.24704  NDCG@10=0.30178\n",
      "\tHR@20=0.58967  MRR@20=0.25477  NDCG@20=0.32991\n",
      "[2020-03-02 16:23:45] [11/50] 0 mean_batch_loss : 4.047416\n",
      "Start predicting 2020-03-02 16:24:37\n",
      "change best\n",
      "testing finish [2020-03-02 16:24:43] \n",
      "\tHR@1=0.15929  MRR@1=0.15929  NDCG@1=0.15929\n",
      "\tHR@5=0.38151  MRR@5=0.24017  NDCG@5=0.27531\n",
      "\tHR@10=0.48931  MRR@10=0.25456  NDCG@10=0.31017\n",
      "\tHR@20=0.59999  MRR@20=0.26229  NDCG@20=0.33821\n",
      "[2020-03-02 16:24:43] [12/50] 0 mean_batch_loss : 4.130651\n",
      "Start predicting 2020-03-02 16:25:35\n",
      "change best\n",
      "testing finish [2020-03-02 16:25:42] \n",
      "\tHR@1=0.16044  MRR@1=0.16044  NDCG@1=0.16044\n",
      "\tHR@5=0.38915  MRR@5=0.24359  NDCG@5=0.27976\n",
      "\tHR@10=0.49845  MRR@10=0.25820  NDCG@10=0.31514\n",
      "\tHR@20=0.60706  MRR@20=0.26574  NDCG@20=0.34260\n",
      "[2020-03-02 16:25:42] [13/50] 0 mean_batch_loss : 4.115239\n",
      "Start predicting 2020-03-02 16:26:34\n",
      "change best\n",
      "testing finish [2020-03-02 16:26:40] \n",
      "\tHR@1=0.16477  MRR@1=0.16477  NDCG@1=0.16477\n",
      "\tHR@5=0.39651  MRR@5=0.24859  NDCG@5=0.28533\n",
      "\tHR@10=0.50938  MRR@10=0.26369  NDCG@10=0.32187\n",
      "\tHR@20=0.61688  MRR@20=0.27116  NDCG@20=0.34907\n",
      "[2020-03-02 16:26:40] [14/50] 0 mean_batch_loss : 3.877794\n",
      "Start predicting 2020-03-02 16:27:38\n",
      "testing finish [2020-03-02 16:27:44] \n",
      "\tHR@1=0.16073  MRR@1=0.16073  NDCG@1=0.16073\n",
      "\tHR@5=0.39570  MRR@5=0.24572  NDCG@5=0.28297\n",
      "\tHR@10=0.50715  MRR@10=0.26070  NDCG@10=0.31912\n",
      "\tHR@20=0.61749  MRR@20=0.26839  NDCG@20=0.34705\n",
      "[2020-03-02 16:27:44] [15/50] 0 mean_batch_loss : 3.988963\n",
      "Start predicting 2020-03-02 16:28:41\n",
      "change best\n",
      "testing finish [2020-03-02 16:28:48] \n",
      "\tHR@1=0.16005  MRR@1=0.16005  NDCG@1=0.16005\n",
      "\tHR@5=0.39978  MRR@5=0.24743  NDCG@5=0.28530\n",
      "\tHR@10=0.51352  MRR@10=0.26262  NDCG@10=0.32209\n",
      "\tHR@20=0.62219  MRR@20=0.27021  NDCG@20=0.34964\n",
      "[2020-03-02 16:28:48] [16/50] 0 mean_batch_loss : 3.964078\n",
      "Start predicting 2020-03-02 16:29:44\n",
      "change best\n",
      "testing finish [2020-03-02 16:29:50] \n",
      "\tHR@1=0.16306  MRR@1=0.16306  NDCG@1=0.16306\n",
      "\tHR@5=0.40378  MRR@5=0.25061  NDCG@5=0.28868\n",
      "\tHR@10=0.51395  MRR@10=0.26527  NDCG@10=0.32426\n",
      "\tHR@20=0.62079  MRR@20=0.27274  NDCG@20=0.35135\n",
      "[2020-03-02 16:29:50] [17/50] 0 mean_batch_loss : 3.629714\n",
      "Start predicting 2020-03-02 16:30:48\n",
      "change best\n",
      "testing finish [2020-03-02 16:30:55] \n",
      "\tHR@1=0.16145  MRR@1=0.16145  NDCG@1=0.16145\n",
      "\tHR@5=0.40365  MRR@5=0.24921  NDCG@5=0.28758\n",
      "\tHR@10=0.51731  MRR@10=0.26443  NDCG@10=0.32439\n",
      "\tHR@20=0.62492  MRR@20=0.27191  NDCG@20=0.35161\n",
      "[2020-03-02 16:30:55] [18/50] 0 mean_batch_loss : 3.676421\n",
      "Start predicting 2020-03-02 16:31:53\n",
      "change best\n",
      "testing finish [2020-03-02 16:31:59] \n",
      "\tHR@1=0.16263  MRR@1=0.16263  NDCG@1=0.16263\n",
      "\tHR@5=0.40931  MRR@5=0.25204  NDCG@5=0.29112\n",
      "\tHR@10=0.52029  MRR@10=0.26689  NDCG@10=0.32705\n",
      "\tHR@20=0.62689  MRR@20=0.27434  NDCG@20=0.35407\n",
      "[2020-03-02 16:31:59] [19/50] 0 mean_batch_loss : 3.551386\n",
      "Start predicting 2020-03-02 16:32:57\n",
      "testing finish [2020-03-02 16:33:03] \n",
      "\tHR@1=0.15836  MRR@1=0.15836  NDCG@1=0.15836\n",
      "\tHR@5=0.40866  MRR@5=0.24928  NDCG@5=0.28889\n",
      "\tHR@10=0.52031  MRR@10=0.26419  NDCG@10=0.32501\n",
      "\tHR@20=0.62689  MRR@20=0.27160  NDCG@20=0.35196\n",
      "[2020-03-02 16:33:03] [20/50] 0 mean_batch_loss : 3.775821\n",
      "Start predicting 2020-03-02 16:34:01\n",
      "testing finish [2020-03-02 16:34:07] \n",
      "\tHR@1=0.15929  MRR@1=0.15929  NDCG@1=0.15929\n",
      "\tHR@5=0.40606  MRR@5=0.24856  NDCG@5=0.28769\n",
      "\tHR@10=0.51844  MRR@10=0.26355  NDCG@10=0.32402\n",
      "\tHR@20=0.62863  MRR@20=0.27126  NDCG@20=0.35196\n",
      "[2020-03-02 16:34:08] [21/50] 0 mean_batch_loss : 3.397857\n",
      "Start predicting 2020-03-02 16:35:04\n",
      "testing finish [2020-03-02 16:35:10] \n",
      "\tHR@1=0.15752  MRR@1=0.15752  NDCG@1=0.15752\n",
      "\tHR@5=0.40712  MRR@5=0.24816  NDCG@5=0.28767\n",
      "\tHR@10=0.51946  MRR@10=0.26321  NDCG@10=0.32406\n",
      "\tHR@20=0.62836  MRR@20=0.27081  NDCG@20=0.35164\n",
      "[2020-03-02 16:35:10] [22/50] 0 mean_batch_loss : 3.400275\n",
      "Start predicting 2020-03-02 16:36:07\n",
      "testing finish [2020-03-02 16:36:13] \n",
      "\tHR@1=0.15874  MRR@1=0.15874  NDCG@1=0.15874\n",
      "\tHR@5=0.40696  MRR@5=0.24894  NDCG@5=0.28822\n",
      "\tHR@10=0.51907  MRR@10=0.26403  NDCG@10=0.32460\n",
      "\tHR@20=0.62858  MRR@20=0.27165  NDCG@20=0.35232\n",
      "[2020-03-02 16:36:13] [23/50] 0 mean_batch_loss : 3.284609\n",
      "Start predicting 2020-03-02 16:37:11\n",
      "change best\n",
      "testing finish [2020-03-02 16:37:17] \n",
      "\tHR@1=0.15768  MRR@1=0.15768  NDCG@1=0.15768\n",
      "\tHR@5=0.41225  MRR@5=0.25035  NDCG@5=0.29060\n",
      "\tHR@10=0.52621  MRR@10=0.26561  NDCG@10=0.32751\n",
      "\tHR@20=0.63057  MRR@20=0.27289  NDCG@20=0.35394\n",
      "[2020-03-02 16:37:17] [24/50] 0 mean_batch_loss : 3.278717\n",
      "Start predicting 2020-03-02 16:38:14\n",
      "testing finish [2020-03-02 16:38:20] \n",
      "\tHR@1=0.15536  MRR@1=0.15536  NDCG@1=0.15536\n",
      "\tHR@5=0.40484  MRR@5=0.24512  NDCG@5=0.28478\n",
      "\tHR@10=0.51989  MRR@10=0.26057  NDCG@10=0.32208\n",
      "\tHR@20=0.62723  MRR@20=0.26808  NDCG@20=0.34930\n",
      "[2020-03-02 16:38:20] [25/50] 0 mean_batch_loss : 3.148611\n",
      "Start predicting 2020-03-02 16:39:18\n",
      "testing finish [2020-03-02 16:39:25] \n",
      "\tHR@1=0.15477  MRR@1=0.15477  NDCG@1=0.15477\n",
      "\tHR@5=0.40457  MRR@5=0.24533  NDCG@5=0.28489\n",
      "\tHR@10=0.51984  MRR@10=0.26081  NDCG@10=0.32227\n",
      "\tHR@20=0.62865  MRR@20=0.26842  NDCG@20=0.34985\n",
      "[2020-03-02 16:39:25] [26/50] 0 mean_batch_loss : 3.386936\n",
      "Start predicting 2020-03-02 16:40:22\n",
      "testing finish [2020-03-02 16:40:28] \n",
      "\tHR@1=0.15294  MRR@1=0.15294  NDCG@1=0.15294\n",
      "\tHR@5=0.39985  MRR@5=0.24181  NDCG@5=0.28105\n",
      "\tHR@10=0.51431  MRR@10=0.25718  NDCG@10=0.31816\n",
      "\tHR@20=0.62409  MRR@20=0.26485  NDCG@20=0.34598\n",
      "[2020-03-02 16:40:28] [27/50] 0 mean_batch_loss : 3.174732\n",
      "Start predicting 2020-03-02 16:41:26\n",
      "testing finish [2020-03-02 16:41:32] \n",
      "\tHR@1=0.15323  MRR@1=0.15323  NDCG@1=0.15323\n",
      "\tHR@5=0.40340  MRR@5=0.24364  NDCG@5=0.28332\n",
      "\tHR@10=0.51790  MRR@10=0.25891  NDCG@10=0.32033\n",
      "\tHR@20=0.62515  MRR@20=0.26642  NDCG@20=0.34753\n",
      "[2020-03-02 16:41:32] [28/50] 0 mean_batch_loss : 3.043989\n",
      "Start predicting 2020-03-02 16:42:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing finish [2020-03-02 16:42:36] \n",
      "\tHR@1=0.15472  MRR@1=0.15472  NDCG@1=0.15472\n",
      "\tHR@5=0.40448  MRR@5=0.24499  NDCG@5=0.28460\n",
      "\tHR@10=0.52011  MRR@10=0.26049  NDCG@10=0.32207\n",
      "\tHR@20=0.62540  MRR@20=0.26788  NDCG@20=0.34878\n",
      "early stopping\n",
      "training and testting over, Total time 0:28:33.733335\n",
      "current model hyper-parameters: session_length=20, hidden_size=300, lr=0.0030, embedding_dim=300, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "current model HR@20=0.63057  MRR@20=0.27289\n",
      "the best result so far. HR@20=0.63057  MRR@20=0.29136, current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0030, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      " \n",
      "\n",
      "The best result HR@20=0.64674  MRR@20=0.29136, hyper-parameters: current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0030, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      ". \n",
      "over.\n"
     ]
    }
   ],
   "source": [
    "hidden_sizes = [10,20,50,100,200,300]\n",
    "# embedding_dims = [100]\n",
    "dropouts = [0.5]\n",
    "embedding_dropouts = [0.25]\n",
    "lrs = [3e-3]\n",
    "session_lengths = [20]\n",
    "patience = 5\n",
    "best_params = \"\"\n",
    "best_all_model = 0.0\n",
    "best_all_hr = 0.0\n",
    "best_all_mrr = 0.0\n",
    "best_all_r1m = 0.0\n",
    "for session_length in session_lengths:\n",
    "    for hidden_size in hidden_sizes:\n",
    "        for dropout in dropouts:\n",
    "            for embedding_dropout in embedding_dropouts:\n",
    "                for lr in lrs:\n",
    "                    args = {}\n",
    "                    print(\"current model hyper-parameters: session_length=%d, hidden_size=%d, lr=%.4f, embedding_dim=%d, embedding_dropout=%.2f, dropout=%.2f\\n\" % (session_length,hidden_size,lr,hidden_size,embedding_dropout,dropout))\n",
    "                    args[\"session_length\"] = session_length\n",
    "                    args[\"hidden_size\"] = hidden_size\n",
    "                    args[\"embedding_dim\"] = hidden_size\n",
    "                    args[\"dropout\"] = dropout\n",
    "                    args[\"embedding_dropout\"] = embedding_dropout\n",
    "                    args[\"patience\"] = patience\n",
    "                    args[\"lr\"] = lr\n",
    "                    best_model,best_model_hr,best_model_mrr = train(args)\n",
    "                    if best_model_hr + best_model_mrr > best_all_r1m:\n",
    "                        print(\"best model change\")\n",
    "                        best_all_r1m = best_model_hr + best_model_mrr\n",
    "                        best_all_hr = best_model_hr\n",
    "                        best_all_mrr = best_model_mrr\n",
    "                        best_all_model = best_model\n",
    "                        best_params = \"current model hyper-parameters: session_length=%d, hidden_size=%d, lr=%.4f, embedding_dim=%d, embedding_dropout=%.2f, dropout=%.2f\\n\" % (session_length,hidden_size,lr,hidden_size,embedding_dropout,dropout)\n",
    "                    best_model = None\n",
    "                    print(\"current model hyper-parameters: session_length=%d, hidden_size=%d, lr=%.4f, embedding_dim=%d, embedding_dropout=%.2f, dropout=%.2f\\n\" % (session_length,hidden_size,lr,hidden_size,embedding_dropout,dropout))\n",
    "                    print(\"current model HR@20=%.5f  MRR@20=%.5f\"%(best_model_hr,best_model_mrr))\n",
    "                    print(\"the best result so far. HR@20=%.5f  MRR@20=%.5f, %s \\n\"%(best_model_hr,best_all_mrr,best_params))\n",
    "print(\"The best result HR@20=%.5f  MRR@20=%.5f, hyper-parameters: %s. \"%(best_all_hr,best_all_mrr,best_params))\n",
    "print(\"over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smy",
   "language": "python",
   "name": "smy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
