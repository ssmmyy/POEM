{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:43:45.073306Z",
     "start_time": "2019-12-23T06:43:44.535897Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:43:45.078810Z",
     "start_time": "2019-12-23T06:43:45.074552Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:43:45.086085Z",
     "start_time": "2019-12-23T06:43:45.080165Z"
    }
   },
   "outputs": [],
   "source": [
    "session_length = 19\n",
    "batch_size = 512\n",
    "plot_num = 500\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:43:45.153336Z",
     "start_time": "2019-12-23T06:43:45.087206Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class SessionData(object):\n",
    "    def __init__(self,session_index,session_id,items_indexes):\n",
    "        self.session_index = session_index\n",
    "        self.session_id = session_id\n",
    "        self.item_list = items_indexes\n",
    "\n",
    "    def generate_seq_datas(self,session_length,padding_idx=0,predict_length=1):\n",
    "        sessions = []\n",
    "        if len(self.item_list)<2:\n",
    "            self.item_list.append[self.item_list[0]]\n",
    "        if predict_length==1:\n",
    "            # when session length>=3\n",
    "            for i in range(1,len(self.item_list)-1):\n",
    "#             # when session length >=2\n",
    "#             for i in range(len(self.item_list)-1):\n",
    "                if i <session_length:\n",
    "                    train_data = [0 for _ in range(session_length-i-1)]\n",
    "                    train_data.extend(self.item_list[:i+1])\n",
    "                    train_data.append(self.item_list[i+1])\n",
    "                else:\n",
    "                    train_data = self.item_list[i+1-session_length:i+1]\n",
    "                    train_data.append(self.item_list[i+1])\n",
    "                sessions.append(train_data)\n",
    "        else:\n",
    "\n",
    "            pass\n",
    "        return self.session_index,sessions\n",
    "    def __str__(self):\n",
    "        info = \" session index = {}\\n session id = {} \\n the length of item list= {} \\n the fisrt item index in item list is {}\".format(self.session_index,self.session_id,len(self.item_list),self.item_list[0])\n",
    "        return info\n",
    "class SessionDataSet(object):\n",
    "    def __init__(self,train_file,test_file,padding_idx=0):\n",
    "        super(SessionDataSet,self).__init__()\n",
    "        self.index_count = 0\n",
    "        self.session_count = 0\n",
    "        self.train_count = 0\n",
    "        self.test_count = 0\n",
    "        self.max_session_length = 0\n",
    "\n",
    "        self.padding_idx = padding_idx\n",
    "        self.item2index = dict()\n",
    "        self.index2item = dict()\n",
    "        self.session2index = dict()\n",
    "        self.index2session = dict()\n",
    "        self.item_total_num = dict()\n",
    "        self.item2index[\"<pad>\"] = padding_idx\n",
    "        self.index2item[padding_idx] = \"<pad>\"\n",
    "        self.train_data = self.load_data(train_file)\n",
    "        print(\"training set is loaded, # index: \",len(self.item2index.keys()))\n",
    "        self.train_count = self.session_count\n",
    "        print(\"train_session_num\",self.train_count)\n",
    "        self.test_data = self.load_data(test_file)\n",
    "        print(\"testing set is loaded, # index: \",len(self.index2item.keys()))\n",
    "        print(\"# item\",self.index_count)\n",
    "        self.test_count = self.session_count-self.train_count\n",
    "        print(\"# test session:\",self.test_count)\n",
    "        self.all_training_data = []\n",
    "        self.all_testing_data = []\n",
    "        self.all_meta_training_data = []\n",
    "        self.all_meta_testing_data = []\n",
    "        self.train_session_length = 0\n",
    "        self.test_session_length = 0\n",
    "    \n",
    "    def load_data(self,file_path):\n",
    "        data =  pickle.load(open(file_path, 'rb'))\n",
    "        session_ids = data[0]\n",
    "        session_data = data[1]\n",
    "        session_label = data[2]\n",
    "\n",
    "        result_data = []\n",
    "        lenth = len(session_ids)\n",
    "        print(\"# session\",lenth)\n",
    "\n",
    "        last_session_id = session_ids[0]\n",
    "        \n",
    "        session_item_indexes = []\n",
    "\n",
    "        for item_id in session_data[0]:\n",
    "            if item_id not in self.item2index.keys():\n",
    "                self.index_count+=1\n",
    "                self.item2index[item_id] = self.index_count\n",
    "                self.index2item[self.index_count] = item_id\n",
    "                self.item_total_num[self.index_count] = 0\n",
    "            session_item_indexes.append(self.item2index[item_id])\n",
    "            self.item_total_num[self.item2index[item_id]] += 1\n",
    "        target_item = session_label[0]\n",
    "        if target_item not in self.item2index.keys():\n",
    "            self.index_count+=1\n",
    "            self.item2index[target_item] = self.index_count\n",
    "            self.index2item[self.index_count] = target_item\n",
    "            self.item_total_num[self.index_count] = 0\n",
    "        session_item_indexes.append(self.item2index[target_item])\n",
    "        self.item_total_num[self.item2index[target_item]] += 1\n",
    "\n",
    "        for session_id,items,target_item in zip(session_ids,session_data,session_label):\n",
    "            if session_id!=last_session_id:\n",
    "\n",
    "                self.session_count+=1\n",
    "                self.session2index[last_session_id] = self.session_count\n",
    "                self.index2session[self.session_count] = last_session_id\n",
    "                if len(session_item_indexes)>self.max_session_length:\n",
    "                    self.max_session_length = len(session_item_indexes)\n",
    "                new_session = SessionData(self.session_count,last_session_id,session_item_indexes)\n",
    "                result_data.append(new_session)\n",
    "                last_session_id = session_id\n",
    "                session_item_indexes = []\n",
    "                for item_id in items:\n",
    "                    if item_id not in self.item2index.keys():\n",
    "                        self.index_count+=1\n",
    "                        self.item2index[item_id] = self.index_count\n",
    "                        self.index2item[self.index_count] = item_id\n",
    "                        self.item_total_num[self.index_count] = 0\n",
    "                    session_item_indexes.append(self.item2index[item_id])\n",
    "                    self.item_total_num[self.item2index[item_id]] += 1\n",
    "                if target_item not in self.item2index.keys():\n",
    "                    self.index_count+=1\n",
    "                    self.item2index[target_item] = self.index_count\n",
    "                    self.index2item[self.index_count] = target_item\n",
    "                    self.item_total_num[self.index_count] = 0\n",
    "                session_item_indexes.append(self.item2index[target_item])\n",
    "                self.item_total_num[self.item2index[target_item]] += 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        self.session_count+=1\n",
    "        self.session2index[last_session_id] = self.session_count\n",
    "        new_session = SessionData(self.session_count,last_session_id,session_item_indexes)\n",
    "        result_data.append(new_session)\n",
    "        print(\"loaded\")\n",
    "        print(new_session)\n",
    "        \n",
    "        return result_data\n",
    "    \n",
    "\n",
    "    def get_batch(self,batch_size,session_length=10,predict_length=1,all_data=None,phase=\"train\",neg_num=1,sampling_mathod=\"random\"):\n",
    "\n",
    "        if phase == \"train\":\n",
    "            if all_data is None:\n",
    "                all_data = self.get_all_training_data(session_length)\n",
    "            indexes = np.random.permutation(all_data.shape[0])\n",
    "            all_data = all_data[indexes]\n",
    "        else:\n",
    "            if all_data is None:\n",
    "                all_data = self.get_all_testing_data(session_length)\n",
    "        \n",
    "        sindex = 0\n",
    "        eindex = batch_size\n",
    "        while eindex < all_data.shape[0]:\n",
    "            batch = all_data[sindex: eindex]\n",
    "\n",
    "            temp = eindex\n",
    "            eindex = eindex + batch_size\n",
    "            sindex = temp\n",
    "            if phase ==\"train\":\n",
    "                batch = self.divid_and_extend_negative_samples(batch,session_length=session_length,predict_length=predict_length,neg_num=neg_num,method=sampling_mathod)\n",
    "            else:\n",
    "                batch = [batch[:,:session_length],batch[:,session_length:]]\n",
    "            yield batch\n",
    "\n",
    "        if eindex >= all_data.shape[0]:\n",
    "            batch = all_data[sindex:]\n",
    "            if phase ==\"train\":\n",
    "                batch = self.divid_and_extend_negative_samples(batch,session_length=session_length,predict_length=predict_length,neg_num=neg_num,method=sampling_mathod)\n",
    "            else:\n",
    "                batch = [batch[:,:session_length],batch[:,session_length:]]\n",
    "            yield batch\n",
    "    \n",
    "    def divid_and_extend_negative_samples(self,batch_data,session_length,predict_length=1,neg_num=1,method=\"random\"):\n",
    "        \"\"\"\n",
    "        divid and extend negative samples\n",
    "        \"\"\"\n",
    "        neg_items = []\n",
    "        if method == \"random\":\n",
    "            for session_and_target in batch_data:\n",
    "                neg_item = []\n",
    "                for i in range(neg_num):\n",
    "                    rand_item = random.randint(1,self.index_count)\n",
    "                    while rand_item in session_and_target or rand_item in neg_item:\n",
    "                        rand_item = random.randint(1,self.index_count)\n",
    "                    neg_item.append(rand_item)\n",
    "                neg_items.append(neg_item)\n",
    "        else:\n",
    "\n",
    "            total_list = set()\n",
    "            for session in batch_data:\n",
    "                for i in session:\n",
    "                    total_list.add(i) \n",
    "            total_list = list(total_list)\n",
    "            total_list =  sorted(total_list, key=lambda item: self.item_total_num[item],reverse=True)\n",
    "            for i,session in enumerate(batch_data):\n",
    "                np.random.choice(total_list)\n",
    "        session_items = batch_data[:,:session_length]\n",
    "        target_item = batch_data[:,session_length:]\n",
    "        neg_items = np.array(neg_items)\n",
    "        return [session_items,target_item,neg_items]\n",
    "    \n",
    "    def get_all_training_data(self,session_length,predict_length=1):\n",
    "        if len(self.all_training_data)!=0 and self.train_session_length==session_length:\n",
    "#             print(\"The build is complete and there is no need to repeat the build\")\n",
    "            return self.all_training_data\n",
    "        print(\"Start building the all training dataset\")\n",
    "        all_sessions = []\n",
    "        for session_data in self.train_data:\n",
    "            session_index,sessions = session_data.generate_seq_datas(session_length,padding_idx=self.padding_idx)\n",
    "            if sessions is not None:\n",
    "                all_sessions.extend(sessions)\n",
    "        all_sessions = np.array(all_sessions)\n",
    "        self.all_training_data = all_sessions\n",
    "        self.train_session_length=session_length\n",
    "        print(\"The total number of training samples is：\",all_sessions.shape)\n",
    "        return all_sessions\n",
    "    \n",
    "    def get_all_testing_data(self,session_length,predict_length=1):\n",
    "        if len(self.all_testing_data)!=0 and self.test_session_length==session_length:\n",
    "            return self.all_testing_data\n",
    "        all_sessions = []\n",
    "        for session_data in self.test_data:\n",
    "            session_index,sessions = session_data.generate_seq_datas(session_length,padding_idx=self.padding_idx)\n",
    "            if sessions is not None:\n",
    "                all_sessions.extend(sessions)\n",
    "        all_sessions = np.array(all_sessions)\n",
    "        self.all_testing_data = all_sessions\n",
    "        self.test_session_length=session_length\n",
    "        print(\"The total number of testing samples is：\",all_sessions.shape)\n",
    "        return all_sessions\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:43:45.970893Z",
     "start_time": "2019-12-23T06:43:45.154740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# session 245270\n",
      "loaded\n",
      " session index = 63131\n",
      " session id = 11497318 \n",
      " the length of item list= 3 \n",
      " the fisrt item index in item list is 225\n",
      "training set is loaded, # index:  15438\n",
      "train_session_num 63131\n",
      "# session 40548\n",
      "loaded\n",
      " session index = 72474\n",
      " session id = 11560908 \n",
      " the length of item list= 3 \n",
      " the fisrt item index in item list is 7568\n",
      "testing set is loaded, # index:  15834\n",
      "# item 15833\n",
      "# test session: 9343\n"
     ]
    }
   ],
   "source": [
    "# dataset = SessionDataSet(train_file=\"../../data/retailrocket_gcsan_my/train.txt\",test_file=\"../../data/srgnn/retailrocket_gcsan_my/test.txt\")\n",
    "dataset = SessionDataSet(train_file=\"../../data/diginetica_gcsan_my/train.txt\",test_file=\"../../data/srgnn/diginetica_gcsan_my/test.txt\")\n",
    "# dataset = SessionDataSet(train_file=\"../../data/yoochoose1_4_gcsan_my/train.txt\",test_file=\"../../data/srgnn/yoochoose1_4_gcsan_my/test.txt\")\n",
    "# dataset = SessionDataSet(train_file=\"../../data/yoochoose1_64_gcsan_my/train.txt\",test_file=\"../../data/srgnn/yoochoose1_64_gcsan_my/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:43:45.983798Z",
     "start_time": "2019-12-23T06:43:45.972872Z"
    }
   },
   "outputs": [],
   "source": [
    "def bpr_loss(r):\n",
    "    return torch.sum(-torch.log(torch.sigmoid(r)))\n",
    "def get_hit_num(pred,y_truth):\n",
    "    \"\"\"\n",
    "        pred: numpy type(batch_size,k) \n",
    "        y_truth: list type (batch_size,groudtruth_num)\n",
    "    \"\"\"\n",
    "\n",
    "    hit_num = 0\n",
    "    for i in range(len(y_truth)):\n",
    "        for value in y_truth[i]:\n",
    "            hit_num += np.sum(pred[i]==value)\n",
    "    return hit_num\n",
    "\n",
    "def get_rr(pred,y_truth):\n",
    "    rr=0.\n",
    "    for i in range(len(y_truth)):\n",
    "        for value in y_truth[i]:\n",
    "            hit_indexes = np.where(pred[i]==value)[0]\n",
    "            for hit_index in hit_indexes:\n",
    "                rr += 1/(hit_index+1)\n",
    "    return rr\n",
    "\n",
    "def get_dcg(pred,y_truth):\n",
    "    y_pred_score = np.zeros_like(pred)\n",
    "\n",
    "    for i in range(len(y_truth)):\n",
    "\n",
    "        for j,y_pred in enumerate(pred[i]):\n",
    "            if y_pred == y_truth[i][0]:\n",
    "                y_pred_score[i][j]=1\n",
    "    gain = 2 ** y_pred_score - 1\n",
    "    discounts = np.tile(np.log2(np.arange(pred.shape[1]) + 2),(len(y_truth),1))\n",
    "    dcg = np.sum(gain / discounts,axis=1)\n",
    "    return dcg\n",
    "\n",
    "def get_ndcg(pred,y_truth):\n",
    "    dcg = get_dcg(pred, y_truth)\n",
    "    idcg = get_dcg(np.concatenate((y_truth,np.zeros_like(pred)[:,:-1]-1),axis=1), y_truth)\n",
    "    ndcg = np.sum(dcg / idcg)\n",
    "\n",
    "    return ndcg\n",
    "\n",
    "def dcg_score(y_pre, y_true, k):\n",
    "    y_pre_score = np.zeros(k)\n",
    "    if len(y_pre) > k:\n",
    "        y_pre = y_pre[:k]\n",
    "    for i in range(len(y_pre)):\n",
    "        pre_tag = y_pre[i]\n",
    "        if pre_tag in y_true:\n",
    "            y_pre_score[i] = 1\n",
    "    gain = 2 ** y_pre_score - 1\n",
    "    discounts = np.log2(np.arange(k) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_pre, y_true, k=5):\n",
    "    dcg = dcg_score(y_pre, y_true, k)\n",
    "    idcg = dcg_score(y_true, y_true, k)\n",
    "    return dcg / idcg\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:43:46.005881Z",
     "start_time": "2019-12-23T06:43:45.984834Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class NARM(torch.nn.Module):\n",
    "    def __init__(self, itemNum, hidden_size, embedding_dim, batch_size, layerNum = 1,padding_idx=0,posNum=11, dropout=0.5,embedding_dropout=0.25,activate=\"tanh\"):\n",
    "        super(NARM, self).__init__()\n",
    "        self.itemNum = itemNum\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.layerNum = layerNum\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.item_embedding = torch.nn.Embedding(itemNum, self.embedding_dim, padding_idx=padding_idx)\n",
    "        torch.nn.init.constant_(self.item_embedding.weight[0],0)\n",
    "        self.embedding_dropout = torch.nn.Dropout(embedding_dropout)\n",
    "        self.gru = torch.nn.GRU(self.embedding_dim, self.hidden_size, self.layerNum)\n",
    "        self.a_1 = torch.nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.a_2 = torch.nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.v_t = torch.nn.Linear(self.hidden_size, 1, bias=False)\n",
    "        self.ct_dropout = torch.nn.Dropout(dropout)\n",
    "        self.b = torch.nn.Linear(self.embedding_dim, 2 * self.hidden_size, bias=False)\n",
    "        #self.sf = torch.nn.Softmax()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def forward(self, seq, lengths):\n",
    "        seq = seq.t()\n",
    "        hidden = self.init_hidden(seq.size(1))\n",
    "        embs = self.embedding_dropout(self.item_embedding(seq))\n",
    "#         print(\"before\",embs.shape)\n",
    "        embs = pack_padded_sequence(embs, lengths)\n",
    "#         print(\"after\",embs.shape)\n",
    "        gru_out, hidden = self.gru(embs, hidden)\n",
    "\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)\n",
    "#         print(\"after aa\",gru_out,lengths)\n",
    "        # fetch the last hidden state of last timestamp\n",
    "        ht = hidden[-1]\n",
    "        gru_out = gru_out.permute(1, 0, 2)\n",
    "\n",
    "        c_global = ht\n",
    "        q1 = self.a_1(gru_out.contiguous().view(-1, self.hidden_size)).view(gru_out.size())  \n",
    "        q2 = self.a_2(ht)\n",
    "\n",
    "        mask = torch.where(seq.permute(1, 0) > 0, torch.tensor([1.], device = self.device), torch.tensor([0.], device = self.device))\n",
    "        q2_expand = q2.unsqueeze(1).expand_as(q1)\n",
    "        q2_masked = mask.unsqueeze(2).expand_as(q1) * q2_expand\n",
    "\n",
    "        alpha = self.v_t(torch.sigmoid(q1 + q2_masked).view(-1, self.hidden_size)).view(mask.size())\n",
    "        c_local = torch.sum(alpha.unsqueeze(2).expand_as(gru_out) * gru_out, 1)\n",
    "\n",
    "        c_t = torch.cat([c_local, c_global], 1)\n",
    "        c_t = self.ct_dropout(c_t)\n",
    "        \n",
    "        item_embs = self.item_embedding.weight[1:]\n",
    "        scores = torch.matmul(c_t, self.b(item_embs).permute(1, 0))\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros((self.layerNum, batch_size, self.hidden_size), requires_grad=True).to(self.device)\n",
    "    \n",
    "    def predict_top_k(self,seq, lengths, k=20):\n",
    "        seq = seq.t()\n",
    "        hidden = self.init_hidden(seq.size(1))\n",
    "        embs = self.item_embedding(seq)\n",
    "#         print(\"embs.shape\",embs.shape)\n",
    "        embs = pack_padded_sequence(embs, lengths)\n",
    "        gru_out, hidden = self.gru(embs, hidden)\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)\n",
    "\n",
    "        # fetch the last hidden state of last timestamp\n",
    "        ht = hidden[-1]\n",
    "        gru_out = gru_out.permute(1, 0, 2)\n",
    "\n",
    "        c_global = ht\n",
    "        q1 = self.a_1(gru_out.contiguous().view(-1, self.hidden_size)).view(gru_out.size())  \n",
    "        q2 = self.a_2(ht)\n",
    "\n",
    "        mask = torch.where(seq.permute(1, 0) > 0, torch.tensor([1.], device = self.device), torch.tensor([0.], device = self.device))\n",
    "        q2_expand = q2.unsqueeze(1).expand_as(q1)\n",
    "        q2_masked = mask.unsqueeze(2).expand_as(q1) * q2_expand\n",
    "\n",
    "        alpha = self.v_t(torch.sigmoid(q1 + q2_masked).view(-1, self.hidden_size)).view(mask.size())\n",
    "        c_local = torch.sum(alpha.unsqueeze(2).expand_as(gru_out) * gru_out, 1)\n",
    "\n",
    "        c_t = torch.cat([c_local, c_global], 1)\n",
    "#         c_t = self.ct_dropout(c_t)\n",
    "        \n",
    "        item_embs = self.item_embedding.weight[1:]\n",
    "        scores = torch.matmul(c_t, self.b(item_embs).permute(1, 0))\n",
    "        result = torch.topk(scores,k,dim=-1)[1]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIKM S >= 3   \n",
    "    HR@20=0.64254  MRR@20=0.29892，session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
    "        HR@1=0.18822  MRR@1=0.18822  NDCG@1=0.18822\n",
    "        HR@5=0.42851  MRR@5=0.27700  NDCG@5=0.31474\n",
    "        HR@10=0.53734  MRR@10=0.29158  NDCG@10=0.34999\n",
    "        HR@20=0.64254  MRR@20=0.29892  NDCG@20=0.37664\n",
    "# RR S >= 3   \n",
    "    HR@20=0.54229  MRR@20=0.28290，session_length=19, hidden_size=100, lr=0.0030, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
    "        HR@1=0.19700  MRR@1=0.19700  NDCG@1=0.19700\n",
    "        HR@5=0.38805  MRR@5=0.26708  NDCG@5=0.29718\n",
    "        HR@10=0.46808  MRR@10=0.27777  NDCG@10=0.32306\n",
    "        HR@20=0.54229  MRR@20=0.28290  NDCG@20=0.34180\n",
    "# RSC64 S >= 3   \n",
    "    HR@20=0.69574  MRR@20=0.27960，session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
    "        HR@1=0.14817  MRR@1=0.14817  NDCG@1=0.14817\n",
    "        HR@5=0.44086  MRR@5=0.25262  NDCG@5=0.29931\n",
    "        HR@10=0.58119  MRR@10=0.27152  NDCG@10=0.34486\n",
    "        HR@20=0.69574  MRR@20=0.27960  NDCG@20=0.37400\n",
    "# RSC4 S >= 3   \n",
    "    HR@20=0.71441  MRR@20=0.28263，session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
    "        HR@1=0.14575  MRR@1=0.14575  NDCG@1=0.14575\n",
    "        HR@5=0.45036  MRR@5=0.25469  NDCG@5=0.30324\n",
    "        HR@10=0.59594  MRR@10=0.27422  NDCG@10=0.35042\n",
    "        HR@20=0.71441  MRR@20=0.28263  NDCG@20=0.38060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:43:46.019568Z",
     "start_time": "2019-12-23T06:43:46.007129Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs=50\n",
    "def train(args):\n",
    "    hidden_size = args[\"hidden_size\"] if \"hidden_size\" in args.keys() else 100\n",
    "    embedding_dim = args[\"embedding_dim\"] if \"hidden_size\" in args.keys() else 100\n",
    "    dropout = args[\"dropout\"] if \"dropout\" in args.keys()  else 0.5\n",
    "    embedding_dropout = args[\"embedding_dropout\"] if \"dropout\" in args.keys()  else 0.5\n",
    "    lr = args[\"lr\"] if \"lr\" in args.keys()  else 1e-3\n",
    "    session_length = args[\"session_length\"] if \"session_length\" in args.keys() else 20\n",
    "    model = NARM(hidden_size=hidden_size, embedding_dim=embedding_dim,itemNum=dataset.index_count+1, batch_size=batch_size,posNum=session_length+1, padding_idx=0, dropout=dropout,embedding_dropout=embedding_dropout).to(device)\n",
    "    opti = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    best_model_hr = 0.0\n",
    "    best_model_mrr = 0.0\n",
    "    best_r1m = 0.0\n",
    "    best_model = None\n",
    "    first_loss = 0.0\n",
    "    predict_nums = [1,5,10,20]\n",
    "    for epoch in range(epochs):\n",
    "        batch_losses = []\n",
    "        epoch_losses = []\n",
    "        for i,batch_data in enumerate(dataset.get_batch(batch_size,session_length,phase=\"train\")):\n",
    "            sessions = torch.tensor(batch_data[0]).to(device)\n",
    "            target_items = torch.tensor(batch_data[1]).squeeze().to(device)-1\n",
    "            result_pos = model(sessions,torch.tensor(session_length).unsqueeze(0).repeat(target_items.shape[0]))\n",
    "            loss = loss_function(result_pos,target_items)\n",
    "            opti.zero_grad()\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "            batch_losses.append(loss.cpu().detach().numpy())\n",
    "            epoch_losses.append(loss.cpu().detach().numpy())\n",
    "            if i % plot_num == 0:\n",
    "                time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                print(\"[%s] [%d/%d] %d mean_batch_loss : %0.6f\" % (time, epoch+1, epochs, i, np.mean(batch_losses)))\n",
    "                batch_losses = []\n",
    "        with torch.no_grad():\n",
    "            start_test_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(\"Start predicting\",start_test_time)\n",
    "            rrs = [0 for _ in range(len(predict_nums))]\n",
    "            hit_nums = [0 for _ in range(len(predict_nums))]\n",
    "            ndcgs = [0 for _ in range(len(predict_nums))]\n",
    "            for i,batch_data in enumerate(dataset.get_batch(batch_size,session_length,phase=\"test\")):\n",
    "                sessions = torch.tensor(batch_data[0]).to(device)\n",
    "                target_items = np.array(batch_data[1])-1\n",
    "                y_pred = model.predict_top_k(sessions,torch.tensor(session_length).unsqueeze(0).repeat(target_items.shape[0]),20).cpu().numpy()\n",
    "#                 print(y_pred[:2],target_items[:2])\n",
    "                \n",
    "                for j,predict_num in enumerate(predict_nums):\n",
    "                    hit_nums[j]+=get_hit_num(y_pred[:,:predict_num],target_items)\n",
    "                    rrs[j]+=get_rr(y_pred[:,:predict_num],target_items)\n",
    "                    ndcgs[j]+=get_ndcg(y_pred[:,:predict_num],target_items)\n",
    "                    \n",
    "            end_test_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            hrs = [hit_num/len(dataset.all_testing_data) for hit_num in hit_nums]\n",
    "            mrrs = [rr/len(dataset.all_testing_data) for rr in rrs]\n",
    "            mndcgs = [ndcg/len(dataset.all_testing_data) for ndcg in ndcgs]\n",
    "            if hrs[-1] + mrrs[-1] > best_r1m:\n",
    "                print(\"change best\")\n",
    "                best_model = deepcopy(model)\n",
    "                best_model_hr = hrs[-1]\n",
    "                best_model_mrr = mrrs[-1]\n",
    "                best_r1m = hrs[-1] + mrrs[-1]\n",
    "                no_improvement_epoch = 0\n",
    "            else:\n",
    "                no_improvement_epoch +=1\n",
    "            print(\"testing finish [%s] \"%end_test_time)\n",
    "            for k,predict_num in enumerate(predict_nums):\n",
    "                print(\"\\tHR@%d=%.5f  MRR@%d=%.5f  NDCG@%d=%.5f\"%(predict_num,hrs[k],predict_num,mrrs[k],predict_num,mndcgs[k]))\n",
    "        if no_improvement_epoch>=patience:\n",
    "            print(\"early stopping\")\n",
    "            break\n",
    "    return best_model,best_model_hr,best_model_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T07:03:43.115846Z",
     "start_time": "2019-12-23T06:43:46.020662Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "Start building the all training dataset\n",
      "The total number of training samples is： (245270, 20)\n",
      "[2019-12-23 14:43:51] [1/50] 0 mean_batch_loss : 15.602084\n",
      "Start predicting 2019-12-23 14:43:57\n",
      "The total number of testing samples is： (40548, 20)\n",
      "change best\n",
      "testing finish [2019-12-23 14:44:00] \n",
      "\tHR@1=0.10013  MRR@1=0.10013  NDCG@1=0.10013\n",
      "\tHR@5=0.24351  MRR@5=0.15175  NDCG@5=0.17452\n",
      "\tHR@10=0.30633  MRR@10=0.16023  NDCG@10=0.19493\n",
      "\tHR@20=0.36643  MRR@20=0.16439  NDCG@20=0.21012\n",
      "[2019-12-23 14:44:00] [2/50] 0 mean_batch_loss : 7.385964\n",
      "Start predicting 2019-12-23 14:44:06\n",
      "change best\n",
      "testing finish [2019-12-23 14:44:08] \n",
      "\tHR@1=0.10780  MRR@1=0.10780  NDCG@1=0.10780\n",
      "\tHR@5=0.29121  MRR@5=0.17406  NDCG@5=0.20315\n",
      "\tHR@10=0.38448  MRR@10=0.18662  NDCG@10=0.23343\n",
      "\tHR@20=0.47443  MRR@20=0.19285  NDCG@20=0.25615\n",
      "[2019-12-23 14:44:09] [3/50] 0 mean_batch_loss : 6.475377\n",
      "Start predicting 2019-12-23 14:44:14\n",
      "change best\n",
      "testing finish [2019-12-23 14:44:17] \n",
      "\tHR@1=0.11433  MRR@1=0.11433  NDCG@1=0.11433\n",
      "\tHR@5=0.31706  MRR@5=0.18706  NDCG@5=0.21932\n",
      "\tHR@10=0.41881  MRR@10=0.20074  NDCG@10=0.25232\n",
      "\tHR@20=0.51919  MRR@20=0.20773  NDCG@20=0.27774\n",
      "[2019-12-23 14:44:17] [4/50] 0 mean_batch_loss : 6.387411\n",
      "Start predicting 2019-12-23 14:44:23\n",
      "change best\n",
      "testing finish [2019-12-23 14:44:26] \n",
      "\tHR@1=0.11749  MRR@1=0.11749  NDCG@1=0.11749\n",
      "\tHR@5=0.33242  MRR@5=0.19390  NDCG@5=0.22823\n",
      "\tHR@10=0.44508  MRR@10=0.20899  NDCG@10=0.26471\n",
      "\tHR@20=0.54535  MRR@20=0.21599  NDCG@20=0.29012\n",
      "[2019-12-23 14:44:26] [5/50] 0 mean_batch_loss : 5.830817\n",
      "Start predicting 2019-12-23 14:44:32\n",
      "change best\n",
      "testing finish [2019-12-23 14:44:35] \n",
      "\tHR@1=0.12183  MRR@1=0.12183  NDCG@1=0.12183\n",
      "\tHR@5=0.35013  MRR@5=0.20400  NDCG@5=0.24028\n",
      "\tHR@10=0.46861  MRR@10=0.21993  NDCG@10=0.27871\n",
      "\tHR@20=0.57145  MRR@20=0.22710  NDCG@20=0.30476\n",
      "[2019-12-23 14:44:35] [6/50] 0 mean_batch_loss : 6.089738\n",
      "Start predicting 2019-12-23 14:44:41\n",
      "change best\n",
      "testing finish [2019-12-23 14:44:44] \n",
      "\tHR@1=0.12267  MRR@1=0.12267  NDCG@1=0.12267\n",
      "\tHR@5=0.35933  MRR@5=0.20750  NDCG@5=0.24517\n",
      "\tHR@10=0.48103  MRR@10=0.22380  NDCG@10=0.28458\n",
      "\tHR@20=0.58420  MRR@20=0.23105  NDCG@20=0.31078\n",
      "[2019-12-23 14:44:44] [7/50] 0 mean_batch_loss : 5.520948\n",
      "Start predicting 2019-12-23 14:44:50\n",
      "change best\n",
      "testing finish [2019-12-23 14:44:53] \n",
      "\tHR@1=0.12336  MRR@1=0.12336  NDCG@1=0.12336\n",
      "\tHR@5=0.36584  MRR@5=0.20993  NDCG@5=0.24860\n",
      "\tHR@10=0.48895  MRR@10=0.22639  NDCG@10=0.28844\n",
      "\tHR@20=0.59756  MRR@20=0.23403  NDCG@20=0.31602\n",
      "[2019-12-23 14:44:53] [8/50] 0 mean_batch_loss : 5.597782\n",
      "Start predicting 2019-12-23 14:44:59\n",
      "change best\n",
      "testing finish [2019-12-23 14:45:02] \n",
      "\tHR@1=0.12765  MRR@1=0.12765  NDCG@1=0.12765\n",
      "\tHR@5=0.37388  MRR@5=0.21552  NDCG@5=0.25480\n",
      "\tHR@10=0.50010  MRR@10=0.23238  NDCG@10=0.29563\n",
      "\tHR@20=0.60997  MRR@20=0.24012  NDCG@20=0.32355\n",
      "[2019-12-23 14:45:02] [9/50] 0 mean_batch_loss : 5.416670\n",
      "Start predicting 2019-12-23 14:45:07\n",
      "change best\n",
      "testing finish [2019-12-23 14:45:10] \n",
      "\tHR@1=0.13125  MRR@1=0.13125  NDCG@1=0.13125\n",
      "\tHR@5=0.38628  MRR@5=0.22289  NDCG@5=0.26344\n",
      "\tHR@10=0.51280  MRR@10=0.23983  NDCG@10=0.30442\n",
      "\tHR@20=0.62166  MRR@20=0.24752  NDCG@20=0.33211\n",
      "[2019-12-23 14:45:10] [10/50] 0 mean_batch_loss : 5.260067\n",
      "Start predicting 2019-12-23 14:45:16\n",
      "change best\n",
      "testing finish [2019-12-23 14:45:19] \n",
      "\tHR@1=0.13073  MRR@1=0.13073  NDCG@1=0.13073\n",
      "\tHR@5=0.38488  MRR@5=0.22126  NDCG@5=0.26182\n",
      "\tHR@10=0.51776  MRR@10=0.23907  NDCG@10=0.30487\n",
      "\tHR@20=0.62893  MRR@20=0.24689  NDCG@20=0.33311\n",
      "[2019-12-23 14:45:19] [11/50] 0 mean_batch_loss : 5.176062\n",
      "Start predicting 2019-12-23 14:45:25\n",
      "change best\n",
      "testing finish [2019-12-23 14:45:28] \n",
      "\tHR@1=0.13475  MRR@1=0.13475  NDCG@1=0.13475\n",
      "\tHR@5=0.39773  MRR@5=0.22912  NDCG@5=0.27096\n",
      "\tHR@10=0.53147  MRR@10=0.24709  NDCG@10=0.31433\n",
      "\tHR@20=0.63974  MRR@20=0.25471  NDCG@20=0.34184\n",
      "[2019-12-23 14:45:28] [12/50] 0 mean_batch_loss : 5.208612\n",
      "Start predicting 2019-12-23 14:45:33\n",
      "change best\n",
      "testing finish [2019-12-23 14:45:36] \n",
      "\tHR@1=0.13448  MRR@1=0.13448  NDCG@1=0.13448\n",
      "\tHR@5=0.40197  MRR@5=0.22971  NDCG@5=0.27242\n",
      "\tHR@10=0.53655  MRR@10=0.24780  NDCG@10=0.31608\n",
      "\tHR@20=0.64417  MRR@20=0.25539  NDCG@20=0.34343\n",
      "[2019-12-23 14:45:36] [13/50] 0 mean_batch_loss : 5.121971\n",
      "Start predicting 2019-12-23 14:45:42\n",
      "change best\n",
      "testing finish [2019-12-23 14:45:45] \n",
      "\tHR@1=0.13707  MRR@1=0.13707  NDCG@1=0.13707\n",
      "\tHR@5=0.40271  MRR@5=0.23218  NDCG@5=0.27449\n",
      "\tHR@10=0.53692  MRR@10=0.25016  NDCG@10=0.31795\n",
      "\tHR@20=0.64891  MRR@20=0.25806  NDCG@20=0.34644\n",
      "[2019-12-23 14:45:45] [14/50] 0 mean_batch_loss : 4.881684\n",
      "Start predicting 2019-12-23 14:45:51\n",
      "change best\n",
      "testing finish [2019-12-23 14:45:54] \n",
      "\tHR@1=0.13791  MRR@1=0.13791  NDCG@1=0.13791\n",
      "\tHR@5=0.40900  MRR@5=0.23445  NDCG@5=0.27772\n",
      "\tHR@10=0.54296  MRR@10=0.25247  NDCG@10=0.32119\n",
      "\tHR@20=0.65525  MRR@20=0.26039  NDCG@20=0.34973\n",
      "[2019-12-23 14:45:54] [15/50] 0 mean_batch_loss : 4.968803\n",
      "Start predicting 2019-12-23 14:46:00\n",
      "change best\n",
      "testing finish [2019-12-23 14:46:03] \n",
      "\tHR@1=0.13971  MRR@1=0.13971  NDCG@1=0.13971\n",
      "\tHR@5=0.40966  MRR@5=0.23563  NDCG@5=0.27877\n",
      "\tHR@10=0.54523  MRR@10=0.25382  NDCG@10=0.32271\n",
      "\tHR@20=0.65621  MRR@20=0.26167  NDCG@20=0.35095\n",
      "[2019-12-23 14:46:03] [16/50] 0 mean_batch_loss : 4.876219\n",
      "Start predicting 2019-12-23 14:46:09\n",
      "change best\n",
      "testing finish [2019-12-23 14:46:12] \n",
      "\tHR@1=0.13942  MRR@1=0.13942  NDCG@1=0.13942\n",
      "\tHR@5=0.41383  MRR@5=0.23744  NDCG@5=0.28119\n",
      "\tHR@10=0.54930  MRR@10=0.25562  NDCG@10=0.32510\n",
      "\tHR@20=0.66201  MRR@20=0.26356  NDCG@20=0.35375\n",
      "[2019-12-23 14:46:12] [17/50] 0 mean_batch_loss : 4.855543\n",
      "Start predicting 2019-12-23 14:46:18\n",
      "testing finish [2019-12-23 14:46:21] \n",
      "\tHR@1=0.13951  MRR@1=0.13951  NDCG@1=0.13951\n",
      "\tHR@5=0.40949  MRR@5=0.23522  NDCG@5=0.27841\n",
      "\tHR@10=0.54698  MRR@10=0.25372  NDCG@10=0.32302\n",
      "\tHR@20=0.66117  MRR@20=0.26174  NDCG@20=0.35202\n",
      "[2019-12-23 14:46:21] [18/50] 0 mean_batch_loss : 4.760386\n",
      "Start predicting 2019-12-23 14:46:27\n",
      "change best\n",
      "testing finish [2019-12-23 14:46:30] \n",
      "\tHR@1=0.14109  MRR@1=0.14109  NDCG@1=0.14109\n",
      "\tHR@5=0.41657  MRR@5=0.23918  NDCG@5=0.28316\n",
      "\tHR@10=0.55593  MRR@10=0.25788  NDCG@10=0.32833\n",
      "\tHR@20=0.66802  MRR@20=0.26578  NDCG@20=0.35682\n",
      "[2019-12-23 14:46:30] [19/50] 0 mean_batch_loss : 4.655862\n",
      "Start predicting 2019-12-23 14:46:36\n",
      "change best\n",
      "testing finish [2019-12-23 14:46:38] \n",
      "\tHR@1=0.14146  MRR@1=0.14146  NDCG@1=0.14146\n",
      "\tHR@5=0.41802  MRR@5=0.24021  NDCG@5=0.28431\n",
      "\tHR@10=0.55510  MRR@10=0.25856  NDCG@10=0.32869\n",
      "\tHR@20=0.66829  MRR@20=0.26651  NDCG@20=0.35743\n",
      "[2019-12-23 14:46:38] [20/50] 0 mean_batch_loss : 4.489861\n",
      "Start predicting 2019-12-23 14:46:44\n",
      "change best\n",
      "testing finish [2019-12-23 14:46:47] \n",
      "\tHR@1=0.14403  MRR@1=0.14403  NDCG@1=0.14403\n",
      "\tHR@5=0.42046  MRR@5=0.24211  NDCG@5=0.28630\n",
      "\tHR@10=0.55830  MRR@10=0.26058  NDCG@10=0.33096\n",
      "\tHR@20=0.67101  MRR@20=0.26850  NDCG@20=0.35958\n",
      "[2019-12-23 14:46:47] [21/50] 0 mean_batch_loss : 4.801312\n",
      "Start predicting 2019-12-23 14:46:53\n",
      "change best\n",
      "testing finish [2019-12-23 14:46:56] \n",
      "\tHR@1=0.14112  MRR@1=0.14112  NDCG@1=0.14112\n",
      "\tHR@5=0.41681  MRR@5=0.23932  NDCG@5=0.28334\n",
      "\tHR@10=0.56148  MRR@10=0.25871  NDCG@10=0.33020\n",
      "\tHR@20=0.67379  MRR@20=0.26660  NDCG@20=0.35872\n",
      "[2019-12-23 14:46:56] [22/50] 0 mean_batch_loss : 4.391238\n",
      "Start predicting 2019-12-23 14:47:02\n",
      "change best\n",
      "testing finish [2019-12-23 14:47:05] \n",
      "\tHR@1=0.14171  MRR@1=0.14171  NDCG@1=0.14171\n",
      "\tHR@5=0.42291  MRR@5=0.24222  NDCG@5=0.28705\n",
      "\tHR@10=0.56254  MRR@10=0.26096  NDCG@10=0.33230\n",
      "\tHR@20=0.67557  MRR@20=0.26891  NDCG@20=0.36102\n",
      "[2019-12-23 14:47:05] [23/50] 0 mean_batch_loss : 4.625549\n",
      "Start predicting 2019-12-23 14:47:11\n",
      "change best\n",
      "testing finish [2019-12-23 14:47:14] \n",
      "\tHR@1=0.14319  MRR@1=0.14319  NDCG@1=0.14319\n",
      "\tHR@5=0.42461  MRR@5=0.24346  NDCG@5=0.28837\n",
      "\tHR@10=0.56558  MRR@10=0.26231  NDCG@10=0.33400\n",
      "\tHR@20=0.67821  MRR@20=0.27025  NDCG@20=0.36263\n",
      "[2019-12-23 14:47:14] [24/50] 0 mean_batch_loss : 4.360841\n",
      "Start predicting 2019-12-23 14:47:20\n",
      "testing finish [2019-12-23 14:47:23] \n",
      "\tHR@1=0.14245  MRR@1=0.14245  NDCG@1=0.14245\n",
      "\tHR@5=0.42088  MRR@5=0.24114  NDCG@5=0.28568\n",
      "\tHR@10=0.56153  MRR@10=0.26004  NDCG@10=0.33129\n",
      "\tHR@20=0.67710  MRR@20=0.26816  NDCG@20=0.36063\n",
      "[2019-12-23 14:47:23] [25/50] 0 mean_batch_loss : 4.753301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 14:47:29\n",
      "change best\n",
      "testing finish [2019-12-23 14:47:32] \n",
      "\tHR@1=0.14459  MRR@1=0.14459  NDCG@1=0.14459\n",
      "\tHR@5=0.43240  MRR@5=0.24713  NDCG@5=0.29308\n",
      "\tHR@10=0.57113  MRR@10=0.26567  NDCG@10=0.33798\n",
      "\tHR@20=0.68341  MRR@20=0.27363  NDCG@20=0.36657\n",
      "[2019-12-23 14:47:32] [26/50] 0 mean_batch_loss : 4.734376\n",
      "Start predicting 2019-12-23 14:47:38\n",
      "testing finish [2019-12-23 14:47:41] \n",
      "\tHR@1=0.14464  MRR@1=0.14464  NDCG@1=0.14464\n",
      "\tHR@5=0.42737  MRR@5=0.24481  NDCG@5=0.29005\n",
      "\tHR@10=0.56743  MRR@10=0.26357  NDCG@10=0.33541\n",
      "\tHR@20=0.68104  MRR@20=0.27157  NDCG@20=0.36428\n",
      "[2019-12-23 14:47:41] [27/50] 0 mean_batch_loss : 4.317061\n",
      "Start predicting 2019-12-23 14:47:46\n",
      "testing finish [2019-12-23 14:47:49] \n",
      "\tHR@1=0.14250  MRR@1=0.14250  NDCG@1=0.14250\n",
      "\tHR@5=0.42821  MRR@5=0.24447  NDCG@5=0.29004\n",
      "\tHR@10=0.56767  MRR@10=0.26321  NDCG@10=0.33527\n",
      "\tHR@20=0.68437  MRR@20=0.27142  NDCG@20=0.36491\n",
      "[2019-12-23 14:47:49] [28/50] 0 mean_batch_loss : 4.598503\n",
      "Start predicting 2019-12-23 14:47:55\n",
      "testing finish [2019-12-23 14:47:58] \n",
      "\tHR@1=0.14329  MRR@1=0.14329  NDCG@1=0.14329\n",
      "\tHR@5=0.42833  MRR@5=0.24506  NDCG@5=0.29053\n",
      "\tHR@10=0.56666  MRR@10=0.26363  NDCG@10=0.33537\n",
      "\tHR@20=0.68285  MRR@20=0.27181  NDCG@20=0.36490\n",
      "[2019-12-23 14:47:58] [29/50] 0 mean_batch_loss : 4.282199\n",
      "Start predicting 2019-12-23 14:48:04\n",
      "change best\n",
      "testing finish [2019-12-23 14:48:07] \n",
      "\tHR@1=0.14701  MRR@1=0.14701  NDCG@1=0.14701\n",
      "\tHR@5=0.43270  MRR@5=0.24797  NDCG@5=0.29374\n",
      "\tHR@10=0.57063  MRR@10=0.26650  NDCG@10=0.33846\n",
      "\tHR@20=0.68391  MRR@20=0.27448  NDCG@20=0.36725\n",
      "[2019-12-23 14:48:07] [30/50] 0 mean_batch_loss : 4.548561\n",
      "Start predicting 2019-12-23 14:48:13\n",
      "testing finish [2019-12-23 14:48:16] \n",
      "\tHR@1=0.14270  MRR@1=0.14270  NDCG@1=0.14270\n",
      "\tHR@5=0.42513  MRR@5=0.24310  NDCG@5=0.28823\n",
      "\tHR@10=0.56733  MRR@10=0.26220  NDCG@10=0.33434\n",
      "\tHR@20=0.68321  MRR@20=0.27036  NDCG@20=0.36378\n",
      "[2019-12-23 14:48:16] [31/50] 0 mean_batch_loss : 4.223788\n",
      "Start predicting 2019-12-23 14:48:22\n",
      "testing finish [2019-12-23 14:48:25] \n",
      "\tHR@1=0.14393  MRR@1=0.14393  NDCG@1=0.14393\n",
      "\tHR@5=0.42594  MRR@5=0.24425  NDCG@5=0.28930\n",
      "\tHR@10=0.56900  MRR@10=0.26339  NDCG@10=0.33561\n",
      "\tHR@20=0.68428  MRR@20=0.27152  NDCG@20=0.36491\n",
      "[2019-12-23 14:48:25] [32/50] 0 mean_batch_loss : 4.658972\n",
      "Start predicting 2019-12-23 14:48:31\n",
      "testing finish [2019-12-23 14:48:33] \n",
      "\tHR@1=0.14437  MRR@1=0.14437  NDCG@1=0.14437\n",
      "\tHR@5=0.42577  MRR@5=0.24383  NDCG@5=0.28891\n",
      "\tHR@10=0.56718  MRR@10=0.26285  NDCG@10=0.33478\n",
      "\tHR@20=0.68477  MRR@20=0.27113  NDCG@20=0.36466\n",
      "[2019-12-23 14:48:33] [33/50] 0 mean_batch_loss : 4.149910\n",
      "Start predicting 2019-12-23 14:48:39\n",
      "change best\n",
      "testing finish [2019-12-23 14:48:42] \n",
      "\tHR@1=0.14637  MRR@1=0.14637  NDCG@1=0.14637\n",
      "\tHR@5=0.43087  MRR@5=0.24720  NDCG@5=0.29272\n",
      "\tHR@10=0.57302  MRR@10=0.26630  NDCG@10=0.33882\n",
      "\tHR@20=0.68790  MRR@20=0.27438  NDCG@20=0.36800\n",
      "[2019-12-23 14:48:42] [34/50] 0 mean_batch_loss : 4.246517\n",
      "Start predicting 2019-12-23 14:48:47\n",
      "change best\n",
      "testing finish [2019-12-23 14:48:50] \n",
      "\tHR@1=0.14351  MRR@1=0.14351  NDCG@1=0.14351\n",
      "\tHR@5=0.43329  MRR@5=0.24690  NDCG@5=0.29313\n",
      "\tHR@10=0.57233  MRR@10=0.26557  NDCG@10=0.33820\n",
      "\tHR@20=0.68884  MRR@20=0.27380  NDCG@20=0.36785\n",
      "[2019-12-23 14:48:50] [35/50] 0 mean_batch_loss : 4.251612\n",
      "Start predicting 2019-12-23 14:48:56\n",
      "change best\n",
      "testing finish [2019-12-23 14:48:59] \n",
      "\tHR@1=0.14706  MRR@1=0.14706  NDCG@1=0.14706\n",
      "\tHR@5=0.43543  MRR@5=0.24975  NDCG@5=0.29580\n",
      "\tHR@10=0.57687  MRR@10=0.26872  NDCG@10=0.34163\n",
      "\tHR@20=0.68916  MRR@20=0.27663  NDCG@20=0.37017\n",
      "[2019-12-23 14:48:59] [36/50] 0 mean_batch_loss : 4.152072\n",
      "Start predicting 2019-12-23 14:49:05\n",
      "testing finish [2019-12-23 14:49:08] \n",
      "\tHR@1=0.14267  MRR@1=0.14267  NDCG@1=0.14267\n",
      "\tHR@5=0.42979  MRR@5=0.24465  NDCG@5=0.29054\n",
      "\tHR@10=0.57253  MRR@10=0.26384  NDCG@10=0.33684\n",
      "\tHR@20=0.68788  MRR@20=0.27199  NDCG@20=0.36618\n",
      "[2019-12-23 14:49:08] [37/50] 0 mean_batch_loss : 4.311244\n",
      "Start predicting 2019-12-23 14:49:14\n",
      "change best\n",
      "testing finish [2019-12-23 14:49:17] \n",
      "\tHR@1=0.14856  MRR@1=0.14856  NDCG@1=0.14856\n",
      "\tHR@5=0.44061  MRR@5=0.25273  NDCG@5=0.29933\n",
      "\tHR@10=0.57986  MRR@10=0.27145  NDCG@10=0.34449\n",
      "\tHR@20=0.69190  MRR@20=0.27933  NDCG@20=0.37295\n",
      "[2019-12-23 14:49:17] [38/50] 0 mean_batch_loss : 4.398051\n",
      "Start predicting 2019-12-23 14:49:23\n",
      "testing finish [2019-12-23 14:49:26] \n",
      "\tHR@1=0.14528  MRR@1=0.14528  NDCG@1=0.14528\n",
      "\tHR@5=0.43650  MRR@5=0.24902  NDCG@5=0.29551\n",
      "\tHR@10=0.57663  MRR@10=0.26783  NDCG@10=0.34094\n",
      "\tHR@20=0.69199  MRR@20=0.27596  NDCG@20=0.37026\n",
      "[2019-12-23 14:49:26] [39/50] 0 mean_batch_loss : 4.265167\n",
      "Start predicting 2019-12-23 14:49:32\n",
      "testing finish [2019-12-23 14:49:35] \n",
      "\tHR@1=0.14324  MRR@1=0.14324  NDCG@1=0.14324\n",
      "\tHR@5=0.43346  MRR@5=0.24634  NDCG@5=0.29272\n",
      "\tHR@10=0.57280  MRR@10=0.26506  NDCG@10=0.33791\n",
      "\tHR@20=0.69101  MRR@20=0.27344  NDCG@20=0.36802\n",
      "[2019-12-23 14:49:35] [40/50] 0 mean_batch_loss : 4.152765\n",
      "Start predicting 2019-12-23 14:49:41\n",
      "testing finish [2019-12-23 14:49:44] \n",
      "\tHR@1=0.14696  MRR@1=0.14696  NDCG@1=0.14696\n",
      "\tHR@5=0.43442  MRR@5=0.24958  NDCG@5=0.29544\n",
      "\tHR@10=0.57852  MRR@10=0.26891  NDCG@10=0.34214\n",
      "\tHR@20=0.69380  MRR@20=0.27704  NDCG@20=0.37145\n",
      "[2019-12-23 14:49:44] [41/50] 0 mean_batch_loss : 4.155554\n",
      "Start predicting 2019-12-23 14:49:50\n",
      "testing finish [2019-12-23 14:49:52] \n",
      "\tHR@1=0.14388  MRR@1=0.14388  NDCG@1=0.14388\n",
      "\tHR@5=0.42969  MRR@5=0.24545  NDCG@5=0.29113\n",
      "\tHR@10=0.57372  MRR@10=0.26484  NDCG@10=0.33788\n",
      "\tHR@20=0.69005  MRR@20=0.27309  NDCG@20=0.36750\n",
      "[2019-12-23 14:49:53] [42/50] 0 mean_batch_loss : 4.247988\n",
      "Start predicting 2019-12-23 14:49:58\n",
      "change best\n",
      "testing finish [2019-12-23 14:50:01] \n",
      "\tHR@1=0.14854  MRR@1=0.14854  NDCG@1=0.14854\n",
      "\tHR@5=0.43585  MRR@5=0.25130  NDCG@5=0.29709\n",
      "\tHR@10=0.58163  MRR@10=0.27086  NDCG@10=0.34434\n",
      "\tHR@20=0.69375  MRR@20=0.27877  NDCG@20=0.37284\n",
      "[2019-12-23 14:50:01] [43/50] 0 mean_batch_loss : 4.187042\n",
      "Start predicting 2019-12-23 14:50:07\n",
      "testing finish [2019-12-23 14:50:10] \n",
      "\tHR@1=0.14815  MRR@1=0.14815  NDCG@1=0.14815\n",
      "\tHR@5=0.43580  MRR@5=0.25085  NDCG@5=0.29672\n",
      "\tHR@10=0.57880  MRR@10=0.27004  NDCG@10=0.34306\n",
      "\tHR@20=0.69310  MRR@20=0.27808  NDCG@20=0.37210\n",
      "[2019-12-23 14:50:10] [44/50] 0 mean_batch_loss : 4.271257\n",
      "Start predicting 2019-12-23 14:50:16\n",
      "testing finish [2019-12-23 14:50:19] \n",
      "\tHR@1=0.14548  MRR@1=0.14548  NDCG@1=0.14548\n",
      "\tHR@5=0.42902  MRR@5=0.24572  NDCG@5=0.29113\n",
      "\tHR@10=0.57174  MRR@10=0.26490  NDCG@10=0.33742\n",
      "\tHR@20=0.68867  MRR@20=0.27314  NDCG@20=0.36714\n",
      "[2019-12-23 14:50:19] [45/50] 0 mean_batch_loss : 4.256121\n",
      "Start predicting 2019-12-23 14:50:25\n",
      "testing finish [2019-12-23 14:50:28] \n",
      "\tHR@1=0.14738  MRR@1=0.14738  NDCG@1=0.14738\n",
      "\tHR@5=0.43768  MRR@5=0.25042  NDCG@5=0.29684\n",
      "\tHR@10=0.58065  MRR@10=0.26961  NDCG@10=0.34318\n",
      "\tHR@20=0.69269  MRR@20=0.27751  NDCG@20=0.37165\n",
      "[2019-12-23 14:50:28] [46/50] 0 mean_batch_loss : 4.347242\n",
      "Start predicting 2019-12-23 14:50:34\n",
      "testing finish [2019-12-23 14:50:37] \n",
      "\tHR@1=0.14487  MRR@1=0.14487  NDCG@1=0.14487\n",
      "\tHR@5=0.43753  MRR@5=0.24950  NDCG@5=0.29615\n",
      "\tHR@10=0.57949  MRR@10=0.26850  NDCG@10=0.34212\n",
      "\tHR@20=0.69239  MRR@20=0.27648  NDCG@20=0.37085\n",
      "[2019-12-23 14:50:37] [47/50] 0 mean_batch_loss : 4.262711\n",
      "Start predicting 2019-12-23 14:50:43\n",
      "testing finish [2019-12-23 14:50:46] \n",
      "\tHR@1=0.14694  MRR@1=0.14694  NDCG@1=0.14694\n",
      "\tHR@5=0.43936  MRR@5=0.25067  NDCG@5=0.29744\n",
      "\tHR@10=0.57813  MRR@10=0.26925  NDCG@10=0.34237\n",
      "\tHR@20=0.69244  MRR@20=0.27730  NDCG@20=0.37142\n",
      "[2019-12-23 14:50:46] [48/50] 0 mean_batch_loss : 4.087535\n",
      "Start predicting 2019-12-23 14:50:52\n",
      "change best\n",
      "testing finish [2019-12-23 14:50:55] \n",
      "\tHR@1=0.14876  MRR@1=0.14876  NDCG@1=0.14876\n",
      "\tHR@5=0.43921  MRR@5=0.25204  NDCG@5=0.29844\n",
      "\tHR@10=0.58198  MRR@10=0.27124  NDCG@10=0.34476\n",
      "\tHR@20=0.69513  MRR@20=0.27922  NDCG@20=0.37352\n",
      "[2019-12-23 14:50:55] [49/50] 0 mean_batch_loss : 4.190902\n",
      "Start predicting 2019-12-23 14:51:01\n",
      "testing finish [2019-12-23 14:51:04] \n",
      "\tHR@1=0.14837  MRR@1=0.14837  NDCG@1=0.14837\n",
      "\tHR@5=0.43341  MRR@5=0.24973  NDCG@5=0.29527\n",
      "\tHR@10=0.57663  MRR@10=0.26901  NDCG@10=0.34175\n",
      "\tHR@20=0.69259  MRR@20=0.27716  NDCG@20=0.37119\n",
      "[2019-12-23 14:51:04] [50/50] 0 mean_batch_loss : 3.999040\n",
      "Start predicting 2019-12-23 14:51:10\n",
      "testing finish [2019-12-23 14:51:13] \n",
      "\tHR@1=0.14723  MRR@1=0.14723  NDCG@1=0.14723\n",
      "\tHR@5=0.43802  MRR@5=0.25097  NDCG@5=0.29737\n",
      "\tHR@10=0.58180  MRR@10=0.27027  NDCG@10=0.34396\n",
      "\tHR@20=0.69421  MRR@20=0.27821  NDCG@20=0.37257\n",
      "best model change\n",
      "current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "current model HR@20=0.69513  MRR@20=0.27922\n",
      "the best result so far. HR@20=0.69513  MRR@20=0.27922，其参数current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      " \n",
      "\n",
      "current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0030, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "[2019-12-23 14:51:13] [1/50] 0 mean_batch_loss : 18.676559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 14:51:19\n",
      "change best\n",
      "testing finish [2019-12-23 14:51:22] \n",
      "\tHR@1=0.10696  MRR@1=0.10696  NDCG@1=0.10696\n",
      "\tHR@5=0.29188  MRR@5=0.17335  NDCG@5=0.20277\n",
      "\tHR@10=0.38981  MRR@10=0.18648  NDCG@10=0.23449\n",
      "\tHR@20=0.48779  MRR@20=0.19333  NDCG@20=0.25933\n",
      "[2019-12-23 14:51:22] [2/50] 0 mean_batch_loss : 6.530899\n",
      "Start predicting 2019-12-23 14:51:28\n",
      "change best\n",
      "testing finish [2019-12-23 14:51:30] \n",
      "\tHR@1=0.12223  MRR@1=0.12223  NDCG@1=0.12223\n",
      "\tHR@5=0.34258  MRR@5=0.20081  NDCG@5=0.23597\n",
      "\tHR@10=0.45793  MRR@10=0.21625  NDCG@10=0.27333\n",
      "\tHR@20=0.56755  MRR@20=0.22393  NDCG@20=0.30114\n",
      "[2019-12-23 14:51:31] [3/50] 0 mean_batch_loss : 5.893652\n",
      "Start predicting 2019-12-23 14:51:37\n",
      "change best\n",
      "testing finish [2019-12-23 14:51:39] \n",
      "\tHR@1=0.12417  MRR@1=0.12417  NDCG@1=0.12417\n",
      "\tHR@5=0.35972  MRR@5=0.20896  NDCG@5=0.24639\n",
      "\tHR@10=0.48483  MRR@10=0.22569  NDCG@10=0.28687\n",
      "\tHR@20=0.59490  MRR@20=0.23341  NDCG@20=0.31480\n",
      "[2019-12-23 14:51:39] [4/50] 0 mean_batch_loss : 5.844903\n",
      "Start predicting 2019-12-23 14:51:45\n",
      "change best\n",
      "testing finish [2019-12-23 14:51:48] \n",
      "\tHR@1=0.12639  MRR@1=0.12639  NDCG@1=0.12639\n",
      "\tHR@5=0.38012  MRR@5=0.21743  NDCG@5=0.25780\n",
      "\tHR@10=0.50910  MRR@10=0.23469  NDCG@10=0.29956\n",
      "\tHR@20=0.62703  MRR@20=0.24298  NDCG@20=0.32951\n",
      "[2019-12-23 14:51:48] [5/50] 0 mean_batch_loss : 5.224605\n",
      "Start predicting 2019-12-23 14:51:54\n",
      "change best\n",
      "testing finish [2019-12-23 14:51:57] \n",
      "\tHR@1=0.13081  MRR@1=0.13081  NDCG@1=0.13081\n",
      "\tHR@5=0.39955  MRR@5=0.22703  NDCG@5=0.26983\n",
      "\tHR@10=0.53465  MRR@10=0.24519  NDCG@10=0.31365\n",
      "\tHR@20=0.64844  MRR@20=0.25322  NDCG@20=0.34257\n",
      "[2019-12-23 14:51:57] [6/50] 0 mean_batch_loss : 4.932331\n",
      "Start predicting 2019-12-23 14:52:03\n",
      "change best\n",
      "testing finish [2019-12-23 14:52:05] \n",
      "\tHR@1=0.13071  MRR@1=0.13071  NDCG@1=0.13071\n",
      "\tHR@5=0.39415  MRR@5=0.22446  NDCG@5=0.26652\n",
      "\tHR@10=0.53532  MRR@10=0.24341  NDCG@10=0.31228\n",
      "\tHR@20=0.65273  MRR@20=0.25169  NDCG@20=0.34214\n",
      "[2019-12-23 14:52:06] [7/50] 0 mean_batch_loss : 5.062285\n",
      "Start predicting 2019-12-23 14:52:12\n",
      "change best\n",
      "testing finish [2019-12-23 14:52:14] \n",
      "\tHR@1=0.13224  MRR@1=0.13224  NDCG@1=0.13224\n",
      "\tHR@5=0.39943  MRR@5=0.22762  NDCG@5=0.27022\n",
      "\tHR@10=0.54343  MRR@10=0.24694  NDCG@10=0.31689\n",
      "\tHR@20=0.66181  MRR@20=0.25527  NDCG@20=0.34696\n",
      "[2019-12-23 14:52:14] [8/50] 0 mean_batch_loss : 4.879548\n",
      "Start predicting 2019-12-23 14:52:21\n",
      "change best\n",
      "testing finish [2019-12-23 14:52:23] \n",
      "\tHR@1=0.13335  MRR@1=0.13335  NDCG@1=0.13335\n",
      "\tHR@5=0.41289  MRR@5=0.23276  NDCG@5=0.27741\n",
      "\tHR@10=0.55334  MRR@10=0.25167  NDCG@10=0.32300\n",
      "\tHR@20=0.67074  MRR@20=0.25992  NDCG@20=0.35281\n",
      "[2019-12-23 14:52:23] [9/50] 0 mean_batch_loss : 4.652766\n",
      "Start predicting 2019-12-23 14:52:29\n",
      "change best\n",
      "testing finish [2019-12-23 14:52:32] \n",
      "\tHR@1=0.13801  MRR@1=0.13801  NDCG@1=0.13801\n",
      "\tHR@5=0.41388  MRR@5=0.23556  NDCG@5=0.27975\n",
      "\tHR@10=0.55519  MRR@10=0.25448  NDCG@10=0.32551\n",
      "\tHR@20=0.67559  MRR@20=0.26297  NDCG@20=0.35611\n",
      "[2019-12-23 14:52:32] [10/50] 0 mean_batch_loss : 4.676276\n",
      "Start predicting 2019-12-23 14:52:38\n",
      "change best\n",
      "testing finish [2019-12-23 14:52:41] \n",
      "\tHR@1=0.13897  MRR@1=0.13897  NDCG@1=0.13897\n",
      "\tHR@5=0.41943  MRR@5=0.23792  NDCG@5=0.28287\n",
      "\tHR@10=0.56153  MRR@10=0.25705  NDCG@10=0.32900\n",
      "\tHR@20=0.67651  MRR@20=0.26517  NDCG@20=0.35824\n",
      "[2019-12-23 14:52:41] [11/50] 0 mean_batch_loss : 4.611319\n",
      "Start predicting 2019-12-23 14:52:47\n",
      "testing finish [2019-12-23 14:52:50] \n",
      "\tHR@1=0.13369  MRR@1=0.13369  NDCG@1=0.13369\n",
      "\tHR@5=0.41467  MRR@5=0.23414  NDCG@5=0.27892\n",
      "\tHR@10=0.55808  MRR@10=0.25331  NDCG@10=0.32532\n",
      "\tHR@20=0.67478  MRR@20=0.26153  NDCG@20=0.35498\n",
      "[2019-12-23 14:52:50] [12/50] 0 mean_batch_loss : 4.410101\n",
      "Start predicting 2019-12-23 14:52:56\n",
      "testing finish [2019-12-23 14:52:59] \n",
      "\tHR@1=0.13372  MRR@1=0.13372  NDCG@1=0.13372\n",
      "\tHR@5=0.41186  MRR@5=0.23230  NDCG@5=0.27679\n",
      "\tHR@10=0.55544  MRR@10=0.25159  NDCG@10=0.32335\n",
      "\tHR@20=0.67648  MRR@20=0.26012  NDCG@20=0.35412\n",
      "[2019-12-23 14:52:59] [13/50] 0 mean_batch_loss : 4.371334\n",
      "Start predicting 2019-12-23 14:53:05\n",
      "change best\n",
      "testing finish [2019-12-23 14:53:08] \n",
      "\tHR@1=0.13981  MRR@1=0.13981  NDCG@1=0.13981\n",
      "\tHR@5=0.42828  MRR@5=0.24266  NDCG@5=0.28870\n",
      "\tHR@10=0.56780  MRR@10=0.26133  NDCG@10=0.33387\n",
      "\tHR@20=0.68432  MRR@20=0.26957  NDCG@20=0.36352\n",
      "[2019-12-23 14:53:08] [14/50] 0 mean_batch_loss : 4.217777\n",
      "Start predicting 2019-12-23 14:53:14\n",
      "testing finish [2019-12-23 14:53:17] \n",
      "\tHR@1=0.13584  MRR@1=0.13584  NDCG@1=0.13584\n",
      "\tHR@5=0.41817  MRR@5=0.23678  NDCG@5=0.28177\n",
      "\tHR@10=0.56235  MRR@10=0.25623  NDCG@10=0.32861\n",
      "\tHR@20=0.68186  MRR@20=0.26465  NDCG@20=0.35898\n",
      "[2019-12-23 14:53:17] [15/50] 0 mean_batch_loss : 4.293095\n",
      "Start predicting 2019-12-23 14:53:23\n",
      "change best\n",
      "testing finish [2019-12-23 14:53:26] \n",
      "\tHR@1=0.14040  MRR@1=0.14040  NDCG@1=0.14040\n",
      "\tHR@5=0.43077  MRR@5=0.24398  NDCG@5=0.29029\n",
      "\tHR@10=0.57233  MRR@10=0.26302  NDCG@10=0.33622\n",
      "\tHR@20=0.68807  MRR@20=0.27123  NDCG@20=0.36571\n",
      "[2019-12-23 14:53:26] [16/50] 0 mean_batch_loss : 4.135553\n",
      "Start predicting 2019-12-23 14:53:32\n",
      "change best\n",
      "testing finish [2019-12-23 14:53:35] \n",
      "\tHR@1=0.13902  MRR@1=0.13902  NDCG@1=0.13902\n",
      "\tHR@5=0.43632  MRR@5=0.24532  NDCG@5=0.29271\n",
      "\tHR@10=0.57860  MRR@10=0.26439  NDCG@10=0.33880\n",
      "\tHR@20=0.69061  MRR@20=0.27232  NDCG@20=0.36731\n",
      "[2019-12-23 14:53:35] [17/50] 0 mean_batch_loss : 4.505748\n",
      "Start predicting 2019-12-23 14:53:41\n",
      "change best\n",
      "testing finish [2019-12-23 14:53:44] \n",
      "\tHR@1=0.14188  MRR@1=0.14188  NDCG@1=0.14188\n",
      "\tHR@5=0.43418  MRR@5=0.24636  NDCG@5=0.29294\n",
      "\tHR@10=0.57756  MRR@10=0.26565  NDCG@10=0.33946\n",
      "\tHR@20=0.69148  MRR@20=0.27365  NDCG@20=0.36839\n",
      "[2019-12-23 14:53:44] [18/50] 0 mean_batch_loss : 4.101788\n",
      "Start predicting 2019-12-23 14:53:50\n",
      "testing finish [2019-12-23 14:53:53] \n",
      "\tHR@1=0.14107  MRR@1=0.14107  NDCG@1=0.14107\n",
      "\tHR@5=0.43465  MRR@5=0.24612  NDCG@5=0.29290\n",
      "\tHR@10=0.57593  MRR@10=0.26502  NDCG@10=0.33864\n",
      "\tHR@20=0.69024  MRR@20=0.27311  NDCG@20=0.36774\n",
      "[2019-12-23 14:53:53] [19/50] 0 mean_batch_loss : 4.235513\n",
      "Start predicting 2019-12-23 14:53:59\n",
      "testing finish [2019-12-23 14:54:02] \n",
      "\tHR@1=0.13939  MRR@1=0.13939  NDCG@1=0.13939\n",
      "\tHR@5=0.42747  MRR@5=0.24241  NDCG@5=0.28833\n",
      "\tHR@10=0.57098  MRR@10=0.26170  NDCG@10=0.33487\n",
      "\tHR@20=0.68864  MRR@20=0.26999  NDCG@20=0.36478\n",
      "[2019-12-23 14:54:02] [20/50] 0 mean_batch_loss : 3.978989\n",
      "Start predicting 2019-12-23 14:54:08\n",
      "testing finish [2019-12-23 14:54:11] \n",
      "\tHR@1=0.13500  MRR@1=0.13500  NDCG@1=0.13500\n",
      "\tHR@5=0.41386  MRR@5=0.23378  NDCG@5=0.27840\n",
      "\tHR@10=0.56235  MRR@10=0.25374  NDCG@10=0.32655\n",
      "\tHR@20=0.68225  MRR@20=0.26222  NDCG@20=0.35707\n",
      "[2019-12-23 14:54:11] [21/50] 0 mean_batch_loss : 4.219768\n",
      "Start predicting 2019-12-23 14:54:17\n",
      "testing finish [2019-12-23 14:54:20] \n",
      "\tHR@1=0.14033  MRR@1=0.14033  NDCG@1=0.14033\n",
      "\tHR@5=0.42165  MRR@5=0.23990  NDCG@5=0.28493\n",
      "\tHR@10=0.56757  MRR@10=0.25943  NDCG@10=0.33218\n",
      "\tHR@20=0.68573  MRR@20=0.26776  NDCG@20=0.36221\n",
      "[2019-12-23 14:54:20] [22/50] 0 mean_batch_loss : 4.194420\n",
      "Start predicting 2019-12-23 14:54:26\n",
      "testing finish [2019-12-23 14:54:29] \n",
      "\tHR@1=0.14146  MRR@1=0.14146  NDCG@1=0.14146\n",
      "\tHR@5=0.43395  MRR@5=0.24587  NDCG@5=0.29251\n",
      "\tHR@10=0.57675  MRR@10=0.26512  NDCG@10=0.33888\n",
      "\tHR@20=0.69167  MRR@20=0.27324  NDCG@20=0.36813\n",
      "[2019-12-23 14:54:29] [23/50] 0 mean_batch_loss : 4.230920\n",
      "Start predicting 2019-12-23 14:54:35\n",
      "testing finish [2019-12-23 14:54:38] \n",
      "\tHR@1=0.14045  MRR@1=0.14045  NDCG@1=0.14045\n",
      "\tHR@5=0.43132  MRR@5=0.24391  NDCG@5=0.29037\n",
      "\tHR@10=0.57396  MRR@10=0.26306  NDCG@10=0.33661\n",
      "\tHR@20=0.69106  MRR@20=0.27131  NDCG@20=0.36637\n",
      "[2019-12-23 14:54:38] [24/50] 0 mean_batch_loss : 3.999944\n",
      "Start predicting 2019-12-23 14:54:44\n",
      "change best\n",
      "testing finish [2019-12-23 14:54:47] \n",
      "\tHR@1=0.14191  MRR@1=0.14191  NDCG@1=0.14191\n",
      "\tHR@5=0.43635  MRR@5=0.24653  NDCG@5=0.29359\n",
      "\tHR@10=0.57897  MRR@10=0.26572  NDCG@10=0.33986\n",
      "\tHR@20=0.69259  MRR@20=0.27371  NDCG@20=0.36873\n",
      "[2019-12-23 14:54:47] [25/50] 0 mean_batch_loss : 4.150707\n",
      "Start predicting 2019-12-23 14:54:53\n",
      "testing finish [2019-12-23 14:54:56] \n",
      "\tHR@1=0.14015  MRR@1=0.14015  NDCG@1=0.14015\n",
      "\tHR@5=0.43072  MRR@5=0.24390  NDCG@5=0.29024\n",
      "\tHR@10=0.57384  MRR@10=0.26318  NDCG@10=0.33670\n",
      "\tHR@20=0.69081  MRR@20=0.27142  NDCG@20=0.36643\n",
      "[2019-12-23 14:54:56] [26/50] 0 mean_batch_loss : 4.175833\n",
      "Start predicting 2019-12-23 14:55:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing finish [2019-12-23 14:55:04] \n",
      "\tHR@1=0.14215  MRR@1=0.14215  NDCG@1=0.14215\n",
      "\tHR@5=0.42947  MRR@5=0.24455  NDCG@5=0.29042\n",
      "\tHR@10=0.57105  MRR@10=0.26360  NDCG@10=0.33636\n",
      "\tHR@20=0.68825  MRR@20=0.27184  NDCG@20=0.36612\n",
      "[2019-12-23 14:55:04] [27/50] 0 mean_batch_loss : 4.127415\n",
      "Start predicting 2019-12-23 14:55:10\n",
      "testing finish [2019-12-23 14:55:13] \n",
      "\tHR@1=0.14270  MRR@1=0.14270  NDCG@1=0.14270\n",
      "\tHR@5=0.43363  MRR@5=0.24659  NDCG@5=0.29299\n",
      "\tHR@10=0.57677  MRR@10=0.26580  NDCG@10=0.33938\n",
      "\tHR@20=0.69190  MRR@20=0.27391  NDCG@20=0.36865\n",
      "[2019-12-23 14:55:13] [28/50] 0 mean_batch_loss : 4.109509\n",
      "Start predicting 2019-12-23 14:55:19\n",
      "testing finish [2019-12-23 14:55:22] \n",
      "\tHR@1=0.14045  MRR@1=0.14045  NDCG@1=0.14045\n",
      "\tHR@5=0.43164  MRR@5=0.24431  NDCG@5=0.29077\n",
      "\tHR@10=0.57510  MRR@10=0.26356  NDCG@10=0.33727\n",
      "\tHR@20=0.68973  MRR@20=0.27167  NDCG@20=0.36644\n",
      "[2019-12-23 14:55:22] [29/50] 0 mean_batch_loss : 4.059772\n",
      "Start predicting 2019-12-23 14:55:28\n",
      "testing finish [2019-12-23 14:55:31] \n",
      "\tHR@1=0.13685  MRR@1=0.13685  NDCG@1=0.13685\n",
      "\tHR@5=0.41903  MRR@5=0.23826  NDCG@5=0.28314\n",
      "\tHR@10=0.56410  MRR@10=0.25778  NDCG@10=0.33021\n",
      "\tHR@20=0.68260  MRR@20=0.26613  NDCG@20=0.36033\n",
      "[2019-12-23 14:55:31] [30/50] 0 mean_batch_loss : 3.990940\n",
      "Start predicting 2019-12-23 14:55:38\n",
      "testing finish [2019-12-23 14:55:40] \n",
      "\tHR@1=0.14055  MRR@1=0.14055  NDCG@1=0.14055\n",
      "\tHR@5=0.43055  MRR@5=0.24412  NDCG@5=0.29037\n",
      "\tHR@10=0.57330  MRR@10=0.26334  NDCG@10=0.33669\n",
      "\tHR@20=0.68879  MRR@20=0.27148  NDCG@20=0.36605\n",
      "[2019-12-23 14:55:40] [31/50] 0 mean_batch_loss : 3.924262\n",
      "Start predicting 2019-12-23 14:55:46\n",
      "testing finish [2019-12-23 14:55:49] \n",
      "\tHR@1=0.14469  MRR@1=0.14469  NDCG@1=0.14469\n",
      "\tHR@5=0.43053  MRR@5=0.24658  NDCG@5=0.29220\n",
      "\tHR@10=0.57120  MRR@10=0.26549  NDCG@10=0.33782\n",
      "\tHR@20=0.68748  MRR@20=0.27368  NDCG@20=0.36737\n",
      "[2019-12-23 14:55:49] [32/50] 0 mean_batch_loss : 4.129214\n",
      "Start predicting 2019-12-23 14:55:55\n",
      "testing finish [2019-12-23 14:55:58] \n",
      "\tHR@1=0.14028  MRR@1=0.14028  NDCG@1=0.14028\n",
      "\tHR@5=0.42924  MRR@5=0.24317  NDCG@5=0.28932\n",
      "\tHR@10=0.57073  MRR@10=0.26217  NDCG@10=0.33519\n",
      "\tHR@20=0.68706  MRR@20=0.27037  NDCG@20=0.36476\n",
      "[2019-12-23 14:55:58] [33/50] 0 mean_batch_loss : 3.910071\n",
      "Start predicting 2019-12-23 14:56:04\n",
      "testing finish [2019-12-23 14:56:07] \n",
      "\tHR@1=0.13993  MRR@1=0.13993  NDCG@1=0.13993\n",
      "\tHR@5=0.43228  MRR@5=0.24398  NDCG@5=0.29067\n",
      "\tHR@10=0.57416  MRR@10=0.26307  NDCG@10=0.33670\n",
      "\tHR@20=0.68906  MRR@20=0.27116  NDCG@20=0.36590\n",
      "[2019-12-23 14:56:07] [34/50] 0 mean_batch_loss : 4.081352\n",
      "Start predicting 2019-12-23 14:56:13\n",
      "testing finish [2019-12-23 14:56:16] \n",
      "\tHR@1=0.14339  MRR@1=0.14339  NDCG@1=0.14339\n",
      "\tHR@5=0.43023  MRR@5=0.24530  NDCG@5=0.29115\n",
      "\tHR@10=0.56967  MRR@10=0.26399  NDCG@10=0.33632\n",
      "\tHR@20=0.68511  MRR@20=0.27213  NDCG@20=0.36567\n",
      "early stopping\n",
      "current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0030, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "current model HR@20=0.69259  MRR@20=0.27371\n",
      "the best result so far. HR@20=0.69259  MRR@20=0.27922，其参数current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      " \n",
      "\n",
      "current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0005, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "[2019-12-23 14:56:16] [1/50] 0 mean_batch_loss : 13.700386\n",
      "Start predicting 2019-12-23 14:56:22\n",
      "change best\n",
      "testing finish [2019-12-23 14:56:25] \n",
      "\tHR@1=0.09332  MRR@1=0.09332  NDCG@1=0.09332\n",
      "\tHR@5=0.18982  MRR@5=0.12959  NDCG@5=0.14462\n",
      "\tHR@10=0.21959  MRR@10=0.13356  NDCG@10=0.15425\n",
      "\tHR@20=0.25007  MRR@20=0.13566  NDCG@20=0.16194\n",
      "[2019-12-23 14:56:25] [2/50] 0 mean_batch_loss : 8.478365\n",
      "Start predicting 2019-12-23 14:56:31\n",
      "change best\n",
      "testing finish [2019-12-23 14:56:34] \n",
      "\tHR@1=0.09988  MRR@1=0.09988  NDCG@1=0.09988\n",
      "\tHR@5=0.24813  MRR@5=0.15353  NDCG@5=0.17702\n",
      "\tHR@10=0.32021  MRR@10=0.16324  NDCG@10=0.20042\n",
      "\tHR@20=0.39085  MRR@20=0.16814  NDCG@20=0.21827\n",
      "[2019-12-23 14:56:34] [3/50] 0 mean_batch_loss : 7.222411\n",
      "Start predicting 2019-12-23 14:56:40\n",
      "change best\n",
      "testing finish [2019-12-23 14:56:43] \n",
      "\tHR@1=0.10474  MRR@1=0.10474  NDCG@1=0.10474\n",
      "\tHR@5=0.27397  MRR@5=0.16593  NDCG@5=0.19276\n",
      "\tHR@10=0.36189  MRR@10=0.17763  NDCG@10=0.22116\n",
      "\tHR@20=0.44769  MRR@20=0.18365  NDCG@20=0.24293\n",
      "[2019-12-23 14:56:43] [4/50] 0 mean_batch_loss : 6.749127\n",
      "Start predicting 2019-12-23 14:56:49\n",
      "change best\n",
      "testing finish [2019-12-23 14:56:52] \n",
      "\tHR@1=0.11019  MRR@1=0.11019  NDCG@1=0.11019\n",
      "\tHR@5=0.30179  MRR@5=0.17901  NDCG@5=0.20948\n",
      "\tHR@10=0.39893  MRR@10=0.19202  NDCG@10=0.24094\n",
      "\tHR@20=0.48930  MRR@20=0.19833  NDCG@20=0.26383\n",
      "[2019-12-23 14:56:52] [5/50] 0 mean_batch_loss : 6.567851\n",
      "Start predicting 2019-12-23 14:56:58\n",
      "change best\n",
      "testing finish [2019-12-23 14:57:01] \n",
      "\tHR@1=0.11448  MRR@1=0.11448  NDCG@1=0.11448\n",
      "\tHR@5=0.31787  MRR@5=0.18750  NDCG@5=0.21986\n",
      "\tHR@10=0.42160  MRR@10=0.20133  NDCG@10=0.25339\n",
      "\tHR@20=0.51475  MRR@20=0.20783  NDCG@20=0.27698\n",
      "[2019-12-23 14:57:01] [6/50] 0 mean_batch_loss : 6.339918\n",
      "Start predicting 2019-12-23 14:57:07\n",
      "change best\n",
      "testing finish [2019-12-23 14:57:10] \n",
      "\tHR@1=0.11485  MRR@1=0.11485  NDCG@1=0.11485\n",
      "\tHR@5=0.32914  MRR@5=0.19205  NDCG@5=0.22609\n",
      "\tHR@10=0.43593  MRR@10=0.20639  NDCG@10=0.26072\n",
      "\tHR@20=0.52962  MRR@20=0.21295  NDCG@20=0.28448\n",
      "[2019-12-23 14:57:10] [7/50] 0 mean_batch_loss : 6.213219\n",
      "Start predicting 2019-12-23 14:57:16\n",
      "change best\n",
      "testing finish [2019-12-23 14:57:19] \n",
      "\tHR@1=0.11734  MRR@1=0.11734  NDCG@1=0.11734\n",
      "\tHR@5=0.33580  MRR@5=0.19569  NDCG@5=0.23046\n",
      "\tHR@10=0.44436  MRR@10=0.21021  NDCG@10=0.26560\n",
      "\tHR@20=0.54202  MRR@20=0.21705  NDCG@20=0.29036\n",
      "[2019-12-23 14:57:19] [8/50] 0 mean_batch_loss : 6.177614\n",
      "Start predicting 2019-12-23 14:57:25\n",
      "change best\n",
      "testing finish [2019-12-23 14:57:28] \n",
      "\tHR@1=0.12208  MRR@1=0.12208  NDCG@1=0.12208\n",
      "\tHR@5=0.34690  MRR@5=0.20279  NDCG@5=0.23856\n",
      "\tHR@10=0.45798  MRR@10=0.21767  NDCG@10=0.27454\n",
      "\tHR@20=0.55687  MRR@20=0.22461  NDCG@20=0.29964\n",
      "[2019-12-23 14:57:28] [9/50] 0 mean_batch_loss : 5.767195\n",
      "Start predicting 2019-12-23 14:57:34\n",
      "change best\n",
      "testing finish [2019-12-23 14:57:37] \n",
      "\tHR@1=0.12166  MRR@1=0.12166  NDCG@1=0.12166\n",
      "\tHR@5=0.35193  MRR@5=0.20446  NDCG@5=0.24107\n",
      "\tHR@10=0.46757  MRR@10=0.21992  NDCG@10=0.27849\n",
      "\tHR@20=0.56881  MRR@20=0.22701  NDCG@20=0.30416\n",
      "[2019-12-23 14:57:37] [10/50] 0 mean_batch_loss : 5.871465\n",
      "Start predicting 2019-12-23 14:57:43\n",
      "change best\n",
      "testing finish [2019-12-23 14:57:46] \n",
      "\tHR@1=0.12472  MRR@1=0.12472  NDCG@1=0.12472\n",
      "\tHR@5=0.36118  MRR@5=0.20931  NDCG@5=0.24698\n",
      "\tHR@10=0.47953  MRR@10=0.22512  NDCG@10=0.28527\n",
      "\tHR@20=0.58032  MRR@20=0.23219  NDCG@20=0.31085\n",
      "[2019-12-23 14:57:46] [11/50] 0 mean_batch_loss : 5.924027\n",
      "Start predicting 2019-12-23 14:57:52\n",
      "change best\n",
      "testing finish [2019-12-23 14:57:54] \n",
      "\tHR@1=0.12612  MRR@1=0.12612  NDCG@1=0.12612\n",
      "\tHR@5=0.36317  MRR@5=0.21088  NDCG@5=0.24866\n",
      "\tHR@10=0.48542  MRR@10=0.22721  NDCG@10=0.28821\n",
      "\tHR@20=0.59073  MRR@20=0.23461  NDCG@20=0.31495\n",
      "[2019-12-23 14:57:55] [12/50] 0 mean_batch_loss : 5.696298\n",
      "Start predicting 2019-12-23 14:58:01\n",
      "change best\n",
      "testing finish [2019-12-23 14:58:03] \n",
      "\tHR@1=0.12854  MRR@1=0.12854  NDCG@1=0.12854\n",
      "\tHR@5=0.36690  MRR@5=0.21394  NDCG@5=0.25190\n",
      "\tHR@10=0.48920  MRR@10=0.23033  NDCG@10=0.29152\n",
      "\tHR@20=0.59574  MRR@20=0.23780  NDCG@20=0.31856\n",
      "[2019-12-23 14:58:04] [13/50] 0 mean_batch_loss : 5.638118\n",
      "Start predicting 2019-12-23 14:58:09\n",
      "change best\n",
      "testing finish [2019-12-23 14:58:12] \n",
      "\tHR@1=0.12896  MRR@1=0.12896  NDCG@1=0.12896\n",
      "\tHR@5=0.37255  MRR@5=0.21677  NDCG@5=0.25545\n",
      "\tHR@10=0.49502  MRR@10=0.23309  NDCG@10=0.29503\n",
      "\tHR@20=0.60181  MRR@20=0.24060  NDCG@20=0.32215\n",
      "[2019-12-23 14:58:12] [14/50] 0 mean_batch_loss : 5.610801\n",
      "Start predicting 2019-12-23 14:58:18\n",
      "change best\n",
      "testing finish [2019-12-23 14:58:21] \n",
      "\tHR@1=0.13113  MRR@1=0.13113  NDCG@1=0.13113\n",
      "\tHR@5=0.37597  MRR@5=0.21890  NDCG@5=0.25789\n",
      "\tHR@10=0.50012  MRR@10=0.23553  NDCG@10=0.29809\n",
      "\tHR@20=0.60814  MRR@20=0.24313  NDCG@20=0.32554\n",
      "[2019-12-23 14:58:21] [15/50] 0 mean_batch_loss : 5.590117\n",
      "Start predicting 2019-12-23 14:58:27\n",
      "change best\n",
      "testing finish [2019-12-23 14:58:30] \n",
      "\tHR@1=0.12940  MRR@1=0.12940  NDCG@1=0.12940\n",
      "\tHR@5=0.37684  MRR@5=0.21847  NDCG@5=0.25778\n",
      "\tHR@10=0.50350  MRR@10=0.23544  NDCG@10=0.29881\n",
      "\tHR@20=0.61120  MRR@20=0.24303  NDCG@20=0.32619\n",
      "[2019-12-23 14:58:30] [16/50] 0 mean_batch_loss : 5.634845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 14:58:36\n",
      "change best\n",
      "testing finish [2019-12-23 14:58:39] \n",
      "\tHR@1=0.13034  MRR@1=0.13034  NDCG@1=0.13034\n",
      "\tHR@5=0.38263  MRR@5=0.22107  NDCG@5=0.26118\n",
      "\tHR@10=0.50871  MRR@10=0.23800  NDCG@10=0.30205\n",
      "\tHR@20=0.61747  MRR@20=0.24565  NDCG@20=0.32968\n",
      "[2019-12-23 14:58:39] [17/50] 0 mean_batch_loss : 5.384971\n",
      "Start predicting 2019-12-23 14:58:45\n",
      "change best\n",
      "testing finish [2019-12-23 14:58:48] \n",
      "\tHR@1=0.13108  MRR@1=0.13108  NDCG@1=0.13108\n",
      "\tHR@5=0.38922  MRR@5=0.22401  NDCG@5=0.26503\n",
      "\tHR@10=0.51576  MRR@10=0.24094  NDCG@10=0.30599\n",
      "\tHR@20=0.62494  MRR@20=0.24859  NDCG@20=0.33370\n",
      "[2019-12-23 14:58:48] [18/50] 0 mean_batch_loss : 5.260434\n",
      "Start predicting 2019-12-23 14:58:54\n",
      "change best\n",
      "testing finish [2019-12-23 14:58:57] \n",
      "\tHR@1=0.13443  MRR@1=0.13443  NDCG@1=0.13443\n",
      "\tHR@5=0.38734  MRR@5=0.22464  NDCG@5=0.26500\n",
      "\tHR@10=0.51744  MRR@10=0.24201  NDCG@10=0.30708\n",
      "\tHR@20=0.62669  MRR@20=0.24969  NDCG@20=0.33482\n",
      "[2019-12-23 14:58:57] [19/50] 0 mean_batch_loss : 5.344368\n",
      "Start predicting 2019-12-23 14:59:03\n",
      "change best\n",
      "testing finish [2019-12-23 14:59:06] \n",
      "\tHR@1=0.13685  MRR@1=0.13685  NDCG@1=0.13685\n",
      "\tHR@5=0.39654  MRR@5=0.22976  NDCG@5=0.27115\n",
      "\tHR@10=0.52372  MRR@10=0.24682  NDCG@10=0.31237\n",
      "\tHR@20=0.63342  MRR@20=0.25454  NDCG@20=0.34023\n",
      "[2019-12-23 14:59:06] [20/50] 0 mean_batch_loss : 5.198259\n",
      "Start predicting 2019-12-23 14:59:12\n",
      "change best\n",
      "testing finish [2019-12-23 14:59:15] \n",
      "\tHR@1=0.13660  MRR@1=0.13660  NDCG@1=0.13660\n",
      "\tHR@5=0.39834  MRR@5=0.22990  NDCG@5=0.27168\n",
      "\tHR@10=0.52528  MRR@10=0.24686  NDCG@10=0.31274\n",
      "\tHR@20=0.63663  MRR@20=0.25467  NDCG@20=0.34101\n",
      "[2019-12-23 14:59:15] [21/50] 0 mean_batch_loss : 5.046835\n",
      "Start predicting 2019-12-23 14:59:20\n",
      "testing finish [2019-12-23 14:59:23] \n",
      "\tHR@1=0.13268  MRR@1=0.13268  NDCG@1=0.13268\n",
      "\tHR@5=0.39257  MRR@5=0.22639  NDCG@5=0.26766\n",
      "\tHR@10=0.52299  MRR@10=0.24384  NDCG@10=0.30989\n",
      "\tHR@20=0.63473  MRR@20=0.25171  NDCG@20=0.33828\n",
      "[2019-12-23 14:59:23] [22/50] 0 mean_batch_loss : 4.942847\n",
      "Start predicting 2019-12-23 14:59:29\n",
      "change best\n",
      "testing finish [2019-12-23 14:59:32] \n",
      "\tHR@1=0.13784  MRR@1=0.13784  NDCG@1=0.13784\n",
      "\tHR@5=0.40224  MRR@5=0.23248  NDCG@5=0.27461\n",
      "\tHR@10=0.53169  MRR@10=0.24978  NDCG@10=0.31650\n",
      "\tHR@20=0.64173  MRR@20=0.25749  NDCG@20=0.34441\n",
      "[2019-12-23 14:59:32] [23/50] 0 mean_batch_loss : 5.041722\n",
      "Start predicting 2019-12-23 14:59:38\n",
      "change best\n",
      "testing finish [2019-12-23 14:59:41] \n",
      "\tHR@1=0.13821  MRR@1=0.13821  NDCG@1=0.13821\n",
      "\tHR@5=0.40421  MRR@5=0.23334  NDCG@5=0.27574\n",
      "\tHR@10=0.53334  MRR@10=0.25060  NDCG@10=0.31753\n",
      "\tHR@20=0.64546  MRR@20=0.25849  NDCG@20=0.34601\n",
      "[2019-12-23 14:59:41] [24/50] 0 mean_batch_loss : 4.815830\n",
      "Start predicting 2019-12-23 14:59:47\n",
      "testing finish [2019-12-23 14:59:50] \n",
      "\tHR@1=0.13586  MRR@1=0.13586  NDCG@1=0.13586\n",
      "\tHR@5=0.40621  MRR@5=0.23279  NDCG@5=0.27584\n",
      "\tHR@10=0.53566  MRR@10=0.25002  NDCG@10=0.31765\n",
      "\tHR@20=0.64602  MRR@20=0.25778  NDCG@20=0.34567\n",
      "[2019-12-23 14:59:50] [25/50] 0 mean_batch_loss : 5.012278\n",
      "Start predicting 2019-12-23 14:59:56\n",
      "change best\n",
      "testing finish [2019-12-23 14:59:59] \n",
      "\tHR@1=0.13786  MRR@1=0.13786  NDCG@1=0.13786\n",
      "\tHR@5=0.40419  MRR@5=0.23344  NDCG@5=0.27581\n",
      "\tHR@10=0.53751  MRR@10=0.25128  NDCG@10=0.31898\n",
      "\tHR@20=0.64913  MRR@20=0.25917  NDCG@20=0.34738\n",
      "[2019-12-23 14:59:59] [26/50] 0 mean_batch_loss : 4.887893\n",
      "Start predicting 2019-12-23 15:00:05\n",
      "change best\n",
      "testing finish [2019-12-23 15:00:08] \n",
      "\tHR@1=0.13650  MRR@1=0.13650  NDCG@1=0.13650\n",
      "\tHR@5=0.40616  MRR@5=0.23330  NDCG@5=0.27621\n",
      "\tHR@10=0.53756  MRR@10=0.25085  NDCG@10=0.31871\n",
      "\tHR@20=0.64997  MRR@20=0.25876  NDCG@20=0.34728\n",
      "[2019-12-23 15:00:08] [27/50] 0 mean_batch_loss : 4.907789\n",
      "Start predicting 2019-12-23 15:00:15\n",
      "change best\n",
      "testing finish [2019-12-23 15:00:17] \n",
      "\tHR@1=0.13717  MRR@1=0.13717  NDCG@1=0.13717\n",
      "\tHR@5=0.40399  MRR@5=0.23242  NDCG@5=0.27498\n",
      "\tHR@10=0.53897  MRR@10=0.25055  NDCG@10=0.31874\n",
      "\tHR@20=0.65251  MRR@20=0.25855  NDCG@20=0.34760\n",
      "[2019-12-23 15:00:17] [28/50] 0 mean_batch_loss : 4.871415\n",
      "Start predicting 2019-12-23 15:00:23\n",
      "change best\n",
      "testing finish [2019-12-23 15:00:26] \n",
      "\tHR@1=0.13826  MRR@1=0.13826  NDCG@1=0.13826\n",
      "\tHR@5=0.40710  MRR@5=0.23441  NDCG@5=0.27726\n",
      "\tHR@10=0.54180  MRR@10=0.25246  NDCG@10=0.32089\n",
      "\tHR@20=0.65586  MRR@20=0.26052  NDCG@20=0.34992\n",
      "[2019-12-23 15:00:26] [29/50] 0 mean_batch_loss : 4.722847\n",
      "Start predicting 2019-12-23 15:00:32\n",
      "change best\n",
      "testing finish [2019-12-23 15:00:35] \n",
      "\tHR@1=0.14136  MRR@1=0.14136  NDCG@1=0.14136\n",
      "\tHR@5=0.41435  MRR@5=0.23869  NDCG@5=0.28227\n",
      "\tHR@10=0.54673  MRR@10=0.25641  NDCG@10=0.32513\n",
      "\tHR@20=0.66053  MRR@20=0.26447  NDCG@20=0.35410\n",
      "[2019-12-23 15:00:35] [30/50] 0 mean_batch_loss : 5.000986\n",
      "Start predicting 2019-12-23 15:00:41\n",
      "testing finish [2019-12-23 15:00:44] \n",
      "\tHR@1=0.13801  MRR@1=0.13801  NDCG@1=0.13801\n",
      "\tHR@5=0.41171  MRR@5=0.23603  NDCG@5=0.27963\n",
      "\tHR@10=0.54777  MRR@10=0.25421  NDCG@10=0.32364\n",
      "\tHR@20=0.66065  MRR@20=0.26216  NDCG@20=0.35233\n",
      "[2019-12-23 15:00:44] [31/50] 0 mean_batch_loss : 4.692512\n",
      "Start predicting 2019-12-23 15:00:50\n",
      "change best\n",
      "testing finish [2019-12-23 15:00:53] \n",
      "\tHR@1=0.14023  MRR@1=0.14023  NDCG@1=0.14023\n",
      "\tHR@5=0.41526  MRR@5=0.23873  NDCG@5=0.28254\n",
      "\tHR@10=0.54992  MRR@10=0.25667  NDCG@10=0.32605\n",
      "\tHR@20=0.66282  MRR@20=0.26463  NDCG@20=0.35476\n",
      "[2019-12-23 15:00:53] [32/50] 0 mean_batch_loss : 4.789192\n",
      "Start predicting 2019-12-23 15:00:59\n",
      "change best\n",
      "testing finish [2019-12-23 15:01:02] \n",
      "\tHR@1=0.14097  MRR@1=0.14097  NDCG@1=0.14097\n",
      "\tHR@5=0.41598  MRR@5=0.23942  NDCG@5=0.28324\n",
      "\tHR@10=0.55001  MRR@10=0.25738  NDCG@10=0.32665\n",
      "\tHR@20=0.66346  MRR@20=0.26540  NDCG@20=0.35552\n",
      "[2019-12-23 15:01:02] [33/50] 0 mean_batch_loss : 4.856608\n",
      "Start predicting 2019-12-23 15:01:08\n",
      "change best\n",
      "testing finish [2019-12-23 15:01:11] \n",
      "\tHR@1=0.14038  MRR@1=0.14038  NDCG@1=0.14038\n",
      "\tHR@5=0.41573  MRR@5=0.23874  NDCG@5=0.28265\n",
      "\tHR@10=0.55177  MRR@10=0.25703  NDCG@10=0.32677\n",
      "\tHR@20=0.66398  MRR@20=0.26492  NDCG@20=0.35528\n",
      "[2019-12-23 15:01:11] [34/50] 0 mean_batch_loss : 4.800863\n",
      "Start predicting 2019-12-23 15:01:16\n",
      "change best\n",
      "testing finish [2019-12-23 15:01:19] \n",
      "\tHR@1=0.14166  MRR@1=0.14166  NDCG@1=0.14166\n",
      "\tHR@5=0.41504  MRR@5=0.23946  NDCG@5=0.28302\n",
      "\tHR@10=0.55085  MRR@10=0.25762  NDCG@10=0.32697\n",
      "\tHR@20=0.66519  MRR@20=0.26571  NDCG@20=0.35607\n",
      "[2019-12-23 15:01:19] [35/50] 0 mean_batch_loss : 4.779817\n",
      "Start predicting 2019-12-23 15:01:25\n",
      "change best\n",
      "testing finish [2019-12-23 15:01:28] \n",
      "\tHR@1=0.14122  MRR@1=0.14122  NDCG@1=0.14122\n",
      "\tHR@5=0.41805  MRR@5=0.23970  NDCG@5=0.28392\n",
      "\tHR@10=0.55532  MRR@10=0.25809  NDCG@10=0.32838\n",
      "\tHR@20=0.66654  MRR@20=0.26594  NDCG@20=0.35667\n",
      "[2019-12-23 15:01:28] [36/50] 0 mean_batch_loss : 4.684981\n",
      "Start predicting 2019-12-23 15:01:34\n",
      "change best\n",
      "testing finish [2019-12-23 15:01:37] \n",
      "\tHR@1=0.14168  MRR@1=0.14168  NDCG@1=0.14168\n",
      "\tHR@5=0.42387  MRR@5=0.24279  NDCG@5=0.28772\n",
      "\tHR@10=0.55680  MRR@10=0.26057  NDCG@10=0.33075\n",
      "\tHR@20=0.67098  MRR@20=0.26867  NDCG@20=0.35984\n",
      "[2019-12-23 15:01:37] [37/50] 0 mean_batch_loss : 4.544423\n",
      "Start predicting 2019-12-23 15:01:43\n",
      "testing finish [2019-12-23 15:01:46] \n",
      "\tHR@1=0.14363  MRR@1=0.14363  NDCG@1=0.14363\n",
      "\tHR@5=0.41805  MRR@5=0.24174  NDCG@5=0.28548\n",
      "\tHR@10=0.55702  MRR@10=0.26034  NDCG@10=0.33048\n",
      "\tHR@20=0.66948  MRR@20=0.26829  NDCG@20=0.35909\n",
      "[2019-12-23 15:01:46] [38/50] 0 mean_batch_loss : 4.458992\n",
      "Start predicting 2019-12-23 15:01:52\n",
      "change best\n",
      "testing finish [2019-12-23 15:01:55] \n",
      "\tHR@1=0.14154  MRR@1=0.14154  NDCG@1=0.14154\n",
      "\tHR@5=0.42207  MRR@5=0.24207  NDCG@5=0.28674\n",
      "\tHR@10=0.55872  MRR@10=0.26037  NDCG@10=0.33100\n",
      "\tHR@20=0.67190  MRR@20=0.26834  NDCG@20=0.35975\n",
      "[2019-12-23 15:01:55] [39/50] 0 mean_batch_loss : 4.663650\n",
      "Start predicting 2019-12-23 15:02:01\n",
      "change best\n",
      "testing finish [2019-12-23 15:02:04] \n",
      "\tHR@1=0.14452  MRR@1=0.14452  NDCG@1=0.14452\n",
      "\tHR@5=0.42444  MRR@5=0.24435  NDCG@5=0.28902\n",
      "\tHR@10=0.55978  MRR@10=0.26250  NDCG@10=0.33288\n",
      "\tHR@20=0.67416  MRR@20=0.27057  NDCG@20=0.36196\n",
      "[2019-12-23 15:02:04] [40/50] 0 mean_batch_loss : 4.536252\n",
      "Start predicting 2019-12-23 15:02:10\n",
      "testing finish [2019-12-23 15:02:13] \n",
      "\tHR@1=0.14343  MRR@1=0.14343  NDCG@1=0.14343\n",
      "\tHR@5=0.42002  MRR@5=0.24217  NDCG@5=0.28629\n",
      "\tHR@10=0.55593  MRR@10=0.26042  NDCG@10=0.33035\n",
      "\tHR@20=0.67293  MRR@20=0.26868  NDCG@20=0.36011\n",
      "[2019-12-23 15:02:13] [41/50] 0 mean_batch_loss : 4.754000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 15:02:19\n",
      "testing finish [2019-12-23 15:02:22] \n",
      "\tHR@1=0.14188  MRR@1=0.14188  NDCG@1=0.14188\n",
      "\tHR@5=0.42372  MRR@5=0.24273  NDCG@5=0.28764\n",
      "\tHR@10=0.56059  MRR@10=0.26112  NDCG@10=0.33203\n",
      "\tHR@20=0.67547  MRR@20=0.26923  NDCG@20=0.36125\n",
      "[2019-12-23 15:02:22] [42/50] 0 mean_batch_loss : 4.720062\n",
      "Start predicting 2019-12-23 15:02:28\n",
      "change best\n",
      "testing finish [2019-12-23 15:02:31] \n",
      "\tHR@1=0.14403  MRR@1=0.14403  NDCG@1=0.14403\n",
      "\tHR@5=0.42281  MRR@5=0.24340  NDCG@5=0.28790\n",
      "\tHR@10=0.55894  MRR@10=0.26162  NDCG@10=0.33199\n",
      "\tHR@20=0.67498  MRR@20=0.26982  NDCG@20=0.36151\n",
      "[2019-12-23 15:02:31] [43/50] 0 mean_batch_loss : 4.408696\n",
      "Start predicting 2019-12-23 15:02:37\n",
      "change best\n",
      "testing finish [2019-12-23 15:02:40] \n",
      "\tHR@1=0.14368  MRR@1=0.14368  NDCG@1=0.14368\n",
      "\tHR@5=0.42392  MRR@5=0.24359  NDCG@5=0.28831\n",
      "\tHR@10=0.56193  MRR@10=0.26209  NDCG@10=0.33302\n",
      "\tHR@20=0.67614  MRR@20=0.27012  NDCG@20=0.36203\n",
      "[2019-12-23 15:02:40] [44/50] 0 mean_batch_loss : 4.563772\n",
      "Start predicting 2019-12-23 15:02:46\n",
      "change best\n",
      "testing finish [2019-12-23 15:02:49] \n",
      "\tHR@1=0.14528  MRR@1=0.14528  NDCG@1=0.14528\n",
      "\tHR@5=0.42515  MRR@5=0.24522  NDCG@5=0.28986\n",
      "\tHR@10=0.56400  MRR@10=0.26390  NDCG@10=0.33490\n",
      "\tHR@20=0.67628  MRR@20=0.27181  NDCG@20=0.36345\n",
      "[2019-12-23 15:02:49] [45/50] 0 mean_batch_loss : 4.414533\n",
      "Start predicting 2019-12-23 15:02:55\n",
      "testing finish [2019-12-23 15:02:58] \n",
      "\tHR@1=0.14380  MRR@1=0.14380  NDCG@1=0.14380\n",
      "\tHR@5=0.42298  MRR@5=0.24319  NDCG@5=0.28777\n",
      "\tHR@10=0.56022  MRR@10=0.26160  NDCG@10=0.33224\n",
      "\tHR@20=0.67678  MRR@20=0.26980  NDCG@20=0.36185\n",
      "[2019-12-23 15:02:58] [46/50] 0 mean_batch_loss : 4.431603\n",
      "Start predicting 2019-12-23 15:03:04\n",
      "change best\n",
      "testing finish [2019-12-23 15:03:07] \n",
      "\tHR@1=0.14610  MRR@1=0.14610  NDCG@1=0.14610\n",
      "\tHR@5=0.42757  MRR@5=0.24659  NDCG@5=0.29149\n",
      "\tHR@10=0.56637  MRR@10=0.26527  NDCG@10=0.33653\n",
      "\tHR@20=0.67929  MRR@20=0.27326  NDCG@20=0.36528\n",
      "[2019-12-23 15:03:07] [47/50] 0 mean_batch_loss : 4.518096\n",
      "Start predicting 2019-12-23 15:03:13\n",
      "change best\n",
      "testing finish [2019-12-23 15:03:16] \n",
      "\tHR@1=0.14588  MRR@1=0.14588  NDCG@1=0.14588\n",
      "\tHR@5=0.42969  MRR@5=0.24703  NDCG@5=0.29233\n",
      "\tHR@10=0.56772  MRR@10=0.26559  NDCG@10=0.33711\n",
      "\tHR@20=0.68104  MRR@20=0.27357  NDCG@20=0.36590\n",
      "[2019-12-23 15:03:16] [48/50] 0 mean_batch_loss : 4.479922\n",
      "Start predicting 2019-12-23 15:03:22\n",
      "testing finish [2019-12-23 15:03:25] \n",
      "\tHR@1=0.14551  MRR@1=0.14551  NDCG@1=0.14551\n",
      "\tHR@5=0.42850  MRR@5=0.24644  NDCG@5=0.29160\n",
      "\tHR@10=0.56543  MRR@10=0.26480  NDCG@10=0.33596\n",
      "\tHR@20=0.68006  MRR@20=0.27291  NDCG@20=0.36513\n",
      "[2019-12-23 15:03:25] [49/50] 0 mean_batch_loss : 4.453387\n",
      "Start predicting 2019-12-23 15:03:31\n",
      "testing finish [2019-12-23 15:03:34] \n",
      "\tHR@1=0.14575  MRR@1=0.14575  NDCG@1=0.14575\n",
      "\tHR@5=0.42779  MRR@5=0.24611  NDCG@5=0.29116\n",
      "\tHR@10=0.56651  MRR@10=0.26471  NDCG@10=0.33610\n",
      "\tHR@20=0.68055  MRR@20=0.27273  NDCG@20=0.36507\n",
      "[2019-12-23 15:03:34] [50/50] 0 mean_batch_loss : 4.230141\n",
      "Start predicting 2019-12-23 15:03:40\n",
      "testing finish [2019-12-23 15:03:43] \n",
      "\tHR@1=0.14649  MRR@1=0.14649  NDCG@1=0.14649\n",
      "\tHR@5=0.42739  MRR@5=0.24660  NDCG@5=0.29143\n",
      "\tHR@10=0.56720  MRR@10=0.26534  NDCG@10=0.33673\n",
      "\tHR@20=0.68092  MRR@20=0.27334  NDCG@20=0.36562\n",
      "current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0005, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      "\n",
      "current model HR@20=0.68104  MRR@20=0.27357\n",
      "the best result so far. HR@20=0.68104  MRR@20=0.27922，其参数current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      " \n",
      "\n",
      "The best result HR@20=0.69513  MRR@20=0.27922, hyper-parameters: current model hyper-parameters: session_length=19, hidden_size=100, lr=0.0010, embedding_dim=100, embedding_dropout=0.25, dropout=0.50\n",
      ". \n",
      "over.\n"
     ]
    }
   ],
   "source": [
    "hidden_sizes = [100]\n",
    "embedding_dims = [100]\n",
    "dropouts = [0.5]\n",
    "embedding_dropouts = [0.25]\n",
    "lrs = [1e-3,3e-3,5e-4]\n",
    "session_lengths = [19]\n",
    "patience = 10\n",
    "best_params = \"\"\n",
    "best_all_model = 0.0\n",
    "best_all_hr = 0.0\n",
    "best_all_mrr = 0.0\n",
    "best_all_r1m = 0.0\n",
    "for session_length in session_lengths:\n",
    "    for hidden_size in hidden_sizes:\n",
    "        for embedding_dim in embedding_dims:\n",
    "            for dropout in dropouts:\n",
    "                for embedding_dropout in embedding_dropouts:\n",
    "                    for lr in lrs:\n",
    "                        args = {}\n",
    "                        print(\"current model hyper-parameters: session_length=%d, hidden_size=%d, lr=%.4f, embedding_dim=%d, embedding_dropout=%.2f, dropout=%.2f\\n\" % (session_length,hidden_size,lr,embedding_dim,embedding_dropout,dropout))\n",
    "                        args[\"session_length\"] = session_length\n",
    "                        args[\"hidden_size\"] = hidden_size\n",
    "                        args[\"embedding_dim\"] = embedding_dim\n",
    "                        args[\"dropout\"] = dropout\n",
    "                        args[\"embedding_dropout\"] = embedding_dropout\n",
    "                        args[\"patience\"] = patience\n",
    "                        args[\"lr\"] = lr\n",
    "                        best_model,best_model_hr,best_model_mrr = train(args)\n",
    "                        if best_model_hr + best_model_mrr > best_all_r1m:\n",
    "                            print(\"best model change\")\n",
    "                            best_all_r1m = best_model_hr + best_model_mrr\n",
    "                            best_all_hr = best_model_hr\n",
    "                            best_all_mrr = best_model_mrr\n",
    "                            best_all_model = best_model\n",
    "                            best_params = \"current model hyper-parameters: session_length=%d, hidden_size=%d, lr=%.4f, embedding_dim=%d, embedding_dropout=%.2f, dropout=%.2f\\n\" % (session_length,hidden_size,lr,embedding_dim,embedding_dropout,dropout)\n",
    "                        best_model = None\n",
    "                        print(\"current model hyper-parameters: session_length=%d, hidden_size=%d, lr=%.4f, embedding_dim=%d, embedding_dropout=%.2f, dropout=%.2f\\n\" % (session_length,hidden_size,lr,embedding_dim,embedding_dropout,dropout))\n",
    "                        print(\"current model HR@20=%.5f  MRR@20=%.5f\"%(best_model_hr,best_model_mrr))\n",
    "                        print(\"the best result so far. HR@20=%.5f  MRR@20=%.5f, %s \\n\"%(best_model_hr,best_all_mrr,best_params))\n",
    "print(\"The best result HR@20=%.5f  MRR@20=%.5f, hyper-parameters: %s. \"%(best_all_hr,best_all_mrr,best_params))\n",
    "print(\"over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smy",
   "language": "python",
   "name": "smy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
