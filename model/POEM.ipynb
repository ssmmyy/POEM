{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T02:28:04.406130Z",
     "start_time": "2019-12-23T02:28:03.961624Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MhcOrxNibMjb"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T02:28:04.409746Z",
     "start_time": "2019-12-23T02:28:04.407336Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EGxgHeR6bN0K"
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda:0\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T02:28:04.418237Z",
     "start_time": "2019-12-23T02:28:04.410895Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tBeDjO8dbPzP"
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "plot_num = 50000\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T02:28:04.446477Z",
     "start_time": "2019-12-23T02:28:04.419452Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zef81a0tbRC4"
   },
   "outputs": [],
   "source": [
    "class SessionData(object):\n",
    "    def __init__(self,session_index,session_id,items_indexes):\n",
    "        self.session_index = session_index\n",
    "        self.session_id = session_id\n",
    "        self.item_list = items_indexes\n",
    "    def generate_seq_datas(self,session_length,padding_idx=0,predict_length=1):\n",
    "        sessions = []\n",
    "        if len(self.item_list)<2:\n",
    "            self.item_list.append[self.item_list[0]]\n",
    "        if predict_length==1:\n",
    "            # when session length>=3\n",
    "            for i in range(1,len(self.item_list)-1):\n",
    "#             # when session length >=2\n",
    "#             for i in range(len(self.item_list)-1):\n",
    "                if i <session_length:\n",
    "                    train_data = [0 for _ in range(session_length-i-1)]\n",
    "                    train_data.extend(self.item_list[:i+1])\n",
    "                    train_data.append(self.item_list[i+1])\n",
    "                else:\n",
    "                    train_data = self.item_list[i+1-session_length:i+1]\n",
    "                    train_data.append(self.item_list[i+1])\n",
    "                sessions.append(train_data)\n",
    "        else:\n",
    "            pass\n",
    "        return self.session_index,sessions\n",
    "    def __str__(self):\n",
    "        info = \" session index = {}\\n session id = {} \\n the length of item list= {} \\n the fisrt item index in item list is {}\".format(self.session_index,self.session_id,len(self.item_list),self.item_list[0])\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T02:28:04.475393Z",
     "start_time": "2019-12-23T02:28:04.447540Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hl6NiyNJbTRg"
   },
   "outputs": [],
   "source": [
    "class SessionDataSet(object):\n",
    "    def __init__(self,train_file,test_file,padding_idx=0):\n",
    "        super(SessionDataSet,self).__init__()\n",
    "        self.index_count = 0\n",
    "        self.session_count = 0\n",
    "        self.train_count = 0\n",
    "        self.test_count = 0\n",
    "        self.max_session_length = 0\n",
    "\n",
    "        self.padding_idx = padding_idx\n",
    "        self.item2index = dict()\n",
    "        self.index2item = dict()\n",
    "        self.session2index = dict()\n",
    "        self.index2session = dict()\n",
    "        self.item_total_num = dict()\n",
    "        self.item2index[\"<pad>\"] = padding_idx\n",
    "        self.index2item[padding_idx] = \"<pad>\"\n",
    "        self.train_data = self.load_data(train_file)\n",
    "        print(\"training set is loaded, # index: \",len(self.item2index.keys()))\n",
    "        self.train_count = self.session_count\n",
    "        print(\"train_session_num\",self.train_count)\n",
    "        self.test_data = self.load_data(test_file)\n",
    "        print(\"testing set is loaded, # index: \",len(self.index2item.keys()))\n",
    "        print(\"# item\",self.index_count)\n",
    "        self.test_count = self.session_count-self.train_count\n",
    "        print(\"# test session:\",self.test_count)\n",
    "        self.all_training_data = []\n",
    "        self.all_testing_data = []\n",
    "        self.all_meta_training_data = []\n",
    "        self.all_meta_testing_data = []\n",
    "        self.train_session_length = 0\n",
    "        self.test_session_length = 0\n",
    "    \n",
    "    def load_data(self,file_path):\n",
    "        data =  pickle.load(open(file_path, 'rb'))\n",
    "        session_ids = data[0]\n",
    "        session_data = data[1]\n",
    "        session_label = data[2]\n",
    "\n",
    "        result_data = []\n",
    "        lenth = len(session_ids)\n",
    "        print(\"# session\",lenth)\n",
    "\n",
    "        last_session_id = session_ids[0]\n",
    "        \n",
    "        session_item_indexes = []\n",
    "\n",
    "        for item_id in session_data[0]:\n",
    "            if item_id not in self.item2index.keys():\n",
    "                self.index_count+=1\n",
    "                self.item2index[item_id] = self.index_count\n",
    "                self.index2item[self.index_count] = item_id\n",
    "                self.item_total_num[self.index_count] = 0\n",
    "            session_item_indexes.append(self.item2index[item_id])\n",
    "            self.item_total_num[self.item2index[item_id]] += 1\n",
    "        target_item = session_label[0]\n",
    "        if target_item not in self.item2index.keys():\n",
    "            self.index_count+=1\n",
    "            self.item2index[target_item] = self.index_count\n",
    "            self.index2item[self.index_count] = target_item\n",
    "            self.item_total_num[self.index_count] = 0\n",
    "        session_item_indexes.append(self.item2index[target_item])\n",
    "        self.item_total_num[self.item2index[target_item]] += 1\n",
    "\n",
    "        for session_id,items,target_item in zip(session_ids,session_data,session_label):\n",
    "            if session_id!=last_session_id:\n",
    "\n",
    "                self.session_count+=1\n",
    "                self.session2index[last_session_id] = self.session_count\n",
    "                self.index2session[self.session_count] = last_session_id\n",
    "                last_session_id = session_id\n",
    "                if len(session_item_indexes)>self.max_session_length:\n",
    "                    self.max_session_length = len(session_item_indexes)\n",
    "                new_session = SessionData(self.session_count,last_session_id,session_item_indexes)\n",
    "                result_data.append(new_session)\n",
    "                session_item_indexes = []\n",
    "                for item_id in items:\n",
    "                    if item_id not in self.item2index.keys():\n",
    "                        self.index_count+=1\n",
    "                        self.item2index[item_id] = self.index_count\n",
    "                        self.index2item[self.index_count] = item_id\n",
    "                        self.item_total_num[self.index_count] = 0\n",
    "                    session_item_indexes.append(self.item2index[item_id])\n",
    "                    self.item_total_num[self.item2index[item_id]] += 1\n",
    "                if target_item not in self.item2index.keys():\n",
    "                    self.index_count+=1\n",
    "                    self.item2index[target_item] = self.index_count\n",
    "                    self.index2item[self.index_count] = target_item\n",
    "                    self.item_total_num[self.index_count] = 0\n",
    "                session_item_indexes.append(self.item2index[target_item])\n",
    "                self.item_total_num[self.item2index[target_item]] += 1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        self.session_count+=1\n",
    "        self.session2index[last_session_id] = self.session_count\n",
    "        new_session = SessionData(self.session_count,last_session_id,session_item_indexes)\n",
    "        result_data.append(new_session)\n",
    "        print(\"loaded\")\n",
    "        print(new_session)\n",
    "        \n",
    "        return result_data\n",
    "    \n",
    "\n",
    "    def get_batch(self,batch_size,session_length=10,predict_length=1,all_data=None,phase=\"train\",neg_num=1,sampling_mathod=\"random\"):\n",
    "\n",
    "        if phase == \"train\":\n",
    "            if all_data is None:\n",
    "                all_data = self.get_all_training_data(session_length)\n",
    "            indexes = np.random.permutation(all_data.shape[0])\n",
    "            all_data = all_data[indexes]\n",
    "        else:\n",
    "            if all_data is None:\n",
    "                all_data = self.get_all_testing_data(session_length)\n",
    "        \n",
    "        sindex = 0\n",
    "        eindex = batch_size\n",
    "        while eindex < all_data.shape[0]:\n",
    "            batch = all_data[sindex: eindex]\n",
    "\n",
    "            temp = eindex\n",
    "            eindex = eindex + batch_size\n",
    "            sindex = temp\n",
    "            if phase ==\"train\":\n",
    "                batch = self.divid_and_extend_negative_samples(batch,session_length=session_length,predict_length=predict_length,neg_num=neg_num,method=sampling_mathod)\n",
    "            else:\n",
    "                batch = [batch[:,:session_length],batch[:,session_length:]]\n",
    "            yield batch\n",
    "\n",
    "        if eindex >= all_data.shape[0]:\n",
    "            batch = all_data[sindex:]\n",
    "            if phase ==\"train\":\n",
    "                batch = self.divid_and_extend_negative_samples(batch,session_length=session_length,predict_length=predict_length,neg_num=neg_num,method=sampling_mathod)\n",
    "            else:\n",
    "                batch = [batch[:,:session_length],batch[:,session_length:]]\n",
    "            yield batch\n",
    "    \n",
    "    def divid_and_extend_negative_samples(self,batch_data,session_length,predict_length=1,neg_num=1,method=\"random\"):\n",
    "        \"\"\"\n",
    "        divid and extend negative samples\n",
    "        \"\"\"\n",
    "        neg_items = []\n",
    "        if method == \"random\":\n",
    "            for session_and_target in batch_data:\n",
    "                neg_item = []\n",
    "                for i in range(neg_num):\n",
    "                    rand_item = random.randint(1,self.index_count)\n",
    "                    while rand_item in session_and_target or rand_item in neg_item:\n",
    "                        rand_item = random.randint(1,self.index_count)\n",
    "                    neg_item.append(rand_item)\n",
    "                neg_items.append(neg_item)\n",
    "        else:\n",
    "\n",
    "            total_list = set()\n",
    "            for session in batch_data:\n",
    "                for i in session:\n",
    "                    total_list.add(i) \n",
    "            total_list = list(total_list)\n",
    "            total_list =  sorted(total_list, key=lambda item: self.item_total_num[item],reverse=True)\n",
    "            for i,session in enumerate(batch_data):\n",
    "                np.random.choice(total_list)\n",
    "        session_items = batch_data[:,:session_length]\n",
    "        target_item = batch_data[:,session_length:]\n",
    "        neg_items = np.array(neg_items)\n",
    "        return [session_items,target_item,neg_items]\n",
    "    \n",
    "    def get_all_training_data(self,session_length,predict_length=1):\n",
    "        if len(self.all_training_data)!=0 and self.train_session_length==session_length:\n",
    "#             print(\"The build is complete and there is no need to repeat the build\")\n",
    "            return self.all_training_data\n",
    "        print(\"Start building the all training dataset\")\n",
    "        all_sessions = []\n",
    "        for session_data in self.train_data:\n",
    "            # 前session_length为session，后predict_length为target_item\n",
    "            session_index,sessions = session_data.generate_seq_datas(session_length,padding_idx=self.padding_idx)\n",
    "            if sessions is not None:\n",
    "                all_sessions.extend(sessions)\n",
    "        all_sessions = np.array(all_sessions)\n",
    "        self.all_training_data = all_sessions\n",
    "        self.train_session_length=session_length\n",
    "        print(\"The total number of training samples is：\",all_sessions.shape)\n",
    "        return all_sessions\n",
    "    \n",
    "    def get_all_testing_data(self,session_length,predict_length=1):\n",
    "        if len(self.all_testing_data)!=0 and self.test_session_length==session_length:\n",
    "            return self.all_testing_data\n",
    "        all_sessions = []\n",
    "        for session_data in self.test_data:\n",
    "            session_index,sessions = session_data.generate_seq_datas(session_length,padding_idx=self.padding_idx)\n",
    "            if sessions is not None:\n",
    "                all_sessions.extend(sessions)\n",
    "        all_sessions = np.array(all_sessions)\n",
    "        self.all_testing_data = all_sessions\n",
    "        self.test_session_length=session_length\n",
    "        print(\"The total number of testing samples is：\",all_sessions.shape)\n",
    "        return all_sessions\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T02:28:05.691006Z",
     "start_time": "2019-12-23T02:28:04.476345Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "ctSu0HF8bUqh",
    "outputId": "7287ecc0-f73d-4883-c8f6-20c9b8aeddb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# session 526135\n",
      "loaded\n",
      " session index = 132501\n",
      " session id = 598664 \n",
      " the length of item list= 5 \n",
      " the fisrt item index in item list is 15612\n",
      "training set is loaded, # index:  40841\n",
      "train_session_num 132501\n",
      "# session 44279\n",
      "loaded\n",
      " session index = 143847\n",
      " session id = 600240 \n",
      " the length of item list= 4 \n",
      " the fisrt item index in item list is 2093\n",
      "testing set is loaded, # index:  40841\n",
      "# item 40840\n",
      "# test session: 11346\n"
     ]
    }
   ],
   "source": [
    "# dataset = SessionDataSet(train_file=\"../data/retailrocket_gcsan_my/train.txt\",test_file=\"../../data/srgnn/retailrocket_gcsan_my/test.txt\")\n",
    "dataset = SessionDataSet(train_file=\"../data/diginetica_gcsan_my/train.txt\",test_file=\"../../data/srgnn/diginetica_gcsan_my/test.txt\")\n",
    "# dataset = SessionDataSet(train_file=\"../data/yoochoose1_4_gcsan_my/train.txt\",test_file=\"../../data/srgnn/yoochoose1_4_gcsan_my/test.txt\")\n",
    "# dataset = SessionDataSet(train_file=\"../data/yoochoose1_64_gcsan_my/train.txt\",test_file=\"../../data/srgnn/yoochoose1_64_gcsan_my/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T02:28:05.699945Z",
     "start_time": "2019-12-23T02:28:05.691907Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "cm7qU4B6bq2i"
   },
   "outputs": [],
   "source": [
    "def bpr_loss(r):\n",
    "    return torch.sum(-torch.log(torch.sigmoid(r)))\n",
    "def get_hit_num(pred,y_truth):\n",
    "    \"\"\"\n",
    "        pred: numpy type(batch_size,k) \n",
    "        y_truth: list type (batch_size,groudtruth_num)\n",
    "    \"\"\"\n",
    "\n",
    "    hit_num = 0\n",
    "    for i in range(len(y_truth)):\n",
    "        for value in y_truth[i]:\n",
    "            hit_num += np.sum(pred[i]==value)\n",
    "    return hit_num\n",
    "\n",
    "def get_rr(pred,y_truth):\n",
    "    rr=0.\n",
    "    for i in range(len(y_truth)):\n",
    "        for value in y_truth[i]:\n",
    "            hit_indexes = np.where(pred[i]==value)[0]\n",
    "            for hit_index in hit_indexes:\n",
    "                rr += 1/(hit_index+1)\n",
    "    return rr\n",
    "\n",
    "def get_dcg(pred,y_truth):\n",
    "    y_pred_score = np.zeros_like(pred)\n",
    "\n",
    "    for i in range(len(y_truth)):\n",
    "\n",
    "        for j,y_pred in enumerate(pred[i]):\n",
    "            if y_pred == y_truth[i][0]:\n",
    "                y_pred_score[i][j]=1\n",
    "    gain = 2 ** y_pred_score - 1\n",
    "    discounts = np.tile(np.log2(np.arange(pred.shape[1]) + 2),(len(y_truth),1))\n",
    "    dcg = np.sum(gain / discounts,axis=1)\n",
    "    return dcg\n",
    "\n",
    "def get_ndcg(pred,y_truth):\n",
    "    dcg = get_dcg(pred, y_truth)\n",
    "    idcg = get_dcg(np.concatenate((y_truth,np.zeros_like(pred)[:,:-1]-1),axis=1), y_truth)\n",
    "    ndcg = np.sum(dcg / idcg)\n",
    "\n",
    "    return ndcg\n",
    "\n",
    "def dcg_score(y_pre, y_true, k):\n",
    "    y_pre_score = np.zeros(k)\n",
    "    if len(y_pre) > k:\n",
    "        y_pre = y_pre[:k]\n",
    "    for i in range(len(y_pre)):\n",
    "        pre_tag = y_pre[i]\n",
    "        if pre_tag in y_true:\n",
    "            y_pre_score[i] = 1\n",
    "    gain = 2 ** y_pre_score - 1\n",
    "    discounts = np.log2(np.arange(k) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_pre, y_true, k=5):\n",
    "    dcg = dcg_score(y_pre, y_true, k)\n",
    "    idcg = dcg_score(y_true, y_true, k)\n",
    "    return dcg / idcg\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T02:28:05.723079Z",
     "start_time": "2019-12-23T02:28:05.700802Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "QdNvTTApbr_g"
   },
   "outputs": [],
   "source": [
    "# SelfAttention Layer\n",
    "class SelfAttention(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size,activate=\"selu\",dropout=0):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.config = list()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method not in ['dot', 'general']:\n",
    "            raise ValueError(self.method, \"Attention method do not exists.\")\n",
    "\n",
    "        if self.method == \"dot\":\n",
    "            self.query = torch.nn.Linear(self.hidden_size *2, self.hidden_size*2)\n",
    "            self.key = torch.nn.Linear(self.hidden_size*2, self.hidden_size*2)\n",
    "            torch.nn.init.constant_(self.query.bias,0)\n",
    "            torch.nn.init.constant_(self.key.bias,0)\n",
    "\n",
    "        if self.method == \"general\":\n",
    "            self.attention = torch.nn.Linear(self.hidden_size*2, self.hidden_size*2)\n",
    "            torch.nn.init.constant_(self.attention.bias,0)\n",
    "        \n",
    "        if activate == \"relu\":\n",
    "            self.activate = torch.relu\n",
    "        elif activate == \"tanh\":\n",
    "            self.activate = torch.tanh\n",
    "        elif activate == \"elu\":\n",
    "            self.activate = torch.nn.ELU()\n",
    "        elif activate == \"selu\":\n",
    "            self.activate = torch.selu\n",
    "        else:\n",
    "            self.activate = torch.sigmoid\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        torch.nn.utils.clip_grad_norm_(self.parameters(),max_norm=110)\n",
    "\n",
    "    def dot_score(self, encoder_output,is_train=True,weights=None):\n",
    "\n",
    "        if weights is None:\n",
    "            if is_train:\n",
    "                query = self.dropout(self.activate(self.query(encoder_output)))\n",
    "                key = self.dropout(self.activate(self.key(encoder_output)))\n",
    "            else:\n",
    "                query = self.activate(self.query(encoder_output))\n",
    "                key = self.activate(self.key(encoder_output))\n",
    "        else:\n",
    "            query = self.activate(torch.matmul(encoder_output,weights[0].t())+weights[1])\n",
    "            key = self.activate(torch.matmul(encoder_output,weights[2].t())+weights[3])\n",
    "        dot = query.bmm(key.permute(0, 2, 1))\n",
    "        return dot\n",
    "\n",
    "    def general_score(self, encoder_output,is_train=True,weights=None):\n",
    "        if weights is None:\n",
    "            if is_train:\n",
    "                energy = self.dropout(self.activate(self.attention(encoder_output)))\n",
    "            else:\n",
    "                energy = self.activate(self.attention(encoder_output))\n",
    "        else:\n",
    "            energy = self.activate(torch.matmul(encoder_output,weights[0].t())+weights[1])\n",
    "        return encoder_output.bmm(energy.permute(0, 2, 1))\n",
    "\n",
    "    def forward(self, encoder_outputs, mask=None,is_train=True):\n",
    "        # (batch_size,length,dim)\n",
    "        if self.method == \"general\":\n",
    "            attention_energies = self.general_score(encoder_outputs,is_train=is_train)\n",
    "        elif self.method == \"dot\":\n",
    "            attention_energies = self.dot_score(encoder_outputs,is_train=is_train)\n",
    "\n",
    "        #  (batch_size,length,length)\n",
    "        attention_energies.div_(torch.sqrt(torch.tensor(self.hidden_size, dtype=torch.float)))\n",
    "        if mask is not None:\n",
    "            new_mask = (1 - (1 - mask.float()).unsqueeze(1).permute(0, 2, 1).bmm(\n",
    "                (1 - mask.float()).unsqueeze(1)))\n",
    "\n",
    "            attention_energies = attention_energies - new_mask*1e12\n",
    "            weights = F.softmax(attention_energies, dim=2)\n",
    "            weights = weights*(1-new_mask)\n",
    "            # batch_size,length,length)*(batch_size,length,dim)->(batch_size,length,dim)->(batch_size,1,dim)->(batch_size,dim)\n",
    "            outputs = weights.bmm(encoder_outputs)\n",
    "            outputs.div_(mask.shape[1]-torch.sum(mask,dim=1).unsqueeze(1).unsqueeze(2).repeat((1,mask.shape[1],outputs.shape[2])).float())\n",
    "            outputs = outputs.sum(dim=1).squeeze(1)\n",
    "        else:\n",
    "            weights = F.softmax(attention_energies, dim=2)\n",
    "            # (batch_size,length,length)*(batch_size,length,dim)->(batch_size,length,dim)->(batch_size,1,dim)->(batch_size,dim)\n",
    "            outputs = (weights.bmm(encoder_outputs).sum(dim=1) / encoder_outputs.shape[1]).squeeze(1)\n",
    "        sa_weights = weights.sum(dim=1).squeeze(1)\n",
    "        return outputs, sa_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T02:28:05.738620Z",
     "start_time": "2019-12-23T02:28:05.724055Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aVIrdlmKbtUq"
   },
   "outputs": [],
   "source": [
    "class POEM(torch.nn.Module):\n",
    "    def __init__(self, hidden_size=64, itemNum=0, posNum=0, padding_idx=0, dropout=0.5,attention_method=\"dot\",head_num=4,\n",
    "                 activate=\"selu\",session_length=20):\n",
    "        super(POEM, self).__init__()\n",
    "        self.padding_idx = padding_idx\n",
    "        self.hidden_size = hidden_size\n",
    "        self.head_num = head_num\n",
    "        self.session_length = session_length\n",
    "        if activate == \"sigmoid\":\n",
    "            self.activate = torch.sigmoid\n",
    "        elif activate == \"tanh\":\n",
    "            self.activate = torch.tanh\n",
    "        elif activate == \"relu\":\n",
    "            self.activate = torch.relu\n",
    "        elif activate == \"elu\":\n",
    "            self.activate = torch.nn.ELU()\n",
    "        else:\n",
    "            self.activate = torch.selu\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.item_embedding = torch.nn.Embedding(itemNum, hidden_size, padding_idx=self.padding_idx,max_norm=1.5)\n",
    "        \n",
    "        self.position_embedding = torch.nn.Embedding(posNum,hidden_size,padding_idx=self.padding_idx,max_norm=1.5)\n",
    "    \n",
    "        self.position_weights = torch.nn.Embedding(posNum,1,padding_idx=self.padding_idx)\n",
    "        \n",
    "        self.self_attention = SelfAttention(attention_method, hidden_size,activate=activate,dropout=dropout).to(device)\n",
    "        torch.nn.init.constant_(self.item_embedding.weight[0],0)\n",
    "        torch.nn.init.constant_(self.position_embedding.weight[0],0)\n",
    "        torch.nn.init.constant_(self.position_weights.weight,1)\n",
    "        torch.nn.init.constant_(self.position_weights.weight[0],0)\n",
    "        \n",
    "        self.left_mlp1 = torch.nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.right_mlp1 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.mid_mlp1 = torch.nn.Linear(hidden_size*3, hidden_size,bias=False)\n",
    "        \n",
    "        self.layer_norm1 = torch.nn.LayerNorm(hidden_size*2)\n",
    "        self.layer_norm2 = torch.nn.LayerNorm(hidden_size)\n",
    "        \n",
    "    def forward(self, session,item=None,bpr_loss=False,neg_num=50):\n",
    "\n",
    "        mask = (session!=0).float()\n",
    "        length = torch.sum(mask,1).unsqueeze(1).repeat((1,self.hidden_size))\n",
    "        mask = mask.unsqueeze(2).repeat((1,1,self.hidden_size))\n",
    "        session_item_embeddings = self.item_embedding(session) * mask\n",
    "        positions = session.shape[1] - torch.arange(0,session.shape[1]).unsqueeze(0).repeat((session.shape[0],1)).to(device)\n",
    "        session_position_embeddings = self.dropout(self.position_embedding(positions))*mask\n",
    "        session_item_vecs = torch.cat((session_item_embeddings,session_position_embeddings), dim=2)\n",
    "        attention_mask = (session == self.padding_idx)\n",
    "        compute_output, sa_weights = self.self_attention(session_item_vecs, attention_mask)\n",
    "        compute_output = self.layer_norm1(compute_output)\n",
    "\n",
    "        session_position_weights = self.dropout(self.position_weights(positions))*mask\n",
    "        sa_weights = sa_weights.unsqueeze(2).repeat((1,1,self.hidden_size))\n",
    "        session_item_vecs2 = session_item_embeddings * session_position_weights * sa_weights\n",
    "        compute_output2 = torch.sum(session_item_vecs2, dim=1)/length\n",
    "        compute_output2 = self.layer_norm2(compute_output2)\n",
    "\n",
    "        left_output = self.dropout(self.activate(self.left_mlp1(compute_output)))\n",
    "        right_output = self.dropout(self.activate(self.right_mlp1(session_item_embeddings[:,-1])))\n",
    "        mid_output = self.dropout(self.activate(self.mid_mlp1(torch.cat((compute_output,session_item_embeddings[:,-1]),1))))\n",
    "        \n",
    "        compute_output1 = self.layer_norm2(left_output* right_output+mid_output +compute_output2)\n",
    "        \n",
    "        result = torch.matmul(compute_output1,self.item_embedding.weight[1:].t())\n",
    "        return result\n",
    "    \n",
    "    def predict_top_k(self, session, k=20):\n",
    "        mask = (session!=0).float()\n",
    "        length = torch.sum(mask,1).unsqueeze(1).repeat((1,self.hidden_size))\n",
    "        mask = mask.unsqueeze(2).repeat((1,1,self.hidden_size))\n",
    "        session_item_embeddings = self.item_embedding(session) * mask\n",
    "        positions = session.shape[1] - torch.arange(0,session.shape[1]).unsqueeze(0).repeat((session.shape[0],1)).to(device)\n",
    "        session_position_embeddings = self.position_embedding(positions)*mask\n",
    "        session_item_vecs = torch.cat((session_item_embeddings,session_position_embeddings), dim=2)\n",
    "        attention_mask = (session == self.padding_idx)\n",
    "        compute_output, sa_weights = self.self_attention(session_item_vecs, attention_mask,is_train=False)\n",
    "        compute_output = self.layer_norm1(compute_output)\n",
    "\n",
    "        session_position_weights = self.position_weights(positions)*mask\n",
    "        sa_weights = sa_weights.unsqueeze(2).repeat((1,1,self.hidden_size))\n",
    "        session_item_vecs2 = session_item_embeddings * session_position_weights * sa_weights\n",
    "        compute_output2 = torch.sum(session_item_vecs2, dim=1)/length\n",
    "        compute_output2 = self.layer_norm2(compute_output2)\n",
    "\n",
    "        left_output =self.activate(self.left_mlp1(compute_output))\n",
    "\n",
    "        right_output = self.activate(self.right_mlp1(session_item_embeddings[:,-1]))\n",
    "        mid_output = self.activate(self.mid_mlp1(torch.cat((compute_output,session_item_embeddings[:,-1]),1)))\n",
    "        compute_output1 = self.layer_norm2(left_output* right_output+mid_output +compute_output2)\n",
    "\n",
    "        result = torch.matmul(compute_output1,self.item_embedding.weight[1:].t())\n",
    "        result = torch.topk(result,k,dim=1)[1]\n",
    "        \n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T02:28:05.752731Z",
     "start_time": "2019-12-23T02:28:05.741005Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Jhrg56xebung"
   },
   "outputs": [],
   "source": [
    "epochs=50\n",
    "def train(args):\n",
    "    hidden_size = args[\"hidden_size\"] if \"hidden_size\" in args.keys() else 100\n",
    "    dropout = args[\"dropout\"] if \"dropout\" in args.keys()  else 0.5\n",
    "    attention_method = args[\"method\"] if \"method\" in args.keys()  else \"general\"\n",
    "    lr = args[\"lr\"] if \"lr\" in args.keys()  else 5e-4\n",
    "    weight_decay = args[\"weight_decay\"] if \"weight_decay\" in args.keys()  else 1e-5\n",
    "    amsgrad = args[\"amsgrad\"] if \"amsgrad\" in args.keys() else True\n",
    "    session_length = args[\"session_length\"] if \"session_length\" in args.keys() else 20\n",
    "    model = POEM(hidden_size=hidden_size, itemNum=dataset.index_count+1, posNum=session_length+1, padding_idx=0, dropout=dropout,\n",
    "                 activate=\"selu\",attention_method=attention_method).to(device)\n",
    "    opti = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay,amsgrad=amsgrad)\n",
    "    patience = args[\"patience\"] if \"patience\" in args.keys() else 5\n",
    "    best_model_hr = 0.0\n",
    "    best_model_mrr = 0.0\n",
    "    best_r1m = 0.0\n",
    "    best_model = None\n",
    "    predict_nums = [1,5,10,20]\n",
    "    no_improvement_epoch = 0\n",
    "    for epoch in range(epochs):\n",
    "        batch_losses = []\n",
    "        epoch_losses = []\n",
    "        for i,batch_data in enumerate(dataset.get_batch(batch_size,session_length,phase=\"train\")):\n",
    "            sessions = torch.tensor(batch_data[0]).to(device)\n",
    "            target_items = torch.tensor(batch_data[1]).squeeze().to(device)-1\n",
    "            result_pos = model(sessions)\n",
    "            loss = loss_function(result_pos,target_items)\n",
    "            opti.zero_grad()\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "            batch_losses.append(loss.cpu().detach().numpy())\n",
    "            epoch_losses.append(loss.cpu().detach().numpy())\n",
    "            if i % plot_num == 0:\n",
    "                time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                print(\"[%s] [%d/%d] %d mean_batch_loss : %0.6f\" % (time, epoch+1, epochs, i, np.mean(batch_losses)))\n",
    "                batch_losses = []\n",
    "        with torch.no_grad():\n",
    "            start_test_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(\"Start predicting\",start_test_time)\n",
    "            rrs = [0 for _ in range(len(predict_nums))]\n",
    "            hit_nums = [0 for _ in range(len(predict_nums))]\n",
    "            ndcgs = [0 for _ in range(len(predict_nums))]\n",
    "            for i,batch_data in enumerate(dataset.get_batch(batch_size,session_length,phase=\"test\")):\n",
    "                \n",
    "                sessions = torch.tensor(batch_data[0]).to(device)\n",
    "                target_items = np.array(batch_data[1])-1\n",
    "                y_pred = model.predict_top_k(sessions,20).cpu().numpy()\n",
    "                \n",
    "                for j,predict_num in enumerate(predict_nums):\n",
    "                    hit_nums[j]+=get_hit_num(y_pred[:,:predict_num],target_items)\n",
    "                    rrs[j]+=get_rr(y_pred[:,:predict_num],target_items)\n",
    "                    ndcgs[j]+=get_ndcg(y_pred[:,:predict_num],target_items)\n",
    "                    \n",
    "            end_test_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            hrs = [hit_num/len(dataset.all_testing_data) for hit_num in hit_nums]\n",
    "            mrrs = [rr/len(dataset.all_testing_data) for rr in rrs]\n",
    "            mndcgs = [ndcg/len(dataset.all_testing_data) for ndcg in ndcgs]\n",
    "            if hrs[-1] + mrrs[-1] > best_r1m:\n",
    "                print(\"change best\")\n",
    "                best_model = deepcopy(model)\n",
    "                best_model_hr = hrs[-1]\n",
    "                best_model_mrr = mrrs[-1]\n",
    "                best_r1m = hrs[-1] + mrrs[-1]\n",
    "                no_improvement_epoch = 0\n",
    "            else:\n",
    "                no_improvement_epoch +=1\n",
    "            print(\"testing finish [%s] \"%end_test_time)\n",
    "            for k,predict_num in enumerate(predict_nums):\n",
    "                print(\"\\tHR@%d=%.5f  MRR@%d=%.5f  NDCG@%d=%.5f\"%(predict_num,hrs[k],predict_num,mrrs[k],predict_num,mndcgs[k]))\n",
    "        if no_improvement_epoch>=patience:\n",
    "            print(\"early stopping\")\n",
    "            break\n",
    "    return best_model,best_model_hr,best_model_mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2H2SFJ7F77Z0"
   },
   "source": [
    "# CIKM-Session >= 3\n",
    "    Recall@20=0.67212  MRR@20=0.32399, hyper-parameters: session_length-20, hidden_size-100, lr-0.0005 , amsgrad-True, method-general, dropout-0.5, weight_decay-0.000000  \n",
    "        Recall@1=0.20793  MRR@1=0.20793  NDCG@1=0.20793\n",
    "        Recall@5=0.46230  MRR@5=0.30253  NDCG@5=0.34236\n",
    "        Recall@10=0.56835  MRR@10=0.31676  NDCG@10=0.37673\n",
    "        Recall@20=0.67212  MRR@20=0.32399  NDCG@20=0.40301\n",
    "# RR-Session >= 3\n",
    "    HR@20=0.56787  MRR@20=0.30798, hyper-parameters: session_length-20, hidden_size-100, lr-0.0003 , amsgrad-True, method-general, dropout-0.5, weight_decay-0.000000  \n",
    "        HR@1=0.22072  MRR@1=0.22072  NDCG@1=0.22072\n",
    "        HR@5=0.41475  MRR@5=0.29234  NDCG@5=0.32282\n",
    "        HR@10=0.49101  MRR@10=0.30264  NDCG@10=0.34761\n",
    "        HR@20=0.56787  MRR@20=0.30798  NDCG@20=0.36705\n",
    "# RSC64-Session >= 3\n",
    "    Recall@20=0.71064  MRR@20=0.29387, hyper-parameters: session_length-20, hidden_size-100, lr-0.0005 , amsgrad-True, method-general, neg_num=60, dropout-0.3, weight_decay-0.000000\n",
    "        Recall@1=0.16149  MRR@1=0.16149  NDCG@1=0.16149\n",
    "        Recall@5=0.45849  MRR@5=0.26711  NDCG@5=0.31456\n",
    "        Recall@10=0.59998  MRR@10=0.28611  NDCG@10=0.36043\n",
    "        Recall@20=0.71064  MRR@20=0.29387  NDCG@20=0.38852\n",
    "# RSC4-Session >= 3\n",
    "    HR@20=0.72378  MRR@20=0.29892, hyper-parameters: session_length-20, hidden_size-100, lr-0.0005 , amsgrad-True, method-general, dropout-0.3, weight_decay-0.000000  \n",
    "        HR@1=0.16524  MRR@1=0.16524  NDCG@1=0.16524\n",
    "        HR@5=0.46385  MRR@5=0.27146  NDCG@5=0.31917\n",
    "        HR@10=0.60716  MRR@10=0.29069  NDCG@10=0.36562\n",
    "        HR@20=0.72378  MRR@20=0.29892  NDCG@20=0.39528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T02:44:50.404405Z",
     "start_time": "2019-12-23T02:28:05.753870Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "S8pn0Z7bbv4t",
    "outputId": "c1aa9692-56a0-40d2-d99b-e75b4f1e537e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0005, amsgrad=True, method=general, dropout=0.5, weight_decay=0.000000. \n",
      "\n",
      "Start building the all training dataset\n",
      "The total number of training samples is： (526135, 21)\n",
      "[2019-12-23 10:28:10] [1/50] 0 mean_batch_loss : 40.987480\n",
      "Start predicting 2019-12-23 10:28:29\n",
      "The total number of testing samples is： (44279, 21)\n",
      "change best\n",
      "testing finish [2019-12-23 10:28:32] \n",
      "\tHR@1=0.00465  MRR@1=0.00465  NDCG@1=0.00465\n",
      "\tHR@5=0.01238  MRR@5=0.00737  NDCG@5=0.00861\n",
      "\tHR@10=0.01899  MRR@10=0.00820  NDCG@10=0.01070\n",
      "\tHR@20=0.03078  MRR@20=0.00902  NDCG@20=0.01367\n",
      "[2019-12-23 10:28:32] [2/50] 0 mean_batch_loss : 10.328138\n",
      "Start predicting 2019-12-23 10:28:48\n",
      "change best\n",
      "testing finish [2019-12-23 10:28:51] \n",
      "\tHR@1=0.05341  MRR@1=0.05341  NDCG@1=0.05341\n",
      "\tHR@5=0.08112  MRR@5=0.06369  NDCG@5=0.06803\n",
      "\tHR@10=0.09546  MRR@10=0.06556  NDCG@10=0.07263\n",
      "\tHR@20=0.11464  MRR@20=0.06687  NDCG@20=0.07745\n",
      "[2019-12-23 10:28:51] [3/50] 0 mean_batch_loss : 9.782820\n",
      "Start predicting 2019-12-23 10:29:06\n",
      "change best\n",
      "testing finish [2019-12-23 10:29:09] \n",
      "\tHR@1=0.20556  MRR@1=0.20556  NDCG@1=0.20556\n",
      "\tHR@5=0.22706  MRR@5=0.21413  NDCG@5=0.21738\n",
      "\tHR@10=0.23487  MRR@10=0.21516  NDCG@10=0.21989\n",
      "\tHR@20=0.24520  MRR@20=0.21587  NDCG@20=0.22249\n",
      "[2019-12-23 10:29:10] [4/50] 0 mean_batch_loss : 9.034612\n",
      "Start predicting 2019-12-23 10:29:28\n",
      "change best\n",
      "testing finish [2019-12-23 10:29:31] \n",
      "\tHR@1=0.21069  MRR@1=0.21069  NDCG@1=0.21069\n",
      "\tHR@5=0.25796  MRR@5=0.22862  NDCG@5=0.23594\n",
      "\tHR@10=0.27756  MRR@10=0.23124  NDCG@10=0.24229\n",
      "\tHR@20=0.29825  MRR@20=0.23266  NDCG@20=0.24750\n",
      "[2019-12-23 10:29:31] [5/50] 0 mean_batch_loss : 8.018018\n",
      "Start predicting 2019-12-23 10:29:49\n",
      "change best\n",
      "testing finish [2019-12-23 10:29:52] \n",
      "\tHR@1=0.21204  MRR@1=0.21204  NDCG@1=0.21204\n",
      "\tHR@5=0.29224  MRR@5=0.24161  NDCG@5=0.25422\n",
      "\tHR@10=0.32930  MRR@10=0.24659  NDCG@10=0.26623\n",
      "\tHR@20=0.36722  MRR@20=0.24922  NDCG@20=0.27582\n",
      "[2019-12-23 10:29:52] [6/50] 0 mean_batch_loss : 7.526215\n",
      "Start predicting 2019-12-23 10:30:07\n",
      "change best\n",
      "testing finish [2019-12-23 10:30:10] \n",
      "\tHR@1=0.21118  MRR@1=0.21118  NDCG@1=0.21118\n",
      "\tHR@5=0.32124  MRR@5=0.25151  NDCG@5=0.26885\n",
      "\tHR@10=0.37322  MRR@10=0.25848  NDCG@10=0.28570\n",
      "\tHR@20=0.42505  MRR@20=0.26209  NDCG@20=0.29882\n",
      "[2019-12-23 10:30:10] [7/50] 0 mean_batch_loss : 6.634240\n",
      "Start predicting 2019-12-23 10:30:27\n",
      "change best\n",
      "testing finish [2019-12-23 10:30:30] \n",
      "\tHR@1=0.21035  MRR@1=0.21035  NDCG@1=0.21035\n",
      "\tHR@5=0.34077  MRR@5=0.25803  NDCG@5=0.27861\n",
      "\tHR@10=0.40396  MRR@10=0.26646  NDCG@10=0.29904\n",
      "\tHR@20=0.46982  MRR@20=0.27104  NDCG@20=0.31570\n",
      "[2019-12-23 10:30:30] [8/50] 0 mean_batch_loss : 6.460123\n",
      "Start predicting 2019-12-23 10:30:48\n",
      "change best\n",
      "testing finish [2019-12-23 10:30:51] \n",
      "\tHR@1=0.20917  MRR@1=0.20917  NDCG@1=0.20917\n",
      "\tHR@5=0.35559  MRR@5=0.26293  NDCG@5=0.28599\n",
      "\tHR@10=0.42774  MRR@10=0.27255  NDCG@10=0.30931\n",
      "\tHR@20=0.50313  MRR@20=0.27777  NDCG@20=0.32836\n",
      "[2019-12-23 10:30:51] [9/50] 0 mean_batch_loss : 6.125219\n",
      "Start predicting 2019-12-23 10:31:07\n",
      "change best\n",
      "testing finish [2019-12-23 10:31:10] \n",
      "\tHR@1=0.20852  MRR@1=0.20852  NDCG@1=0.20852\n",
      "\tHR@5=0.36751  MRR@5=0.26665  NDCG@5=0.29173\n",
      "\tHR@10=0.44667  MRR@10=0.27717  NDCG@10=0.31729\n",
      "\tHR@20=0.52826  MRR@20=0.28286  NDCG@20=0.33795\n",
      "[2019-12-23 10:31:10] [10/50] 0 mean_batch_loss : 5.275475\n",
      "Start predicting 2019-12-23 10:31:26\n",
      "change best\n",
      "testing finish [2019-12-23 10:31:29] \n",
      "\tHR@1=0.20820  MRR@1=0.20820  NDCG@1=0.20820\n",
      "\tHR@5=0.37564  MRR@5=0.26939  NDCG@5=0.29582\n",
      "\tHR@10=0.45995  MRR@10=0.28067  NDCG@10=0.32311\n",
      "\tHR@20=0.54748  MRR@20=0.28678  NDCG@20=0.34529\n",
      "[2019-12-23 10:31:29] [11/50] 0 mean_batch_loss : 5.140894\n",
      "Start predicting 2019-12-23 10:31:47\n",
      "change best\n",
      "testing finish [2019-12-23 10:31:50] \n",
      "\tHR@1=0.20854  MRR@1=0.20854  NDCG@1=0.20854\n",
      "\tHR@5=0.38314  MRR@5=0.27261  NDCG@5=0.30011\n",
      "\tHR@10=0.47198  MRR@10=0.28444  NDCG@10=0.32882\n",
      "\tHR@20=0.56340  MRR@20=0.29080  NDCG@20=0.35195\n",
      "[2019-12-23 10:31:50] [12/50] 0 mean_batch_loss : 5.025702\n",
      "Start predicting 2019-12-23 10:32:08\n",
      "change best\n",
      "testing finish [2019-12-23 10:32:11] \n",
      "\tHR@1=0.20750  MRR@1=0.20750  NDCG@1=0.20750\n",
      "\tHR@5=0.38987  MRR@5=0.27410  NDCG@5=0.30289\n",
      "\tHR@10=0.48194  MRR@10=0.28632  NDCG@10=0.33260\n",
      "\tHR@20=0.57515  MRR@20=0.29282  NDCG@20=0.35620\n",
      "[2019-12-23 10:32:11] [13/50] 0 mean_batch_loss : 4.586874\n",
      "Start predicting 2019-12-23 10:32:26\n",
      "change best\n",
      "testing finish [2019-12-23 10:32:30] \n",
      "\tHR@1=0.20739  MRR@1=0.20739  NDCG@1=0.20739\n",
      "\tHR@5=0.39481  MRR@5=0.27607  NDCG@5=0.30561\n",
      "\tHR@10=0.48913  MRR@10=0.28861  NDCG@10=0.33606\n",
      "\tHR@20=0.58619  MRR@20=0.29541  NDCG@20=0.36068\n",
      "[2019-12-23 10:32:30] [14/50] 0 mean_batch_loss : 4.494617\n",
      "Start predicting 2019-12-23 10:32:46\n",
      "change best\n",
      "testing finish [2019-12-23 10:32:50] \n",
      "\tHR@1=0.20775  MRR@1=0.20775  NDCG@1=0.20775\n",
      "\tHR@5=0.40127  MRR@5=0.27851  NDCG@5=0.30904\n",
      "\tHR@10=0.49597  MRR@10=0.29113  NDCG@10=0.33964\n",
      "\tHR@20=0.59412  MRR@20=0.29798  NDCG@20=0.36451\n",
      "[2019-12-23 10:32:50] [15/50] 0 mean_batch_loss : 4.224423\n",
      "Start predicting 2019-12-23 10:33:08\n",
      "change best\n",
      "testing finish [2019-12-23 10:33:11] \n",
      "\tHR@1=0.20734  MRR@1=0.20734  NDCG@1=0.20734\n",
      "\tHR@5=0.40593  MRR@5=0.27999  NDCG@5=0.31132\n",
      "\tHR@10=0.50268  MRR@10=0.29289  NDCG@10=0.34259\n",
      "\tHR@20=0.60214  MRR@20=0.29980  NDCG@20=0.36774\n",
      "[2019-12-23 10:33:11] [16/50] 0 mean_batch_loss : 4.411129\n",
      "Start predicting 2019-12-23 10:33:27\n",
      "change best\n",
      "testing finish [2019-12-23 10:33:30] \n",
      "\tHR@1=0.20771  MRR@1=0.20771  NDCG@1=0.20771\n",
      "\tHR@5=0.40938  MRR@5=0.28179  NDCG@5=0.31354\n",
      "\tHR@10=0.50846  MRR@10=0.29496  NDCG@10=0.34552\n",
      "\tHR@20=0.60936  MRR@20=0.30195  NDCG@20=0.37102\n",
      "[2019-12-23 10:33:30] [17/50] 0 mean_batch_loss : 4.272418\n",
      "Start predicting 2019-12-23 10:33:45\n",
      "change best\n",
      "testing finish [2019-12-23 10:33:49] \n",
      "\tHR@1=0.20676  MRR@1=0.20676  NDCG@1=0.20676\n",
      "\tHR@5=0.41428  MRR@5=0.28286  NDCG@5=0.31555\n",
      "\tHR@10=0.51282  MRR@10=0.29600  NDCG@10=0.34741\n",
      "\tHR@20=0.61345  MRR@20=0.30302  NDCG@20=0.37291\n",
      "[2019-12-23 10:33:49] [18/50] 0 mean_batch_loss : 4.027922\n",
      "Start predicting 2019-12-23 10:34:07\n",
      "change best\n",
      "testing finish [2019-12-23 10:34:10] \n",
      "\tHR@1=0.20732  MRR@1=0.20732  NDCG@1=0.20732\n",
      "\tHR@5=0.41679  MRR@5=0.28427  NDCG@5=0.31724\n",
      "\tHR@10=0.51695  MRR@10=0.29769  NDCG@10=0.34969\n",
      "\tHR@20=0.61944  MRR@20=0.30483  NDCG@20=0.37564\n",
      "[2019-12-23 10:34:10] [19/50] 0 mean_batch_loss : 3.930878\n",
      "Start predicting 2019-12-23 10:34:27\n",
      "change best\n",
      "testing finish [2019-12-23 10:34:30] \n",
      "\tHR@1=0.20780  MRR@1=0.20780  NDCG@1=0.20780\n",
      "\tHR@5=0.42067  MRR@5=0.28602  NDCG@5=0.31953\n",
      "\tHR@10=0.52074  MRR@10=0.29937  NDCG@10=0.35189\n",
      "\tHR@20=0.62454  MRR@20=0.30662  NDCG@20=0.37819\n",
      "[2019-12-23 10:34:30] [20/50] 0 mean_batch_loss : 4.109733\n",
      "Start predicting 2019-12-23 10:34:46\n",
      "change best\n",
      "testing finish [2019-12-23 10:34:49] \n",
      "\tHR@1=0.20841  MRR@1=0.20841  NDCG@1=0.20841\n",
      "\tHR@5=0.42420  MRR@5=0.28773  NDCG@5=0.32169\n",
      "\tHR@10=0.52524  MRR@10=0.30118  NDCG@10=0.35432\n",
      "\tHR@20=0.62820  MRR@20=0.30839  NDCG@20=0.38045\n",
      "[2019-12-23 10:34:49] [21/50] 0 mean_batch_loss : 3.936034\n",
      "Start predicting 2019-12-23 10:35:06\n",
      "change best\n",
      "testing finish [2019-12-23 10:35:09] \n",
      "\tHR@1=0.20798  MRR@1=0.20798  NDCG@1=0.20798\n",
      "\tHR@5=0.42792  MRR@5=0.28903  NDCG@5=0.32361\n",
      "\tHR@10=0.52948  MRR@10=0.30259  NDCG@10=0.35645\n",
      "\tHR@20=0.63202  MRR@20=0.30975  NDCG@20=0.38242\n",
      "[2019-12-23 10:35:09] [22/50] 0 mean_batch_loss : 3.833929\n",
      "Start predicting 2019-12-23 10:35:28\n",
      "change best\n",
      "testing finish [2019-12-23 10:35:31] \n",
      "\tHR@1=0.20879  MRR@1=0.20879  NDCG@1=0.20879\n",
      "\tHR@5=0.42833  MRR@5=0.28976  NDCG@5=0.32426\n",
      "\tHR@10=0.53362  MRR@10=0.30378  NDCG@10=0.35828\n",
      "\tHR@20=0.63488  MRR@20=0.31083  NDCG@20=0.38391\n",
      "[2019-12-23 10:35:31] [23/50] 0 mean_batch_loss : 3.770357\n",
      "Start predicting 2019-12-23 10:35:46\n",
      "change best\n",
      "testing finish [2019-12-23 10:35:50] \n",
      "\tHR@1=0.20863  MRR@1=0.20863  NDCG@1=0.20863\n",
      "\tHR@5=0.43203  MRR@5=0.29120  NDCG@5=0.32627\n",
      "\tHR@10=0.53669  MRR@10=0.30514  NDCG@10=0.36008\n",
      "\tHR@20=0.63777  MRR@20=0.31221  NDCG@20=0.38571\n",
      "[2019-12-23 10:35:50] [24/50] 0 mean_batch_loss : 3.868102\n",
      "Start predicting 2019-12-23 10:36:05\n",
      "change best\n",
      "testing finish [2019-12-23 10:36:08] \n",
      "\tHR@1=0.20827  MRR@1=0.20827  NDCG@1=0.20827\n",
      "\tHR@5=0.43425  MRR@5=0.29191  NDCG@5=0.32736\n",
      "\tHR@10=0.54003  MRR@10=0.30601  NDCG@10=0.36154\n",
      "\tHR@20=0.64136  MRR@20=0.31304  NDCG@20=0.38716\n",
      "[2019-12-23 10:36:08] [25/50] 0 mean_batch_loss : 3.762710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting 2019-12-23 10:36:27\n",
      "change best\n",
      "testing finish [2019-12-23 10:36:30] \n",
      "\tHR@1=0.20938  MRR@1=0.20938  NDCG@1=0.20938\n",
      "\tHR@5=0.43608  MRR@5=0.29367  NDCG@5=0.32916\n",
      "\tHR@10=0.54258  MRR@10=0.30790  NDCG@10=0.36362\n",
      "\tHR@20=0.64455  MRR@20=0.31499  NDCG@20=0.38942\n",
      "[2019-12-23 10:36:30] [26/50] 0 mean_batch_loss : 3.723840\n",
      "Start predicting 2019-12-23 10:36:46\n",
      "change best\n",
      "testing finish [2019-12-23 10:36:50] \n",
      "\tHR@1=0.20874  MRR@1=0.20874  NDCG@1=0.20874\n",
      "\tHR@5=0.43912  MRR@5=0.29384  NDCG@5=0.33002\n",
      "\tHR@10=0.54391  MRR@10=0.30784  NDCG@10=0.36391\n",
      "\tHR@20=0.64688  MRR@20=0.31502  NDCG@20=0.38999\n",
      "[2019-12-23 10:36:50] [27/50] 0 mean_batch_loss : 3.630210\n",
      "Start predicting 2019-12-23 10:37:05\n",
      "change best\n",
      "testing finish [2019-12-23 10:37:08] \n",
      "\tHR@1=0.21060  MRR@1=0.21060  NDCG@1=0.21060\n",
      "\tHR@5=0.44249  MRR@5=0.29614  NDCG@5=0.33258\n",
      "\tHR@10=0.54556  MRR@10=0.30992  NDCG@10=0.36593\n",
      "\tHR@20=0.64981  MRR@20=0.31716  NDCG@20=0.39230\n",
      "[2019-12-23 10:37:08] [28/50] 0 mean_batch_loss : 3.602756\n",
      "Start predicting 2019-12-23 10:37:26\n",
      "change best\n",
      "testing finish [2019-12-23 10:37:29] \n",
      "\tHR@1=0.20958  MRR@1=0.20958  NDCG@1=0.20958\n",
      "\tHR@5=0.44373  MRR@5=0.29622  NDCG@5=0.33296\n",
      "\tHR@10=0.54771  MRR@10=0.31014  NDCG@10=0.36662\n",
      "\tHR@20=0.65202  MRR@20=0.31739  NDCG@20=0.39300\n",
      "[2019-12-23 10:37:29] [29/50] 0 mean_batch_loss : 3.759323\n",
      "Start predicting 2019-12-23 10:37:47\n",
      "change best\n",
      "testing finish [2019-12-23 10:37:51] \n",
      "\tHR@1=0.21064  MRR@1=0.21064  NDCG@1=0.21064\n",
      "\tHR@5=0.44613  MRR@5=0.29766  NDCG@5=0.33462\n",
      "\tHR@10=0.55101  MRR@10=0.31168  NDCG@10=0.36856\n",
      "\tHR@20=0.65318  MRR@20=0.31877  NDCG@20=0.39439\n",
      "[2019-12-23 10:37:51] [30/50] 0 mean_batch_loss : 3.770199\n",
      "Start predicting 2019-12-23 10:38:06\n",
      "change best\n",
      "testing finish [2019-12-23 10:38:09] \n",
      "\tHR@1=0.20996  MRR@1=0.20996  NDCG@1=0.20996\n",
      "\tHR@5=0.44811  MRR@5=0.29825  NDCG@5=0.33558\n",
      "\tHR@10=0.55378  MRR@10=0.31233  NDCG@10=0.36973\n",
      "\tHR@20=0.65553  MRR@20=0.31938  NDCG@20=0.39544\n",
      "[2019-12-23 10:38:09] [31/50] 0 mean_batch_loss : 3.731070\n",
      "Start predicting 2019-12-23 10:38:25\n",
      "change best\n",
      "testing finish [2019-12-23 10:38:28] \n",
      "\tHR@1=0.20926  MRR@1=0.20926  NDCG@1=0.20926\n",
      "\tHR@5=0.44856  MRR@5=0.29798  NDCG@5=0.33549\n",
      "\tHR@10=0.55304  MRR@10=0.31201  NDCG@10=0.36936\n",
      "\tHR@20=0.65623  MRR@20=0.31921  NDCG@20=0.39551\n",
      "[2019-12-23 10:38:29] [32/50] 0 mean_batch_loss : 3.619015\n",
      "Start predicting 2019-12-23 10:38:47\n",
      "change best\n",
      "testing finish [2019-12-23 10:38:50] \n",
      "\tHR@1=0.20870  MRR@1=0.20870  NDCG@1=0.20870\n",
      "\tHR@5=0.44994  MRR@5=0.29816  NDCG@5=0.33597\n",
      "\tHR@10=0.55593  MRR@10=0.31234  NDCG@10=0.37028\n",
      "\tHR@20=0.65912  MRR@20=0.31951  NDCG@20=0.39638\n",
      "[2019-12-23 10:38:50] [33/50] 0 mean_batch_loss : 3.441865\n",
      "Start predicting 2019-12-23 10:39:06\n",
      "change best\n",
      "testing finish [2019-12-23 10:39:09] \n",
      "\tHR@1=0.20944  MRR@1=0.20944  NDCG@1=0.20944\n",
      "\tHR@5=0.44965  MRR@5=0.29887  NDCG@5=0.33645\n",
      "\tHR@10=0.55649  MRR@10=0.31323  NDCG@10=0.37110\n",
      "\tHR@20=0.66045  MRR@20=0.32046  NDCG@20=0.39741\n",
      "[2019-12-23 10:39:09] [34/50] 0 mean_batch_loss : 3.584634\n",
      "Start predicting 2019-12-23 10:39:25\n",
      "change best\n",
      "testing finish [2019-12-23 10:39:28] \n",
      "\tHR@1=0.20983  MRR@1=0.20983  NDCG@1=0.20983\n",
      "\tHR@5=0.45096  MRR@5=0.29941  NDCG@5=0.33718\n",
      "\tHR@10=0.55850  MRR@10=0.31379  NDCG@10=0.37199\n",
      "\tHR@20=0.66178  MRR@20=0.32096  NDCG@20=0.39810\n",
      "[2019-12-23 10:39:28] [35/50] 0 mean_batch_loss : 3.452351\n",
      "Start predicting 2019-12-23 10:39:46\n",
      "change best\n",
      "testing finish [2019-12-23 10:39:49] \n",
      "\tHR@1=0.21008  MRR@1=0.21008  NDCG@1=0.21008\n",
      "\tHR@5=0.45188  MRR@5=0.30004  NDCG@5=0.33788\n",
      "\tHR@10=0.56011  MRR@10=0.31451  NDCG@10=0.37290\n",
      "\tHR@20=0.66296  MRR@20=0.32168  NDCG@20=0.39895\n",
      "[2019-12-23 10:39:49] [36/50] 0 mean_batch_loss : 3.607268\n",
      "Start predicting 2019-12-23 10:40:07\n",
      "change best\n",
      "testing finish [2019-12-23 10:40:10] \n",
      "\tHR@1=0.20922  MRR@1=0.20922  NDCG@1=0.20922\n",
      "\tHR@5=0.45462  MRR@5=0.30027  NDCG@5=0.33872\n",
      "\tHR@10=0.56144  MRR@10=0.31453  NDCG@10=0.37327\n",
      "\tHR@20=0.66431  MRR@20=0.32169  NDCG@20=0.39930\n",
      "[2019-12-23 10:40:10] [37/50] 0 mean_batch_loss : 3.439280\n",
      "Start predicting 2019-12-23 10:40:26\n",
      "change best\n",
      "testing finish [2019-12-23 10:40:29] \n",
      "\tHR@1=0.20854  MRR@1=0.20854  NDCG@1=0.20854\n",
      "\tHR@5=0.45441  MRR@5=0.30007  NDCG@5=0.33853\n",
      "\tHR@10=0.56243  MRR@10=0.31448  NDCG@10=0.37346\n",
      "\tHR@20=0.66517  MRR@20=0.32162  NDCG@20=0.39945\n",
      "[2019-12-23 10:40:29] [38/50] 0 mean_batch_loss : 3.273194\n",
      "Start predicting 2019-12-23 10:40:45\n",
      "change best\n",
      "testing finish [2019-12-23 10:40:48] \n",
      "\tHR@1=0.20942  MRR@1=0.20942  NDCG@1=0.20942\n",
      "\tHR@5=0.45457  MRR@5=0.30072  NDCG@5=0.33908\n",
      "\tHR@10=0.56298  MRR@10=0.31529  NDCG@10=0.37424\n",
      "\tHR@20=0.66643  MRR@20=0.32247  NDCG@20=0.40039\n",
      "[2019-12-23 10:40:48] [39/50] 0 mean_batch_loss : 3.435845\n",
      "Start predicting 2019-12-23 10:41:07\n",
      "testing finish [2019-12-23 10:41:10] \n",
      "\tHR@1=0.20827  MRR@1=0.20827  NDCG@1=0.20827\n",
      "\tHR@5=0.45439  MRR@5=0.29984  NDCG@5=0.33837\n",
      "\tHR@10=0.56399  MRR@10=0.31452  NDCG@10=0.37387\n",
      "\tHR@20=0.66668  MRR@20=0.32164  NDCG@20=0.39982\n",
      "[2019-12-23 10:41:10] [40/50] 0 mean_batch_loss : 3.353274\n",
      "Start predicting 2019-12-23 10:41:26\n",
      "testing finish [2019-12-23 10:41:29] \n",
      "\tHR@1=0.20743  MRR@1=0.20743  NDCG@1=0.20743\n",
      "\tHR@5=0.45453  MRR@5=0.29943  NDCG@5=0.33809\n",
      "\tHR@10=0.56458  MRR@10=0.31420  NDCG@10=0.37377\n",
      "\tHR@20=0.66711  MRR@20=0.32131  NDCG@20=0.39968\n",
      "[2019-12-23 10:41:29] [41/50] 0 mean_batch_loss : 3.305625\n",
      "Start predicting 2019-12-23 10:41:45\n",
      "change best\n",
      "testing finish [2019-12-23 10:41:48] \n",
      "\tHR@1=0.20780  MRR@1=0.20780  NDCG@1=0.20780\n",
      "\tHR@5=0.45719  MRR@5=0.30073  NDCG@5=0.33973\n",
      "\tHR@10=0.56487  MRR@10=0.31513  NDCG@10=0.37458\n",
      "\tHR@20=0.66804  MRR@20=0.32231  NDCG@20=0.40069\n",
      "[2019-12-23 10:41:48] [42/50] 0 mean_batch_loss : 3.244378\n",
      "Start predicting 2019-12-23 10:42:06\n",
      "change best\n",
      "testing finish [2019-12-23 10:42:09] \n",
      "\tHR@1=0.20786  MRR@1=0.20786  NDCG@1=0.20786\n",
      "\tHR@5=0.45685  MRR@5=0.30065  NDCG@5=0.33960\n",
      "\tHR@10=0.56580  MRR@10=0.31526  NDCG@10=0.37490\n",
      "\tHR@20=0.66975  MRR@20=0.32248  NDCG@20=0.40119\n",
      "[2019-12-23 10:42:09] [43/50] 0 mean_batch_loss : 3.155003\n",
      "Start predicting 2019-12-23 10:42:27\n",
      "testing finish [2019-12-23 10:42:30] \n",
      "\tHR@1=0.20703  MRR@1=0.20703  NDCG@1=0.20703\n",
      "\tHR@5=0.45699  MRR@5=0.30024  NDCG@5=0.33933\n",
      "\tHR@10=0.56675  MRR@10=0.31500  NDCG@10=0.37494\n",
      "\tHR@20=0.66953  MRR@20=0.32219  NDCG@20=0.40099\n",
      "[2019-12-23 10:42:30] [44/50] 0 mean_batch_loss : 3.422896\n",
      "Start predicting 2019-12-23 10:42:46\n",
      "testing finish [2019-12-23 10:42:49] \n",
      "\tHR@1=0.20590  MRR@1=0.20590  NDCG@1=0.20590\n",
      "\tHR@5=0.45776  MRR@5=0.29944  NDCG@5=0.33890\n",
      "\tHR@10=0.56752  MRR@10=0.31418  NDCG@10=0.37448\n",
      "\tHR@20=0.66962  MRR@20=0.32127  NDCG@20=0.40030\n",
      "[2019-12-23 10:42:49] [45/50] 0 mean_batch_loss : 3.163610\n",
      "Start predicting 2019-12-23 10:43:05\n",
      "testing finish [2019-12-23 10:43:09] \n",
      "\tHR@1=0.20603  MRR@1=0.20603  NDCG@1=0.20603\n",
      "\tHR@5=0.45755  MRR@5=0.29950  NDCG@5=0.33889\n",
      "\tHR@10=0.56686  MRR@10=0.31416  NDCG@10=0.37431\n",
      "\tHR@20=0.66962  MRR@20=0.32129  NDCG@20=0.40029\n",
      "[2019-12-23 10:43:09] [46/50] 0 mean_batch_loss : 3.236815\n",
      "Start predicting 2019-12-23 10:43:27\n",
      "testing finish [2019-12-23 10:43:30] \n",
      "\tHR@1=0.20495  MRR@1=0.20495  NDCG@1=0.20495\n",
      "\tHR@5=0.45886  MRR@5=0.29942  NDCG@5=0.33916\n",
      "\tHR@10=0.56747  MRR@10=0.31401  NDCG@10=0.37439\n",
      "\tHR@20=0.67059  MRR@20=0.32115  NDCG@20=0.40043\n",
      "[2019-12-23 10:43:30] [47/50] 0 mean_batch_loss : 3.226507\n",
      "Start predicting 2019-12-23 10:43:46\n",
      "testing finish [2019-12-23 10:43:49] \n",
      "\tHR@1=0.20294  MRR@1=0.20294  NDCG@1=0.20294\n",
      "\tHR@5=0.45753  MRR@5=0.29747  NDCG@5=0.33736\n",
      "\tHR@10=0.56670  MRR@10=0.31215  NDCG@10=0.37278\n",
      "\tHR@20=0.66926  MRR@20=0.31928  NDCG@20=0.39872\n",
      "[2019-12-23 10:43:49] [48/50] 0 mean_batch_loss : 3.344387\n",
      "Start predicting 2019-12-23 10:44:05\n",
      "testing finish [2019-12-23 10:44:08] \n",
      "\tHR@1=0.20294  MRR@1=0.20294  NDCG@1=0.20294\n",
      "\tHR@5=0.45814  MRR@5=0.29755  NDCG@5=0.33756\n",
      "\tHR@10=0.56916  MRR@10=0.31242  NDCG@10=0.37351\n",
      "\tHR@20=0.67039  MRR@20=0.31944  NDCG@20=0.39910\n",
      "[2019-12-23 10:44:08] [49/50] 0 mean_batch_loss : 3.301032\n",
      "Start predicting 2019-12-23 10:44:26\n",
      "testing finish [2019-12-23 10:44:29] \n",
      "\tHR@1=0.20238  MRR@1=0.20238  NDCG@1=0.20238\n",
      "\tHR@5=0.45796  MRR@5=0.29744  NDCG@5=0.33746\n",
      "\tHR@10=0.56731  MRR@10=0.31211  NDCG@10=0.37290\n",
      "\tHR@20=0.67018  MRR@20=0.31929  NDCG@20=0.39895\n",
      "[2019-12-23 10:44:29] [50/50] 0 mean_batch_loss : 3.073684\n",
      "Start predicting 2019-12-23 10:44:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing finish [2019-12-23 10:44:50] \n",
      "\tHR@1=0.20021  MRR@1=0.20021  NDCG@1=0.20021\n",
      "\tHR@5=0.45656  MRR@5=0.29490  NDCG@5=0.33517\n",
      "\tHR@10=0.56607  MRR@10=0.30960  NDCG@10=0.37067\n",
      "\tHR@20=0.66923  MRR@20=0.31677  NDCG@20=0.39676\n",
      "best model change\n",
      "current model hyper-parameters: session_length=20, hidden_size=100, lr=0.0005, amsgrad=True, method=general, dropout=0.5, weight_decay=0.000000. \n",
      "\n",
      "current model HR@20=0.66975  MRR@20=0.32248.\n",
      "the best result so far. HR@20=0.66975  MRR@20=0.32248， hyper-parameters: session_length-20, hidden_size-100, lr-0.0005 , amsgrad-True, method-general, dropout-0.5, weight_decay-0.000000. \n",
      "\n",
      "The best result HR@20=0.66975  MRR@20=0.32248, hyper-parameters: session_length-20, hidden_size-100, lr-0.0005 , amsgrad-True, method-general, dropout-0.5, weight_decay-0.000000. \n",
      "over.\n"
     ]
    }
   ],
   "source": [
    "hidden_sizes = [100]\n",
    "dropouts = [0.5]\n",
    "attention_methods = [\"general\"]\n",
    "lrs = [5e-4]\n",
    "session_lengths = [20]\n",
    "weight_decays = [0]\n",
    "patience = 10\n",
    "amsgrads = [True]\n",
    "best_params = \"\"\n",
    "best_all_model = 0.0\n",
    "best_all_hr = 0.0\n",
    "best_all_mrr = 0.0\n",
    "best_all_r1m = 0.0\n",
    "for session_length in session_lengths:\n",
    "    for hidden_size in hidden_sizes:\n",
    "        for amsgrad in amsgrads:\n",
    "            for attention_method in attention_methods:\n",
    "                for dropout in dropouts:\n",
    "                    for weight_decay in weight_decays:\n",
    "                        for lr in lrs:\n",
    "                            args = {}\n",
    "                            print(\"current model hyper-parameters: session_length=%d, hidden_size=%d, lr=%.4f, amsgrad=%s, method=%s, dropout=%.1f, weight_decay=%.6f. \\n\" % (session_length,hidden_size,lr,str(amsgrad),attention_method,dropout,weight_decay))\n",
    "                            args[\"session_length\"] = session_length\n",
    "                            args[\"hidden_size\"] = hidden_size\n",
    "                            args[\"amsgrad\"] = amsgrad\n",
    "                            args[\"method\"] = attention_method\n",
    "                            args[\"dropout\"] = dropout\n",
    "                            args[\"weight_decay\"] = weight_decay\n",
    "                            args[\"lr\"] = lr\n",
    "                            args[\"patience\"] = patience\n",
    "                            best_model,best_model_hr,best_model_mrr = train(args)\n",
    "                            if best_model_hr + best_model_mrr > best_all_r1m:\n",
    "                                print(\"best model change\")\n",
    "                                best_all_r1m = best_model_hr + best_model_mrr\n",
    "                                best_all_hr = best_model_hr\n",
    "                                best_all_mrr = best_model_mrr\n",
    "                                best_all_model = best_model\n",
    "                                best_params = \"session_length-%d, hidden_size-%d, lr-%.4f , amsgrad-%s, method-%s, dropout-%.1f, weight_decay-%.6f\"%(session_length,hidden_size,lr,str(amsgrad),attention_method,dropout,weight_decay)\n",
    "                            best_model = None\n",
    "                            print(\"current model hyper-parameters: session_length=%d, hidden_size=%d, lr=%.4f, amsgrad=%s, method=%s, dropout=%.1f, weight_decay=%.6f. \\n\" % (session_length,hidden_size,lr,str(amsgrad),attention_method,dropout,weight_decay))\n",
    "                            print(\"current model HR@20=%.5f  MRR@20=%.5f.\"%(best_model_hr,best_model_mrr))\n",
    "                            print(\"the best result so far. HR@20=%.5f  MRR@20=%.5f， hyper-parameters: %s. \\n\"%(best_all_hr,best_all_mrr,best_params))\n",
    "print(\"The best result HR@20=%.5f  MRR@20=%.5f, hyper-parameters: %s. \"%(best_all_hr,best_all_mrr,best_params))\n",
    "print(\"over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "WDP-CE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "smy",
   "language": "python",
   "name": "smy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
